<!DOCTYPE HTML>
<html lang="en" class="rust" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>APR Format Specification - EXTREME TDD - The Aprender Guide to Zero-Defect Machine Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="A comprehensive guide to EXTREME TDD methodology: RED-GREEN-REFACTOR cycles, mutation testing, and Toyota Way principles demonstrated through ML library development">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('rust')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Core Methodology</li><li class="chapter-item expanded "><a href="../methodology/what-is-extreme-tdd.html"><strong aria-hidden="true">1.</strong> What is EXTREME TDD?</a></li><li class="chapter-item expanded "><a href="../methodology/red-green-refactor.html"><strong aria-hidden="true">2.</strong> The RED-GREEN-REFACTOR Cycle</a></li><li class="chapter-item expanded "><a href="../methodology/test-first-philosophy.html"><strong aria-hidden="true">3.</strong> Test-First Philosophy</a></li><li class="chapter-item expanded "><a href="../methodology/zero-tolerance.html"><strong aria-hidden="true">4.</strong> Zero Tolerance Quality</a></li><li class="chapter-item expanded affix "><li class="part-title">The RED Phase</li><li class="chapter-item expanded "><a href="../red-phase/failing-tests-first.html"><strong aria-hidden="true">5.</strong> Writing Failing Tests First</a></li><li class="chapter-item expanded "><a href="../red-phase/test-categories.html"><strong aria-hidden="true">6.</strong> Test Categories</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../red-phase/unit-tests.html"><strong aria-hidden="true">6.1.</strong> Unit Tests</a></li><li class="chapter-item expanded "><a href="../red-phase/integration-tests.html"><strong aria-hidden="true">6.2.</strong> Integration Tests</a></li><li class="chapter-item expanded "><a href="../red-phase/property-based-tests.html"><strong aria-hidden="true">6.3.</strong> Property-Based Tests</a></li></ol></li><li class="chapter-item expanded "><a href="../red-phase/verification-strategy.html"><strong aria-hidden="true">7.</strong> Verification Strategy</a></li><li class="chapter-item expanded affix "><li class="part-title">The GREEN Phase</li><li class="chapter-item expanded "><a href="../green-phase/minimal-implementation.html"><strong aria-hidden="true">8.</strong> Minimal Implementation</a></li><li class="chapter-item expanded "><a href="../green-phase/making-tests-pass.html"><strong aria-hidden="true">9.</strong> Making Tests Pass</a></li><li class="chapter-item expanded "><a href="../green-phase/avoiding-over-engineering.html"><strong aria-hidden="true">10.</strong> Avoiding Over-Engineering</a></li><li class="chapter-item expanded "><a href="../green-phase/simplest-thing.html"><strong aria-hidden="true">11.</strong> The Simplest Thing That Works</a></li><li class="chapter-item expanded affix "><li class="part-title">The REFACTOR Phase</li><li class="chapter-item expanded "><a href="../refactor-phase/refactoring-with-confidence.html"><strong aria-hidden="true">12.</strong> Refactoring with Confidence</a></li><li class="chapter-item expanded "><a href="../refactor-phase/code-quality.html"><strong aria-hidden="true">13.</strong> Code Quality Improvements</a></li><li class="chapter-item expanded "><a href="../refactor-phase/performance-optimization.html"><strong aria-hidden="true">14.</strong> Performance Optimization</a></li><li class="chapter-item expanded "><a href="../refactor-phase/documentation.html"><strong aria-hidden="true">15.</strong> Documentation</a></li><li class="chapter-item expanded affix "><li class="part-title">Advanced Testing</li><li class="chapter-item expanded "><a href="../advanced-testing/popperian-falsification.html"><strong aria-hidden="true">16.</strong> Popperian Falsification</a></li><li class="chapter-item expanded "><a href="../advanced-testing/property-based-testing.html"><strong aria-hidden="true">17.</strong> Property-Based Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../advanced-testing/proptest-fundamentals.html"><strong aria-hidden="true">17.1.</strong> Proptest Fundamentals</a></li><li class="chapter-item expanded "><a href="../advanced-testing/strategies-generators.html"><strong aria-hidden="true">17.2.</strong> Strategies and Generators</a></li><li class="chapter-item expanded "><a href="../advanced-testing/testing-invariants.html"><strong aria-hidden="true">17.3.</strong> Testing Invariants</a></li></ol></li><li class="chapter-item expanded "><a href="../advanced-testing/mutation-testing.html"><strong aria-hidden="true">18.</strong> Mutation Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../advanced-testing/what-is-mutation-testing.html"><strong aria-hidden="true">18.1.</strong> What is Mutation Testing?</a></li><li class="chapter-item expanded "><a href="../advanced-testing/using-cargo-mutants.html"><strong aria-hidden="true">18.2.</strong> Using cargo-mutants</a></li><li class="chapter-item expanded "><a href="../advanced-testing/mutation-score-targets.html"><strong aria-hidden="true">18.3.</strong> Mutation Score Targets</a></li><li class="chapter-item expanded "><a href="../advanced-testing/killing-mutants.html"><strong aria-hidden="true">18.4.</strong> Killing Mutants</a></li></ol></li><li class="chapter-item expanded "><a href="../advanced-testing/fuzzing.html"><strong aria-hidden="true">19.</strong> Fuzzing</a></li><li class="chapter-item expanded "><a href="../advanced-testing/benchmark-testing.html"><strong aria-hidden="true">20.</strong> Benchmark Testing</a></li><li class="chapter-item expanded affix "><li class="part-title">Quality Gates</li><li class="chapter-item expanded "><a href="../quality-gates/pre-commit-hooks.html"><strong aria-hidden="true">21.</strong> Pre-Commit Hooks</a></li><li class="chapter-item expanded "><a href="../quality-gates/continuous-integration.html"><strong aria-hidden="true">22.</strong> Continuous Integration</a></li><li class="chapter-item expanded "><a href="../quality-gates/code-formatting.html"><strong aria-hidden="true">23.</strong> Code Formatting (rustfmt)</a></li><li class="chapter-item expanded "><a href="../quality-gates/linting-clippy.html"><strong aria-hidden="true">24.</strong> Linting (clippy)</a></li><li class="chapter-item expanded "><a href="../quality-gates/coverage-measurement.html"><strong aria-hidden="true">25.</strong> Coverage Measurement</a></li><li class="chapter-item expanded "><a href="../quality-gates/complexity-analysis.html"><strong aria-hidden="true">26.</strong> Complexity Analysis</a></li><li class="chapter-item expanded "><a href="../quality-gates/tdg-score.html"><strong aria-hidden="true">27.</strong> Technical Debt Gradient (TDG)</a></li><li class="chapter-item expanded affix "><li class="part-title">Toyota Way Principles</li><li class="chapter-item expanded "><a href="../toyota-way/overview.html"><strong aria-hidden="true">28.</strong> Overview</a></li><li class="chapter-item expanded "><a href="../toyota-way/kaizen.html"><strong aria-hidden="true">29.</strong> Kaizen (Continuous Improvement)</a></li><li class="chapter-item expanded "><a href="../toyota-way/genchi-genbutsu.html"><strong aria-hidden="true">30.</strong> Genchi Genbutsu (Go and See)</a></li><li class="chapter-item expanded "><a href="../toyota-way/jidoka.html"><strong aria-hidden="true">31.</strong> Jidoka (Built-in Quality)</a></li><li class="chapter-item expanded "><a href="../toyota-way/pdca-cycle.html"><strong aria-hidden="true">32.</strong> PDCA Cycle</a></li><li class="chapter-item expanded "><a href="../toyota-way/respect-for-people.html"><strong aria-hidden="true">33.</strong> Respect for People</a></li><li class="chapter-item expanded affix "><li class="part-title">Machine Learning Fundamentals</li><li class="chapter-item expanded "><a href="../ml-fundamentals/linear-regression.html"><strong aria-hidden="true">34.</strong> Linear Regression Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/regularization.html"><strong aria-hidden="true">35.</strong> Regularization Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/logistic-regression.html"><strong aria-hidden="true">36.</strong> Logistic Regression Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/knn.html"><strong aria-hidden="true">37.</strong> K-Nearest Neighbors (kNN) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/naive-bayes.html"><strong aria-hidden="true">38.</strong> Naive Bayes Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/bayesian-inference.html"><strong aria-hidden="true">39.</strong> Bayesian Inference Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/svm.html"><strong aria-hidden="true">40.</strong> Support Vector Machines (SVM) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/decision-trees.html"><strong aria-hidden="true">41.</strong> Decision Trees Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/ensemble-methods.html"><strong aria-hidden="true">42.</strong> Ensemble Methods Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/kmeans-clustering.html"><strong aria-hidden="true">43.</strong> K-Means Clustering Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/pca.html"><strong aria-hidden="true">44.</strong> Principal Component Analysis (PCA) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/tsne.html"><strong aria-hidden="true">45.</strong> t-SNE (t-Distributed Stochastic Neighbor Embedding) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/regression-metrics.html"><strong aria-hidden="true">46.</strong> Regression Metrics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/classification-metrics.html"><strong aria-hidden="true">47.</strong> Classification Metrics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/cross-validation.html"><strong aria-hidden="true">48.</strong> Cross-Validation Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/gradient-descent.html"><strong aria-hidden="true">49.</strong> Gradient Descent Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/advanced-optimizers.html"><strong aria-hidden="true">50.</strong> Advanced Optimizers Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/metaheuristics.html"><strong aria-hidden="true">51.</strong> Metaheuristics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/automl.html"><strong aria-hidden="true">52.</strong> AutoML: Automated Machine Learning</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/compiler-in-the-loop.html"><strong aria-hidden="true">53.</strong> Compiler-in-the-Loop Learning</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/online-learning.html"><strong aria-hidden="true">54.</strong> Online Learning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/neuro-symbolic.html"><strong aria-hidden="true">55.</strong> Neuro-Symbolic Reasoning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/transfer-learning.html"><strong aria-hidden="true">56.</strong> Transfer Learning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/active-learning.html"><strong aria-hidden="true">57.</strong> Active Learning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/weak-supervision.html"><strong aria-hidden="true">58.</strong> Weak Supervision Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/automatic-differentiation.html"><strong aria-hidden="true">59.</strong> Automatic Differentiation Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-neural-networks.html"><strong aria-hidden="true">60.</strong> Graph Neural Networks Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/neural-network-pruning.html"><strong aria-hidden="true">61.</strong> Neural Network Pruning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/lottery-ticket-hypothesis.html"><strong aria-hidden="true">62.</strong> Lottery Ticket Hypothesis Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/monte-carlo.html"><strong aria-hidden="true">63.</strong> Monte Carlo Simulation Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/speech-voice-processing.html"><strong aria-hidden="true">64.</strong> Speech and Voice Processing Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/probability-calibration.html"><strong aria-hidden="true">65.</strong> Probability Calibration Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/chaos-engineering.html"><strong aria-hidden="true">66.</strong> Chaos Engineering for ML</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/webassembly-ml.html"><strong aria-hidden="true">67.</strong> WebAssembly for ML</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/feature-scaling.html"><strong aria-hidden="true">68.</strong> Feature Scaling Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/audio-processing.html"><strong aria-hidden="true">69.</strong> Audio Processing Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-algorithms.html"><strong aria-hidden="true">70.</strong> Graph Algorithms Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-pathfinding.html"><strong aria-hidden="true">71.</strong> Graph Pathfinding Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-components-traversal.html"><strong aria-hidden="true">72.</strong> Graph Components and Traversal</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-link-prediction.html"><strong aria-hidden="true">73.</strong> Graph Link Prediction and Community Detection</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/descriptive-statistics.html"><strong aria-hidden="true">74.</strong> Descriptive Statistics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/apriori.html"><strong aria-hidden="true">75.</strong> Apriori Algorithm Theory</a></li><li class="chapter-item expanded affix "><li class="part-title">Real-World Examples from Aprender</li><li class="chapter-item expanded "><a href="../examples/examples-reference.html"><strong aria-hidden="true">76.</strong> Examples Reference</a></li><li class="chapter-item expanded "><a href="../examples/linear-regression.html"><strong aria-hidden="true">77.</strong> Case Study: Linear Regression</a></li><li class="chapter-item expanded "><a href="../examples/boston-housing.html"><strong aria-hidden="true">78.</strong> Case Study: Boston Housing</a></li><li class="chapter-item expanded "><a href="../examples/cross-validation.html"><strong aria-hidden="true">79.</strong> Case Study: Cross-Validation</a></li><li class="chapter-item expanded "><a href="../examples/grid-search-tuning.html"><strong aria-hidden="true">80.</strong> Case Study: Grid Search Hyperparameter Tuning</a></li><li class="chapter-item expanded "><a href="../examples/automl-clustering.html"><strong aria-hidden="true">81.</strong> Case Study: AutoML Clustering (TPE)</a></li><li class="chapter-item expanded "><a href="../examples/random-forest.html"><strong aria-hidden="true">82.</strong> Case Study: Random Forest</a></li><li class="chapter-item expanded "><a href="../examples/random-forest-iris.html"><strong aria-hidden="true">83.</strong> Case Study: Random Forest Iris</a></li><li class="chapter-item expanded "><a href="../examples/random-forest-regression.html"><strong aria-hidden="true">84.</strong> Case Study: Random Forest Regression</a></li><li class="chapter-item expanded "><a href="../examples/decision-tree-iris.html"><strong aria-hidden="true">85.</strong> Case Study: Decision Tree Iris</a></li><li class="chapter-item expanded "><a href="../examples/decision-tree-regression.html"><strong aria-hidden="true">86.</strong> Case Study: Decision Tree Regression</a></li><li class="chapter-item expanded "><a href="../examples/model-serialization.html"><strong aria-hidden="true">87.</strong> Case Study: Model Serialization</a></li><li class="chapter-item expanded "><a href="../examples/model-format.html"><strong aria-hidden="true">88.</strong> Case Study: Model Format (.apr)</a></li><li class="chapter-item expanded "><a href="../examples/apr-format-deep-dive.html"><strong aria-hidden="true">89.</strong> The .apr Format: A Five Whys Deep Dive</a></li><li class="chapter-item expanded "><a href="../examples/model-bundling-paging.html"><strong aria-hidden="true">90.</strong> Case Study: Model Bundling and Memory Paging</a></li><li class="chapter-item expanded "><a href="../examples/tracing-memory-paging.html"><strong aria-hidden="true">91.</strong> Case Study: Tracing Memory Paging with Renacer</a></li><li class="chapter-item expanded "><a href="../examples/bundle-trace-demo.html"><strong aria-hidden="true">92.</strong> Case Study: Bundle Trace Demo</a></li><li class="chapter-item expanded "><a href="../examples/synthetic-data-generation.html"><strong aria-hidden="true">93.</strong> Case Study: Synthetic Data Generation</a></li><li class="chapter-item expanded "><a href="../examples/code-eda.html"><strong aria-hidden="true">94.</strong> Case Study: Code-Aware EDA</a></li><li class="chapter-item expanded "><a href="../examples/code-feature-extractor.html"><strong aria-hidden="true">95.</strong> Case Study: Code Feature Extraction</a></li><li class="chapter-item expanded "><a href="../examples/code-analysis.html"><strong aria-hidden="true">96.</strong> Case Study: Code Analysis with Code2Vec and MPNN</a></li><li class="chapter-item expanded "><a href="../examples/kmeans-clustering.html"><strong aria-hidden="true">97.</strong> Case Study: KMeans Clustering</a></li><li class="chapter-item expanded "><a href="../examples/dbscan-clustering.html"><strong aria-hidden="true">98.</strong> Case Study: DBSCAN Clustering</a></li><li class="chapter-item expanded "><a href="../examples/hierarchical-clustering.html"><strong aria-hidden="true">99.</strong> Case Study: Hierarchical Clustering</a></li><li class="chapter-item expanded "><a href="../examples/gmm-clustering.html"><strong aria-hidden="true">100.</strong> Case Study: GMM Clustering</a></li><li class="chapter-item expanded "><a href="../examples/iris-clustering.html"><strong aria-hidden="true">101.</strong> Case Study: Iris Clustering</a></li><li class="chapter-item expanded "><a href="../examples/logistic-regression.html"><strong aria-hidden="true">102.</strong> Case Study: Logistic Regression</a></li><li class="chapter-item expanded "><a href="../examples/knn-iris.html"><strong aria-hidden="true">103.</strong> Case Study: KNN Iris</a></li><li class="chapter-item expanded "><a href="../examples/naive-bayes-iris.html"><strong aria-hidden="true">104.</strong> Case Study: Naive Bayes Iris</a></li><li class="chapter-item expanded "><a href="../examples/beta-binomial-inference.html"><strong aria-hidden="true">105.</strong> Case Study: Beta-Binomial Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/gamma-poisson-inference.html"><strong aria-hidden="true">106.</strong> Case Study: Gamma-Poisson Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/normal-inverse-gamma-inference.html"><strong aria-hidden="true">107.</strong> Case Study: Normal-InverseGamma Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/dirichlet-multinomial-inference.html"><strong aria-hidden="true">108.</strong> Case Study: Dirichlet-Multinomial Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/bayesian-linear-regression.html"><strong aria-hidden="true">109.</strong> Case Study: Bayesian Linear Regression</a></li><li class="chapter-item expanded "><a href="../examples/bayesian-logistic-regression.html"><strong aria-hidden="true">110.</strong> Case Study: Bayesian Logistic Regression</a></li><li class="chapter-item expanded "><a href="../examples/negative-binomial-glm.html"><strong aria-hidden="true">111.</strong> Case Study: Negative Binomial GLM (Overdispersed Counts)</a></li><li class="chapter-item expanded "><a href="../examples/svm-iris.html"><strong aria-hidden="true">112.</strong> Case Study: SVM Iris</a></li><li class="chapter-item expanded "><a href="../examples/gbm-iris.html"><strong aria-hidden="true">113.</strong> Case Study: Gradient Boosting Iris</a></li><li class="chapter-item expanded "><a href="../examples/regularized-regression.html"><strong aria-hidden="true">114.</strong> Case Study: Regularized Regression</a></li><li class="chapter-item expanded "><a href="../examples/optimizer-demo.html"><strong aria-hidden="true">115.</strong> Case Study: Optimizer Demo</a></li><li class="chapter-item expanded "><a href="../examples/batch-optimization.html"><strong aria-hidden="true">116.</strong> Case Study: Batch Optimization</a></li><li class="chapter-item expanded "><a href="../examples/convex-optimization.html"><strong aria-hidden="true">117.</strong> Case Study: Convex Optimization (FISTA + Coordinate Descent)</a></li><li class="chapter-item expanded "><a href="../examples/constrained-optimization.html"><strong aria-hidden="true">118.</strong> Case Study: Constrained Optimization (Projected GD + Augmented Lagrangian + Interior Point)</a></li><li class="chapter-item expanded "><a href="../examples/admm-optimization.html"><strong aria-hidden="true">119.</strong> Case Study: ADMM Optimization (Distributed ML + Federated Learning)</a></li><li class="chapter-item expanded "><a href="../examples/differential-evolution.html"><strong aria-hidden="true">120.</strong> Case Study: Differential Evolution (Metaheuristics)</a></li><li class="chapter-item expanded "><a href="../examples/metaheuristics-optimization.html"><strong aria-hidden="true">121.</strong> Case Study: Metaheuristics Optimization</a></li><li class="chapter-item expanded "><a href="../examples/aco-tsp.html"><strong aria-hidden="true">122.</strong> Case Study: Ant Colony Optimization (TSP)</a></li><li class="chapter-item expanded "><a href="../examples/tabu-tsp.html"><strong aria-hidden="true">123.</strong> Case Study: Tabu Search (TSP)</a></li><li class="chapter-item expanded "><a href="../examples/tsp-solver-crate.html"><strong aria-hidden="true">124.</strong> Case Study: aprender-tsp Sub-Crate</a></li><li class="chapter-item expanded "><a href="../examples/predator-prey-optimization.html"><strong aria-hidden="true">125.</strong> Case Study: Predator-Prey Optimization</a></li><li class="chapter-item expanded "><a href="../examples/dataframe-basics.html"><strong aria-hidden="true">126.</strong> Case Study: DataFrame Basics</a></li><li class="chapter-item expanded "><a href="../examples/data-preprocessing-scalers.html"><strong aria-hidden="true">127.</strong> Case Study: Data Preprocessing with Scalers</a></li><li class="chapter-item expanded "><a href="../examples/graph-social-network.html"><strong aria-hidden="true">128.</strong> Case Study: Graph Social Network</a></li><li class="chapter-item expanded "><a href="../examples/community-detection.html"><strong aria-hidden="true">129.</strong> Case Study: Community Detection with Louvain</a></li><li class="chapter-item expanded "><a href="../examples/graph-algorithms-comprehensive.html"><strong aria-hidden="true">130.</strong> Case Study: Comprehensive Graph Algorithms</a></li><li class="chapter-item expanded "><a href="../examples/descriptive-statistics.html"><strong aria-hidden="true">131.</strong> Case Study: Descriptive Statistics</a></li><li class="chapter-item expanded "><a href="../examples/bayesian-blocks-histogram.html"><strong aria-hidden="true">132.</strong> Case Study: Bayesian Blocks Histogram</a></li><li class="chapter-item expanded "><a href="../examples/pca-iris.html"><strong aria-hidden="true">133.</strong> Case Study: PCA Iris</a></li><li class="chapter-item expanded "><a href="../examples/isolation-forest-anomaly.html"><strong aria-hidden="true">134.</strong> Case Study: Isolation Forest Anomaly Detection</a></li><li class="chapter-item expanded "><a href="../examples/lof-anomaly.html"><strong aria-hidden="true">135.</strong> Case Study: Local Outlier Factor (LOF)</a></li><li class="chapter-item expanded "><a href="../examples/spectral-clustering.html"><strong aria-hidden="true">136.</strong> Case Study: Spectral Clustering</a></li><li class="chapter-item expanded "><a href="../examples/tsne-visualization.html"><strong aria-hidden="true">137.</strong> Case Study: t-SNE Visualization</a></li><li class="chapter-item expanded "><a href="../examples/market-basket-apriori.html"><strong aria-hidden="true">138.</strong> Case Study: Market Basket Analysis (Apriori)</a></li><li class="chapter-item expanded "><a href="../examples/time-series-forecasting.html"><strong aria-hidden="true">139.</strong> Case Study: ARIMA Time Series Forecasting</a></li><li class="chapter-item expanded "><a href="../examples/text-preprocessing.html"><strong aria-hidden="true">140.</strong> Case Study: Text Preprocessing for NLP</a></li><li class="chapter-item expanded "><a href="../examples/text-classification.html"><strong aria-hidden="true">141.</strong> Case Study: Text Classification with TF-IDF</a></li><li class="chapter-item expanded "><a href="../examples/chat-template.html"><strong aria-hidden="true">142.</strong> Case Study: Chat Templates for LLM Inference</a></li><li class="chapter-item expanded "><a href="../examples/advanced-nlp.html"><strong aria-hidden="true">143.</strong> Case Study: Advanced NLP (Similarity, Entities, Summarization)</a></li><li class="chapter-item expanded "><a href="../examples/xor-neural-network.html"><strong aria-hidden="true">144.</strong> Case Study: XOR Neural Network (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../examples/xor-training.html"><strong aria-hidden="true">145.</strong> Case Study: XOR Training</a></li><li class="chapter-item expanded "><a href="../examples/neural-network-training.html"><strong aria-hidden="true">146.</strong> Case Study: Neural Network Training Pipeline</a></li><li class="chapter-item expanded "><a href="../examples/classification-training.html"><strong aria-hidden="true">147.</strong> Case Study: Classification Training</a></li><li class="chapter-item expanded "><a href="../examples/nlp-advanced.html"><strong aria-hidden="true">148.</strong> Case Study: Advanced NLP</a></li><li class="chapter-item expanded "><a href="../examples/topic-sentiment-analysis.html"><strong aria-hidden="true">149.</strong> Case Study: Topic & Sentiment Analysis</a></li><li class="chapter-item expanded "><a href="../examples/recommend-content.html"><strong aria-hidden="true">150.</strong> Case Study: Content-Based Recommendations</a></li><li class="chapter-item expanded "><a href="../examples/content-recommender.html"><strong aria-hidden="true">151.</strong> Case Study: Content-Based Recommender System</a></li><li class="chapter-item expanded "><a href="../examples/shell-completion.html"><strong aria-hidden="true">152.</strong> Case Study: AI Shell Completion</a></li><li class="chapter-item expanded "><a href="../examples/shell-completion-benchmarks.html"><strong aria-hidden="true">153.</strong> Case Study: Shell Completion Benchmarks</a></li><li class="chapter-item expanded "><a href="../examples/shell-hf-hub-publishing.html"><strong aria-hidden="true">154.</strong> Case Study: Publishing Shell Models to HF Hub</a></li><li class="chapter-item expanded "><a href="../examples/shell-encryption-tiers.html"><strong aria-hidden="true">155.</strong> Case Study: Model Encryption Tiers</a></li><li class="chapter-item expanded "><a href="../examples/shell-encryption-demo.html"><strong aria-hidden="true">156.</strong> Case Study: Shell Encryption Demo</a></li><li class="chapter-item expanded "><a href="../examples/shell-homomorphic-encryption.html"><strong aria-hidden="true">157.</strong> Case Study: Shell Homomorphic Encryption</a></li><li class="chapter-item expanded "><a href="../examples/shell-model-format.html"><strong aria-hidden="true">158.</strong> Case Study: Shell Model Format</a></li><li class="chapter-item expanded "><a href="../examples/mixture-of-experts.html"><strong aria-hidden="true">159.</strong> Case Study: Mixture of Experts (MoE)</a></li><li class="chapter-item expanded "><a href="../examples/shell-history-developer-guide.html"><strong aria-hidden="true">160.</strong> Developer's Guide: Shell History Models</a></li><li class="chapter-item expanded "><a href="../examples/custom-error-classifier.html"><strong aria-hidden="true">161.</strong> Building Custom Error Classifiers</a></li><li class="chapter-item expanded "><a href="../examples/citl-automated-repair.html"><strong aria-hidden="true">162.</strong> Case Study: CITL Automated Program Repair</a></li><li class="chapter-item expanded "><a href="../examples/batuta-integration.html"><strong aria-hidden="true">163.</strong> Case Study: Batuta - Automated Migration to Aprender</a></li><li class="chapter-item expanded "><a href="../examples/online-learning.html"><strong aria-hidden="true">164.</strong> Case Study: Online Learning and Dynamic Retraining</a></li><li class="chapter-item expanded "><a href="../examples/apr-loading-modes.html"><strong aria-hidden="true">165.</strong> Case Study: APR Loading Modes</a></li><li class="chapter-item expanded "><a href="../examples/apr-inspection.html"><strong aria-hidden="true">166.</strong> Case Study: APR Model Inspection</a></li><li class="chapter-item expanded "><a href="../examples/apr-scoring.html"><strong aria-hidden="true">167.</strong> Case Study: APR 100-Point Quality Scoring</a></li><li class="chapter-item expanded "><a href="../examples/poka-yoke-validation.html"><strong aria-hidden="true">168.</strong> Case Study: APR Poka-Yoke Validation</a></li><li class="chapter-item expanded "><a href="../examples/apr-cache.html"><strong aria-hidden="true">169.</strong> Case Study: APR Model Cache</a></li><li class="chapter-item expanded "><a href="../examples/apr-embed.html"><strong aria-hidden="true">170.</strong> Case Study: APR Data Embedding</a></li><li class="chapter-item expanded "><a href="../examples/apr-with-metadata.html"><strong aria-hidden="true">171.</strong> Case Study: APR with JSON Metadata</a></li><li class="chapter-item expanded "><a href="../examples/cuda-backend.html"><strong aria-hidden="true">172.</strong> Case Study: CUDA and GPU Backends</a></li><li class="chapter-item expanded "><a href="../examples/trueno-compute-integration.html"><strong aria-hidden="true">173.</strong> Case Study: Trueno Compute Integration</a></li><li class="chapter-item expanded "><a href="../examples/apr-cli-demo.html"><strong aria-hidden="true">174.</strong> Case Study: APR CLI Tool Demo</a></li><li class="chapter-item expanded "><a href="../examples/create-test-apr.html"><strong aria-hidden="true">175.</strong> Case Study: Create Test APR Files</a></li><li class="chapter-item expanded "><a href="../examples/apr-cli-commands.html"><strong aria-hidden="true">176.</strong> Case Study: APR CLI Commands Demo</a></li><li class="chapter-item expanded "><a href="../examples/model-zoo.html"><strong aria-hidden="true">177.</strong> Case Study: Model Zoo</a></li><li class="chapter-item expanded "><a href="../examples/sovereign-stack.html"><strong aria-hidden="true">178.</strong> Case Study: Sovereign AI Stack Integration</a></li><li class="chapter-item expanded "><a href="../examples/sovereign-offline.html"><strong aria-hidden="true">179.</strong> Case Study: Sovereign AI Offline Mode</a></li><li class="chapter-item expanded "><a href="../examples/explainability-audit.html"><strong aria-hidden="true">180.</strong> Case Study: Model Explainability and Audit Trails</a></li><li class="chapter-item expanded "><a href="../examples/model-serving.html"><strong aria-hidden="true">181.</strong> Case Study: Model Serving</a></li><li class="chapter-item expanded "><a href="../examples/federation-gateway.html"><strong aria-hidden="true">182.</strong> Case Study: Federation Gateway</a></li><li class="chapter-item expanded "><a href="../examples/federation-routing.html"><strong aria-hidden="true">183.</strong> Case Study: Federation Routing Policies</a></li><li class="chapter-item expanded "><a href="../examples/probar-tui-testing.html"><strong aria-hidden="true">184.</strong> Case Study: Probar TUI Testing</a></li><li class="chapter-item expanded "><a href="../examples/pipeline-verification.html"><strong aria-hidden="true">185.</strong> Case Study: Pipeline Verification</a></li><li class="chapter-item expanded "><a href="../examples/state-machine-playbooks.html"><strong aria-hidden="true">186.</strong> Case Study: State Machine Playbooks</a></li><li class="chapter-item expanded "><a href="../examples/tensorlogic-reasoning.html"><strong aria-hidden="true">187.</strong> Case Study: TensorLogic Neuro-Symbolic Reasoning</a></li><li class="chapter-item expanded "><a href="../examples/audio-mel-spectrogram.html"><strong aria-hidden="true">188.</strong> Case Study: Audio Mel Spectrogram Processing</a></li><li class="chapter-item expanded "><a href="../examples/monte-carlo-simulation.html"><strong aria-hidden="true">189.</strong> Case Study: Monte Carlo Financial Simulation</a></li><li class="chapter-item expanded "><a href="../examples/autograd-training.html"><strong aria-hidden="true">190.</strong> Case Study: Automatic Differentiation Training</a></li><li class="chapter-item expanded "><a href="../examples/gnn-node-classification.html"><strong aria-hidden="true">191.</strong> Case Study: Graph Neural Networks</a></li><li class="chapter-item expanded "><a href="../examples/pruning-magnitude.html"><strong aria-hidden="true">192.</strong> Case Study: Magnitude Pruning</a></li><li class="chapter-item expanded "><a href="../examples/lottery-ticket-pruning.html"><strong aria-hidden="true">193.</strong> Case Study: Lottery Ticket Pruning</a></li><li class="chapter-item expanded "><a href="../examples/bench-comparison.html"><strong aria-hidden="true">194.</strong> Case Study: Benchmark Comparison</a></li><li class="chapter-item expanded "><a href="../examples/showcase-benchmark.html"><strong aria-hidden="true">195.</strong> Case Study: Showcase Benchmark</a></li><li class="chapter-item expanded "><a href="../examples/qa-falsification.html"><strong aria-hidden="true">196.</strong> Case Study: QA Falsification Protocol</a></li><li class="chapter-item expanded "><a href="../examples/qwen-qa-playbook.html"><strong aria-hidden="true">197.</strong> Case Study: Qwen2.5-Coder QA Playbook</a></li><li class="chapter-item expanded "><a href="../examples/ptx-parity-validation.html"><strong aria-hidden="true">198.</strong> Case Study: PTX Parity Validation (GH-219)</a></li><li class="chapter-item expanded "><a href="../examples/hex-forensics.html"><strong aria-hidden="true">199.</strong> Case Study: Hex Forensics — Binary Model Inspection</a></li><li class="chapter-item expanded "><a href="../examples/rosetta-stone.html"><strong aria-hidden="true">200.</strong> Case Study: Rosetta Stone — Universal Format Converter</a></li><li class="chapter-item expanded "><a href="../examples/validated-tensors.html"><strong aria-hidden="true">201.</strong> Case Study: Validated Tensors — Compile-Time Contracts</a></li><li class="chapter-item expanded "><a href="../examples/qwen-inference.html"><strong aria-hidden="true">202.</strong> Case Study: Qwen Inference with realizar</a></li><li class="chapter-item expanded "><a href="../examples/sharded-safetensors-serve.html"><strong aria-hidden="true">203.</strong> Case Study: Sharded SafeTensors Serving (GH-213)</a></li><li class="chapter-item expanded "><a href="../examples/model-merge-strategies.html"><strong aria-hidden="true">204.</strong> Case Study: Model Merge Strategies (GH-245)</a></li><li class="chapter-item expanded affix "><li class="part-title">Sprint-Based Development</li><li class="chapter-item expanded "><a href="../sprints/sprint-planning.html"><strong aria-hidden="true">205.</strong> Sprint Planning</a></li><li class="chapter-item expanded "><a href="../sprints/sprint-execution.html"><strong aria-hidden="true">206.</strong> Sprint Execution</a></li><li class="chapter-item expanded "><a href="../sprints/sprint-review.html"><strong aria-hidden="true">207.</strong> Sprint Review</a></li><li class="chapter-item expanded "><a href="../sprints/sprint-retrospective.html"><strong aria-hidden="true">208.</strong> Sprint Retrospective</a></li><li class="chapter-item expanded "><a href="../sprints/issue-management.html"><strong aria-hidden="true">209.</strong> Issue Management</a></li><li class="chapter-item expanded affix "><li class="part-title">Anti-Hallucination Enforcement</li><li class="chapter-item expanded "><a href="../anti-hallucination/test-backed-examples.html"><strong aria-hidden="true">210.</strong> Test-Backed Examples</a></li><li class="chapter-item expanded "><a href="../anti-hallucination/example-verification.html"><strong aria-hidden="true">211.</strong> Example Verification</a></li><li class="chapter-item expanded "><a href="../anti-hallucination/ci-validation.html"><strong aria-hidden="true">212.</strong> CI Validation</a></li><li class="chapter-item expanded "><a href="../anti-hallucination/documentation-testing.html"><strong aria-hidden="true">213.</strong> Documentation Testing</a></li><li class="chapter-item expanded affix "><li class="part-title">Tools and Setup</li><li class="chapter-item expanded "><a href="../tools/development-environment.html"><strong aria-hidden="true">214.</strong> Development Environment</a></li><li class="chapter-item expanded "><a href="../tools/cargo-test.html"><strong aria-hidden="true">215.</strong> cargo test</a></li><li class="chapter-item expanded "><a href="../tools/cargo-clippy.html"><strong aria-hidden="true">216.</strong> cargo clippy</a></li><li class="chapter-item expanded "><a href="../tools/cargo-fmt.html"><strong aria-hidden="true">217.</strong> cargo fmt</a></li><li class="chapter-item expanded "><a href="../tools/cargo-mutants.html"><strong aria-hidden="true">218.</strong> cargo mutants</a></li><li class="chapter-item expanded "><a href="../tools/proptest.html"><strong aria-hidden="true">219.</strong> proptest</a></li><li class="chapter-item expanded "><a href="../tools/criterion.html"><strong aria-hidden="true">220.</strong> criterion</a></li><li class="chapter-item expanded "><a href="../tools/pmat.html"><strong aria-hidden="true">221.</strong> pmat (Toyota AI Toolkit)</a></li><li class="chapter-item expanded "><a href="../tools/apr-cli.html"><strong aria-hidden="true">222.</strong> apr (APR Model Operations CLI)</a></li><li class="chapter-item expanded "><a href="../tools/apr-spec.html" class="active"><strong aria-hidden="true">223.</strong> APR Format Specification</a></li><li class="chapter-item expanded affix "><li class="part-title">Best Practices</li><li class="chapter-item expanded "><a href="../best-practices/error-handling.html"><strong aria-hidden="true">224.</strong> Error Handling</a></li><li class="chapter-item expanded "><a href="../best-practices/api-design.html"><strong aria-hidden="true">225.</strong> API Design</a></li><li class="chapter-item expanded "><a href="../best-practices/builder-pattern.html"><strong aria-hidden="true">226.</strong> Builder Pattern</a></li><li class="chapter-item expanded "><a href="../best-practices/type-safety.html"><strong aria-hidden="true">227.</strong> Type Safety</a></li><li class="chapter-item expanded "><a href="../best-practices/performance.html"><strong aria-hidden="true">228.</strong> Performance Considerations</a></li><li class="chapter-item expanded "><a href="../best-practices/documentation-standards.html"><strong aria-hidden="true">229.</strong> Documentation Standards</a></li><li class="chapter-item expanded affix "><li class="part-title">Metrics and Measurement</li><li class="chapter-item expanded "><a href="../metrics/test-coverage.html"><strong aria-hidden="true">230.</strong> Test Coverage</a></li><li class="chapter-item expanded "><a href="../metrics/mutation-score.html"><strong aria-hidden="true">231.</strong> Mutation Score</a></li><li class="chapter-item expanded "><a href="../metrics/cyclomatic-complexity.html"><strong aria-hidden="true">232.</strong> Cyclomatic Complexity</a></li><li class="chapter-item expanded "><a href="../metrics/code-churn.html"><strong aria-hidden="true">233.</strong> Code Churn</a></li><li class="chapter-item expanded "><a href="../metrics/build-times.html"><strong aria-hidden="true">234.</strong> Build Times</a></li><li class="chapter-item expanded "><a href="../metrics/tdg-breakdown.html"><strong aria-hidden="true">235.</strong> TDG Score Breakdown</a></li><li class="chapter-item expanded affix "><li class="part-title">Common Pitfalls</li><li class="chapter-item expanded "><a href="../pitfalls/skipping-tests.html"><strong aria-hidden="true">236.</strong> Skipping Tests</a></li><li class="chapter-item expanded "><a href="../pitfalls/insufficient-coverage.html"><strong aria-hidden="true">237.</strong> Insufficient Test Coverage</a></li><li class="chapter-item expanded "><a href="../pitfalls/ignoring-warnings.html"><strong aria-hidden="true">238.</strong> Ignoring Warnings</a></li><li class="chapter-item expanded "><a href="../pitfalls/over-mocking.html"><strong aria-hidden="true">239.</strong> Over-Mocking</a></li><li class="chapter-item expanded "><a href="../pitfalls/flaky-tests.html"><strong aria-hidden="true">240.</strong> Flaky Tests</a></li><li class="chapter-item expanded "><a href="../pitfalls/technical-debt.html"><strong aria-hidden="true">241.</strong> Technical Debt Accumulation</a></li><li class="chapter-item expanded affix "><li class="part-title">Appendix</li><li class="chapter-item expanded "><a href="../appendix/glossary.html"><strong aria-hidden="true">242.</strong> Glossary</a></li><li class="chapter-item expanded "><a href="../appendix/references.html"><strong aria-hidden="true">243.</strong> References</a></li><li class="chapter-item expanded "><a href="../appendix/further-reading.html"><strong aria-hidden="true">244.</strong> Further Reading</a></li><li class="chapter-item expanded "><a href="../appendix/contributing.html"><strong aria-hidden="true">245.</strong> Contributing to This Book</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">EXTREME TDD - The Aprender Guide to Zero-Defect Machine Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/aprender" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/aprender/edit/main/book/src/tools/apr-spec.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="apr-complete-specification"><a class="header" href="#apr-complete-specification">APR Complete Specification</a></h1>
<p><strong>Version</strong>: 2.0.0-draft
<strong>Status</strong>: Draft
<strong>Created</strong>: 2025-12-16
<strong>GitHub Issue</strong>: https://github.com/paiml/aprender/issues/119</p>
<hr />
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ol>
<li><a href="#1-abstract">Abstract</a></li>
<li><a href="#2-design-principles">Design Principles</a></li>
<li><a href="#3-apr-binary-format">APR Binary Format</a>
<ul>
<li><a href="#31-format-overview">3.1 Format Overview</a></li>
<li><a href="#32-header-32-bytes">3.2 Header</a></li>
<li><a href="#33-feature-flags">3.3 Feature Flags</a></li>
<li><a href="#34-metadata-section">3.4 Metadata Section</a></li>
<li><a href="#35-tensor-index-binary">3.5 Tensor Index</a></li>
<li><a href="#36-tensor-data-section">3.6 Tensor Data Section</a></li>
<li><a href="#37-footer-16-bytes">3.7 Footer</a></li>
<li><a href="#38-sharding-multi-file">3.8 Sharding</a></li>
<li><a href="#39-wasm-considerations">3.9 WASM Considerations</a></li>
</ul>
</li>
<li><a href="#4-cli-operations">CLI Operations</a>
<ul>
<li><a href="#41-command-overview">4.1 Command Overview</a></li>
<li><a href="#42-inspect-command">4.2 Inspect Command</a></li>
<li><a href="#43-debug-command-drama-mode">4.3 Debug Command</a></li>
<li><a href="#44-validate-command">4.4 Validate Command</a></li>
<li><a href="#45-diff-command">4.5 Diff Command</a></li>
<li><a href="#46-export-command">4.6 Export Command</a></li>
<li><a href="#47-import-command">4.7 Import Command</a></li>
<li><a href="#48-convert-command">4.8 Convert Command</a></li>
<li><a href="#49-merge-command">4.9 Merge Command</a></li>
<li><a href="#410-trace-command">4.10 Trace Command</a></li>
<li><a href="#411-lint-command">4.11 Lint Command</a></li>
<li><a href="#412-explain-command">4.12 Explain Command</a></li>
<li><a href="#413-tui-command">4.13 TUI Command</a></li>
</ul>
</li>
<li><a href="#5-auxiliary-data-patterns">Auxiliary Data Patterns</a>
<ul>
<li><a href="#51-json-metadata-pattern">5.1 JSON Metadata Pattern</a></li>
<li><a href="#52-common-auxiliary-data-types">5.2 Common Auxiliary Data Types</a></li>
<li><a href="#53-tensor-storage-for-large-data">5.3 Tensor Storage for Large Data</a></li>
<li><a href="#54-best-practices">5.4 Best Practices</a></li>
</ul>
</li>
<li><a href="#6-format-comparison">Format Comparison</a></li>
<li><a href="#7-error-handling">Error Handling</a></li>
<li><a href="#8-configuration">Configuration</a></li>
<li><a href="#9-quality-gates">Quality Gates</a></li>
<li><a href="#10-multi-format-conversion-specification">Multi-Format Conversion Specification</a>
<ul>
<li><a href="#101-supported-input-formats">10.1 Supported Input Formats</a></li>
<li><a href="#102-safetensors-huggingface">10.2 SafeTensors (HuggingFace)</a></li>
<li><a href="#103-pytorch-pt-pth-bin">10.3 PyTorch (.pt, .pth, .bin)</a></li>
<li><a href="#104-gguf-llamacpp">10.4 GGUF (llama.cpp)</a></li>
<li><a href="#105-ggml-legacy">10.5 GGML (Legacy)</a></li>
<li><a href="#106-onnx">10.6 ONNX</a></li>
<li><a href="#107-tensorflowkeras">10.7 TensorFlow/Keras</a></li>
<li><a href="#108-tensor-name-mapping">10.8 Tensor Name Mapping</a></li>
<li><a href="#109-expected-tensor-statistics">10.9 Expected Tensor Statistics</a></li>
<li><a href="#1010-conversion-validation-requirements">10.10 Conversion Validation Requirements</a></li>
<li><a href="#1011-known-failure-modes">10.11 Known Failure Modes</a></li>
</ul>
</li>
<li><a href="#11-conversion-qa-checklist-25-points">Conversion QA Checklist (25 Points)</a>
<ul>
<li><a href="#a-structural-integrity-5-points">A. Structural Integrity</a></li>
<li><a href="#b-layer-norm-validation-5-points">B. Layer Norm Validation</a></li>
<li><a href="#c-attentionlinear-validation-5-points">C. Attention/Linear Validation</a></li>
<li><a href="#d-embedding-validation-5-points">D. Embedding Validation</a></li>
<li><a href="#e-functional-validation-5-points">E. Functional Validation</a></li>
</ul>
</li>
<li><a href="#12-automated-conversion-validation">Automated Conversion Validation</a></li>
<li><a href="#13-falsification-qa-checklist-legacy">Falsification QA Checklist (Legacy)</a></li>
<li><a href="#14-implementation-roadmap">Implementation Roadmap</a></li>
<li><a href="#15-references">References</a></li>
<li><a href="#16-appendices">Appendices</a></li>
</ol>
<hr />
<h2 id="1-abstract"><a class="header" href="#1-abstract">1. Abstract</a></h2>
<p>APR (Aprender Portable Representation) is a WASM-first model serialization format for machine learning models. This specification covers:</p>
<ul>
<li><strong>APR Binary Format</strong>: Binary format supporting web-scale models (10B+ parameters) with tensor alignment, LZ4 streaming compression, and multi-file sharding</li>
<li><strong>CLI Operations</strong>: Comprehensive tooling for inspect, debug, trace, export, convert, import, merge, diff, and validate operations</li>
<li><strong>Auxiliary Data</strong>: Patterns for storing vocabulary, tokenizer config, mel filterbanks, and other model-specific data</li>
</ul>
<hr />
<h2 id="2-design-principles"><a class="header" href="#2-design-principles">2. Design Principles</a></h2>
<h3 id="21-wasm-first-design"><a class="header" href="#21-wasm-first-design">2.1 WASM-First Design</a></h3>
<ol>
<li><strong>WASM-first</strong>: Must work in <code>wasm32-unknown-unknown</code> without Emscripten</li>
<li><strong>Progressive enhancement</strong>: Features degrade gracefully (mmap → heap, compression → raw)</li>
<li><strong>Single format</strong>: ONE format specification, no versioning complexity</li>
<li><strong>Zero-copy where possible</strong>: Alignment enables direct tensor access</li>
<li><strong>Streaming</strong>: Support chunked loading for large models</li>
</ol>
<h3 id="22-toyota-way-alignment"><a class="header" href="#22-toyota-way-alignment">2.2 Toyota Way Alignment</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Principle</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>Genchi Genbutsu</strong></td><td>Go and see the actual model data, not abstractions</td></tr>
<tr><td><strong>Visualization</strong></td><td>Make model internals visible for debugging</td></tr>
<tr><td><strong>Jidoka</strong></td><td>Stop on quality issues (corrupted models, NaN weights)</td></tr>
<tr><td><strong>Kaizen</strong></td><td>Continuous improvement via diff and merge operations</td></tr>
<tr><td><strong>Standardization</strong></td><td>Consistent CLI interface across all operations</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="3-apr-binary-format"><a class="header" href="#3-apr-binary-format">3. APR Binary Format</a></h2>
<h3 id="31-format-overview"><a class="header" href="#31-format-overview">3.1 Format Overview</a></h3>
<pre><code>┌─────────────────────────────────────────────────────────────┐
│ Header (32 bytes, aligned)                                  │
├─────────────────────────────────────────────────────────────┤
│ Metadata Section (JSON, variable length)                    │
├─────────────────────────────────────────────────────────────┤
│ Tensor Index (binary, variable length)                      │
├─────────────────────────────────────────────────────────────┤
│ [Padding to 64-byte alignment]                              │
├─────────────────────────────────────────────────────────────┤
│ Tensor Data Section (aligned tensors)                       │
│   ├── Tensor 0 (64-byte aligned)                           │
│   ├── Tensor 1 (64-byte aligned)                           │
│   └── ...                                                   │
├─────────────────────────────────────────────────────────────┤
│ Footer (16 bytes)                                           │
└─────────────────────────────────────────────────────────────┘
</code></pre>
<h3 id="32-header-32-bytes"><a class="header" href="#32-header-32-bytes">3.2 Header (32 bytes)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Offset</th><th>Size</th><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>magic</td><td><code>APR2</code> (0x41505232)</td></tr>
<tr><td>4</td><td>2</td><td>version_major</td><td>Format major version (2)</td></tr>
<tr><td>6</td><td>2</td><td>version_minor</td><td>Format minor version (0)</td></tr>
<tr><td>8</td><td>4</td><td>flags</td><td>Feature flags (see below)</td></tr>
<tr><td>12</td><td>4</td><td>metadata_offset</td><td>Offset to metadata section</td></tr>
<tr><td>16</td><td>4</td><td>metadata_size</td><td>Size of metadata section</td></tr>
<tr><td>20</td><td>4</td><td>index_offset</td><td>Offset to tensor index</td></tr>
<tr><td>24</td><td>4</td><td>index_size</td><td>Size of tensor index</td></tr>
<tr><td>28</td><td>4</td><td>data_offset</td><td>Offset to tensor data section</td></tr>
</tbody></table>
</div>
<h3 id="33-feature-flags"><a class="header" href="#33-feature-flags">3.3 Feature Flags</a></h3>
<pre><code class="language-rust">bitflags! {
    pub struct AprFlags: u32 {
        const COMPRESSED     = 0b0000_0001;  // LZ4 compression enabled
        const ALIGNED_64     = 0b0000_0010;  // 64-byte tensor alignment
        const ALIGNED_32     = 0b0000_0100;  // 32-byte tensor alignment (GGUF compat)
        const SHARDED        = 0b0000_1000;  // Multi-file model
        const ENCRYPTED      = 0b0001_0000;  // AES-256-GCM encryption
        const SIGNED         = 0b0010_0000;  // Ed25519 signature present
        const QUANTIZED      = 0b0100_0000;  // Contains quantized tensors
        const STREAMING      = 0b1000_0000;  // Streaming-optimized layout
    }
}</code></pre>
<h3 id="34-metadata-section"><a class="header" href="#34-metadata-section">3.4 Metadata Section</a></h3>
<p>JSON object containing model configuration and auxiliary data.</p>
<h4 id="required-keys"><a class="header" href="#required-keys">Required Keys</a></h4>
<pre><code class="language-json">{
  &quot;apr_version&quot;: &quot;2.0.0&quot;,
  &quot;model_type&quot;: &quot;whisper&quot;,
  &quot;architecture&quot;: {
    &quot;n_vocab&quot;: 51865,
    &quot;n_audio_ctx&quot;: 1500,
    &quot;n_text_ctx&quot;: 448,
    &quot;n_mels&quot;: 80,
    &quot;n_audio_layer&quot;: 4,
    &quot;n_text_layer&quot;: 4,
    &quot;n_audio_head&quot;: 6,
    &quot;n_text_head&quot;: 6,
    &quot;n_audio_state&quot;: 384,
    &quot;n_text_state&quot;: 384
  }
}
</code></pre>
<h4 id="optional-keys"><a class="header" href="#optional-keys">Optional Keys</a></h4>
<pre><code class="language-json">{
  &quot;vocab&quot;: [&quot;&lt;|endoftext|&gt;&quot;, &quot;&lt;|startoftranscript|&gt;&quot;, &quot;...&quot;],
  &quot;mel_filterbank&quot;: [0.0, 0.0, &quot;...&quot;],
  &quot;mel_filterbank_shape&quot;: [80, 201],
  &quot;tokenizer_config&quot;: { &quot;...&quot; },
  &quot;model_card&quot;: { &quot;...&quot; },
  &quot;quantization&quot;: {
    &quot;method&quot;: &quot;Q8_0&quot;,
    &quot;bits_per_weight&quot;: 8.5
  }
}
</code></pre>
<h3 id="35-tensor-index-binary"><a class="header" href="#35-tensor-index-binary">3.5 Tensor Index (Binary)</a></h3>
<h4 id="index-header-8-bytes"><a class="header" href="#index-header-8-bytes">Index Header (8 bytes)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Offset</th><th>Size</th><th>Field</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>tensor_count</td></tr>
<tr><td>4</td><td>4</td><td>reserved</td></tr>
</tbody></table>
</div>
<h4 id="tensor-entry-variable-40-bytes-each"><a class="header" href="#tensor-entry-variable-40-bytes-each">Tensor Entry (variable, ~40+ bytes each)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Offset</th><th>Size</th><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>2</td><td>name_len</td><td>Length of tensor name</td></tr>
<tr><td>2</td><td>name_len</td><td>name</td><td>UTF-8 tensor name</td></tr>
<tr><td>+0</td><td>1</td><td>dtype</td><td>Data type enum</td></tr>
<tr><td>+1</td><td>1</td><td>n_dims</td><td>Number of dimensions (1-8)</td></tr>
<tr><td>+2</td><td>8×n_dims</td><td>dims</td><td>Dimension sizes (u64 each)</td></tr>
<tr><td>+n</td><td>8</td><td>offset</td><td>Byte offset in data section</td></tr>
<tr><td>+n+8</td><td>8</td><td>size</td><td>Compressed size (or raw size)</td></tr>
<tr><td>+n+16</td><td>8</td><td>raw_size</td><td>Uncompressed size (0 if not compressed)</td></tr>
<tr><td>+n+24</td><td>4</td><td>flags</td><td>Per-tensor flags</td></tr>
</tbody></table>
</div>
<h4 id="data-type-enum"><a class="header" href="#data-type-enum">Data Type Enum</a></h4>
<pre><code class="language-rust">#[repr(u8)]
pub enum DType {
    F32 = 0, F16 = 1, BF16 = 2, I8 = 3, I16 = 4, I32 = 5, I64 = 6, U8 = 7,
    Q8_0 = 16, Q4_0 = 17, Q4_1 = 18, Q5_0 = 19, Q5_1 = 20,
}</code></pre>
<h3 id="36-tensor-data-section"><a class="header" href="#36-tensor-data-section">3.6 Tensor Data Section</a></h3>
<p>Tensors stored contiguously with alignment padding.</p>
<ul>
<li><strong>Default</strong>: 64-byte alignment (cache-line optimal)</li>
<li><strong>GGUF-compatible</strong>: 32-byte alignment</li>
<li><strong>Compression</strong>: Per-tensor LZ4 block compression (64KB blocks)</li>
</ul>
<h3 id="37-footer-16-bytes"><a class="header" href="#37-footer-16-bytes">3.7 Footer (16 bytes)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Offset</th><th>Size</th><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>4</td><td>crc32</td><td>CRC32 of all preceding bytes</td></tr>
<tr><td>4</td><td>4</td><td>magic_end</td><td><code>2RPA</code> (reverse magic)</td></tr>
<tr><td>8</td><td>8</td><td>file_size</td><td>Total file size for validation</td></tr>
</tbody></table>
</div>
<h3 id="38-sharding-multi-file"><a class="header" href="#38-sharding-multi-file">3.8 Sharding (Multi-File)</a></h3>
<p>For models &gt; 2GB, use manifest + shard files.</p>
<pre><code class="language-json">{
  &quot;apr_version&quot;: &quot;2.0.0&quot;,
  &quot;sharded&quot;: true,
  &quot;shard_count&quot;: 4,
  &quot;shards&quot;: [
    {&quot;file&quot;: &quot;model-00001-of-00004.apr&quot;, &quot;size&quot;: 2147483648, &quot;crc32&quot;: &quot;...&quot;},
    {&quot;file&quot;: &quot;model-00002-of-00004.apr&quot;, &quot;size&quot;: 2147483648, &quot;crc32&quot;: &quot;...&quot;}
  ],
  &quot;tensor_shard_map&quot;: {
    &quot;encoder.conv1.weight&quot;: 0,
    &quot;decoder.token_embedding.weight&quot;: 1
  }
}
</code></pre>
<h3 id="39-wasm-considerations"><a class="header" href="#39-wasm-considerations">3.9 WASM Considerations</a></h3>
<pre><code class="language-rust">pub trait StreamingLoader {
    fn load_metadata(&amp;mut self) -&gt; Result&lt;AprMetadata&gt;;
    fn load_index(&amp;mut self) -&gt; Result&lt;Vec&lt;TensorDescriptor&gt;&gt;;
    fn load_tensor(&amp;mut self, name: &amp;str) -&gt; Result&lt;Tensor&gt;;
    fn prefetch(&amp;mut self, names: &amp;[&amp;str]);
}</code></pre>
<hr />
<h2 id="4-cli-operations"><a class="header" href="#4-cli-operations">4. CLI Operations</a></h2>
<h3 id="41-command-overview"><a class="header" href="#41-command-overview">4.1 Command Overview</a></h3>
<pre><code>apr - APR Model Operations Tool

COMMANDS:
    inspect     Inspect model metadata, vocab, and structure
    debug       Simple debugging output (&quot;drama&quot; mode)
    validate    Validate model integrity
    diff        Compare two models
    tensors     List tensor information
    export      Export model to other formats
    import      Import from external formats
    convert     Convert between model types
    merge       Merge multiple models
    trace       Trace model operations with renacer
    lint        Check for best practices and conventions
    explain     Explain errors, architecture, and tensors
    tui         Interactive terminal UI for exploration
</code></pre>
<h3 id="42-inspect-command"><a class="header" href="#42-inspect-command">4.2 Inspect Command</a></h3>
<pre><code class="language-bash">$ apr inspect whisper.apr

=== whisper.apr ===
Type:        NeuralCustom (Whisper ASR)
Version:     1.0
Size:        1.5 GB (compressed: 890 MB)
Parameters:  39,000,000
Vocab Size:  51,865
Flags:       COMPRESSED | SIGNED
Checksum:    0xA1B2C3D4 (valid)
</code></pre>
<p>Options: <code>--vocab</code>, <code>--filters</code>, <code>--json</code>, <code>--full</code></p>
<h3 id="421-visual-inspection"><a class="header" href="#421-visual-inspection">4.2.1 Visual Inspection</a></h3>
<p>For suspect tensors, generate an in-terminal histogram to visualize distributions (e.g., detecting shifted means):</p>
<pre><code class="language-bash">$ apr tensors model.apr --hist encoder.layer_norm.weight

Distribution: encoder.layer_norm.weight (shape: [384])
Min: 10.4  Max: 12.1  Mean: 11.2  Std: 0.2

       |          *
       |         ***
  50%  |        *****
       |       *******
       |      *********
       +------------------
       10.0      11.2      12.5
</code></pre>
<h3 id="43-debug-command-drama-mode"><a class="header" href="#43-debug-command-drama-mode">4.3 Debug Command (&quot;Drama&quot; Mode)</a></h3>
<pre><code class="language-bash">$ apr debug whisper.apr --drama

====[ DRAMA: whisper.apr ]====

ACT I: THE HEADER
  Scene 1: Magic bytes... APRN (applause!)
  Scene 2: Version check... 1.0 (standing ovation!)

ACT II: THE METADATA
  Scene 1: Parameters... 39,000,000 (a cast of millions!)

ACT III: THE VERDICT
  CURTAIN CALL: Model is PRODUCTION READY!
</code></pre>
<p>Options: <code>--hex</code>, <code>--strings</code>, <code>--limit</code></p>
<h3 id="44-validate-command"><a class="header" href="#44-validate-command">4.4 Validate Command</a></h3>
<pre><code class="language-bash">$ apr validate model.apr --quality

=== 100-Point Quality Assessment ===

Structure (25 pts):     24/25
Security (25 pts):      20/25
Weights (25 pts):       25/25
Metadata (25 pts):      22/25

TOTAL: 91/100 (EXCELLENT)
</code></pre>
<h3 id="45-diff-command"><a class="header" href="#45-diff-command">4.5 Diff Command</a></h3>
<pre><code class="language-bash">$ apr diff model_v1.apr model_v2.apr

Similarity: 94.2%
Weight Changes: Max delta 0.0234, L2 distance 1.234
Vocab Changes: Added 42 tokens, Removed 3 tokens
</code></pre>
<h4 id="diff-vs-reference"><a class="header" href="#diff-vs-reference">Diff vs Reference</a></h4>
<p>Compare an APR model against a raw <code>.safetensors</code> reference to detect translation drift:</p>
<pre><code class="language-bash">$ apr diff model.apr source.safetensors --tensor-mapping mapping.json

# Output:
# encoder.conv1.weight: MATCH (delta &lt; 1e-6)
# encoder.layer_norm.weight: DRIFT (delta = 10.2) !!!
</code></pre>
<h3 id="46-export-command"><a class="header" href="#46-export-command">4.6 Export Command</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Extension</th><th>Use Case</th></tr></thead><tbody>
<tr><td>ONNX</td><td><code>.onnx</code></td><td>Cross-framework inference</td></tr>
<tr><td>SafeTensors</td><td><code>.safetensors</code></td><td>HuggingFace ecosystem</td></tr>
<tr><td>GGUF</td><td><code>.gguf</code></td><td>llama.cpp / local inference</td></tr>
<tr><td>TorchScript</td><td><code>.pt</code></td><td>PyTorch deployment</td></tr>
</tbody></table>
</div>
<pre><code class="language-bash">apr export model.apr --format gguf --quantize q4_0 --output model.gguf
</code></pre>
<h3 id="47-import-command"><a class="header" href="#47-import-command">4.7 Import Command</a></h3>
<pre><code class="language-bash">apr import hf://openai/whisper-tiny --output whisper.apr
apr import model.safetensors --from safetensors --output model.apr
</code></pre>
<h3 id="48-convert-command"><a class="header" href="#48-convert-command">4.8 Convert Command</a></h3>
<p>Model optimization and size reduction operations.</p>
<pre><code class="language-bash">apr convert model.apr --quantize q8_0 --output model_q8.apr
apr convert model.apr --precision fp16 --output model_fp16.apr
</code></pre>
<h4 id="481-size-reduction-techniques"><a class="header" href="#481-size-reduction-techniques">4.8.1 Size Reduction Techniques</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Technique</th><th>Flag</th><th>Reduction</th><th>Quality</th><th>Reversible</th></tr></thead><tbody>
<tr><td><strong>Quantization</strong></td><td><code>--quantize</code></td><td>2-8x</td><td>Low loss</td><td>No</td></tr>
<tr><td><strong>Compression</strong></td><td><code>--compress</code></td><td>1.2-2x</td><td>Lossless</td><td>Yes</td></tr>
<tr><td><strong>Pruning</strong></td><td><code>--prune</code></td><td>2-10x</td><td>Medium</td><td>No</td></tr>
<tr><td><strong>Distillation</strong></td><td><code>--distill</code></td><td>2-10x</td><td>Medium</td><td>No</td></tr>
<tr><td><strong>Low-rank (SVD)</strong></td><td><code>--lowrank</code></td><td>2-4x</td><td>Low loss</td><td>No</td></tr>
<tr><td><strong>Sparsity</strong></td><td><code>--sparse</code></td><td>2-5x</td><td>Low loss</td><td>Yes</td></tr>
</tbody></table>
</div>
<h5 id="quantization"><a class="header" href="#quantization">Quantization</a></h5>
<p>Reduce precision of weights:</p>
<pre><code class="language-bash"># Integer quantization
apr convert model.apr --quantize int8 -o model-int8.apr      # 4x smaller
apr convert model.apr --quantize int4 -o model-int4.apr      # 8x smaller

# Float quantization
apr convert model.apr --quantize fp16 -o model-fp16.apr      # 2x smaller
apr convert model.apr --quantize bf16 -o model-bf16.apr      # 2x smaller

# GGUF-style quantization
apr convert model.apr --quantize q4_k_m -o model-q4km.apr    # 4.5 bits/weight
apr convert model.apr --quantize q8_0 -o model-q8.apr        # 8 bits/weight
</code></pre>
<h5 id="compression"><a class="header" href="#compression">Compression</a></h5>
<p>Lossless compression of tensor data:</p>
<pre><code class="language-bash"># LZ4 (fast, default)
apr convert model.apr --compress lz4 -o model-lz4.apr

# Zstd (better ratio)
apr convert model.apr --compress zstd -o model-zstd.apr
apr convert model.apr --compress zstd:19 -o model-zstd19.apr  # Max compression

# Combine with quantization
apr convert model.apr --quantize int8 --compress zstd -o model-int8-zstd.apr
</code></pre>
<h5 id="pruning"><a class="header" href="#pruning">Pruning</a></h5>
<p>Remove low-magnitude weights:</p>
<pre><code class="language-bash"># Unstructured pruning (sparse tensors)
apr convert model.apr --prune 0.5 -o model-pruned.apr        # 50% sparsity

# Structured pruning (remove entire neurons/heads)
apr convert model.apr --prune-heads 2 -o model-pruned.apr    # Remove 2 attention heads
apr convert model.apr --prune-layers 1 -o model-pruned.apr   # Remove 1 layer

# Magnitude-based with threshold
apr convert model.apr --prune-threshold 0.01 -o model-pruned.apr
</code></pre>
<h5 id="distillation"><a class="header" href="#distillation">Distillation</a></h5>
<p>Train smaller model from larger (requires reference data):</p>
<pre><code class="language-bash"># Distill to smaller architecture
apr convert model-large.apr --distill tiny --data train.jsonl -o model-tiny.apr

# Layer reduction
apr convert model.apr --distill-layers 4 --data train.jsonl -o model-4layer.apr

# Knowledge distillation with temperature
apr convert model.apr --distill small --temperature 2.0 --data train.jsonl -o model-small.apr
</code></pre>
<p><strong>Note</strong>: Distillation requires training data and compute. Use <code>--epochs</code> and <code>--lr</code> to control.</p>
<h5 id="low-rank-factorization"><a class="header" href="#low-rank-factorization">Low-Rank Factorization</a></h5>
<p>Decompose weight matrices using SVD/LoRA:</p>
<pre><code class="language-bash"># SVD decomposition
apr convert model.apr --lowrank svd --rank 64 -o model-svd.apr

# LoRA-style decomposition
apr convert model.apr --lowrank lora --rank 16 -o model-lora.apr

# Target specific layers
apr convert model.apr --lowrank svd --rank 32 --target &quot;*.fc1.weight&quot; -o model-svd.apr
</code></pre>
<h5 id="sparsity-encoding"><a class="header" href="#sparsity-encoding">Sparsity Encoding</a></h5>
<p>Efficient storage for sparse tensors:</p>
<pre><code class="language-bash"># CSR format for sparse tensors
apr convert model.apr --sparse csr --threshold 0.001 -o model-sparse.apr

# Block sparsity (GPU-friendly)
apr convert model.apr --sparse block:4 -o model-block-sparse.apr
</code></pre>
<h4 id="482-combination-examples"><a class="header" href="#482-combination-examples">4.8.2 Combination Examples</a></h4>
<pre><code class="language-bash"># Maximum compression pipeline
apr convert model.apr \
  --quantize int4 \
  --prune 0.3 \
  --compress zstd:19 \
  -o model-optimized.apr
# Result: ~20x smaller than original

# WASM-optimized (fast decode, small size)
apr convert model.apr \
  --quantize int8 \
  --compress lz4 \
  -o model-wasm.apr
# Result: ~5x smaller, fast streaming decode

# Quality-preserving compression
apr convert model.apr \
  --quantize fp16 \
  --lowrank svd --rank 128 \
  --compress zstd \
  -o model-quality.apr
# Result: ~3x smaller, minimal quality loss
</code></pre>
<h4 id="483-size-comparison-table"><a class="header" href="#483-size-comparison-table">4.8.3 Size Comparison Table</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Technique</th><th>Whisper Tiny</th><th>Whisper Base</th><th>LLaMA 7B</th></tr></thead><tbody>
<tr><td>Original (f32)</td><td>145 MB</td><td>290 MB</td><td>26 GB</td></tr>
<tr><td>fp16</td><td>73 MB</td><td>145 MB</td><td>13 GB</td></tr>
<tr><td>int8</td><td>37 MB</td><td>73 MB</td><td>6.5 GB</td></tr>
<tr><td>int4</td><td>19 MB</td><td>37 MB</td><td>3.3 GB</td></tr>
<tr><td>int4 + zstd</td><td>15 MB</td><td>29 MB</td><td>2.6 GB</td></tr>
<tr><td>int4 + prune50%</td><td>10 MB</td><td>19 MB</td><td>1.7 GB</td></tr>
</tbody></table>
</div>
<h4 id="484-quality-validation-pre-vs-post"><a class="header" href="#484-quality-validation-pre-vs-post">4.8.4 Quality Validation (Pre vs Post)</a></h4>
<p>Compare model quality before and after optimization:</p>
<pre><code class="language-bash"># Compare outputs between original and optimized
apr validate model.apr model-optimized.apr --quality

Quality Comparison: model.apr vs model-optimized.apr
═══════════════════════════════════════════════════════════════
                          Original    Optimized    Δ
Tensor count              167         167          0
Total params              39.0M       39.0M        0
Non-zero params           39.0M       19.5M        -50%
Size                      145 MB      15 MB        -89%

Output Comparison (10 test inputs):
  Mean L2 distance:       0.0234      (threshold: 0.1)  ✓ PASS
  Max L2 distance:        0.0891      (threshold: 0.5)  ✓ PASS
  Cosine similarity:      0.9987      (threshold: 0.99) ✓ PASS

Layer-by-layer drift:
  encoder.conv1:          0.001       ✓
  encoder.layer_norm:     0.002       ✓
  decoder.layer_norm:     0.089       ⚠ (highest drift)

VERDICT: ✓ PASS - Optimized model within quality tolerance
═══════════════════════════════════════════════════════════════
</code></pre>
<h5 id="canary-inputs"><a class="header" href="#canary-inputs">Canary Inputs</a></h5>
<p>Define reference inputs with expected outputs for regression testing:</p>
<pre><code class="language-bash"># Create canary test suite
apr canary create model.apr --input test.wav --output canary.json

# Validate optimized model against canary
apr canary check model-optimized.apr --canary canary.json

Canary Test Results:
  Input: test.wav
  Expected: &quot;The quick brown fox jumps over the lazy dog&quot;
  Original:  &quot;The quick brown fox jumps over the lazy dog&quot;  ✓
  Optimized: &quot;The quick brown fox jumps over the lazy dog&quot;  ✓

  Token-level accuracy: 100%
  Character error rate: 0.0%
</code></pre>
<h5 id="automatic-quality-gates"><a class="header" href="#automatic-quality-gates">Automatic Quality Gates</a></h5>
<pre><code class="language-bash"># Fail optimization if quality degrades beyond threshold
apr convert model.apr --quantize int4 --prune 0.5 \
  --quality-check \
  --max-drift 0.1 \
  --canary canary.json \
  -o model-optimized.apr

# If quality check fails:
# ERROR: Quality gate failed
#   - L2 drift: 0.24 (max: 0.1)
#   - Canary &quot;test.wav&quot; failed: expected &quot;fox&quot; got &quot;box&quot;
# Use --force to ignore quality gates
</code></pre>
<h4 id="485-payload-tracing-radioactive-tracer"><a class="header" href="#485-payload-tracing-radioactive-tracer">4.8.5 Payload Tracing (Radioactive Tracer)</a></h4>
<p>Trace a payload through the model step-by-step, like a radioactive tracer in medicine:</p>
<pre><code class="language-bash">apr trace model.apr --input test.wav --trace-payload

Payload Trace: test.wav → model.apr
═══════════════════════════════════════════════════════════════

Step 1: Audio Input
  Shape: [1, 480000]  (30s @ 16kHz)
  Stats: mean=0.002, std=0.15, range=[-0.98, 0.97]

Step 2: Mel Spectrogram
  Shape: [1, 80, 3000]
  Stats: mean=-4.2, std=2.1
  ▁▂▃▄▅▆▇█▇▆▅▄▃▂▁  (frequency distribution)

Step 3: encoder.conv1
  Shape: [1, 384, 3000]
  Stats: mean=0.12, std=0.34
  Time: 2.3ms
  ⚠ Activation spike at position 1247 (value: 12.4)

Step 4: encoder.conv2
  Shape: [1, 384, 1500]
  Stats: mean=0.08, std=0.29
  Time: 1.8ms

Step 5: encoder.positional_embedding
  Shape: [1, 1500, 384]
  Stats: mean=0.08, std=0.31

Step 6: encoder.layers.0.self_attn
  Shape: [1, 1500, 384]
  Attention pattern:
  ░░░░░░░░░░░░░░░░░░░░
  ░░░░████░░░░░░░░░░░░  ← attending to positions 40-80
  ░░░░░░░░░░░░████░░░░

  ... (layers 1-3) ...

Step 10: encoder.layer_norm
  Shape: [1, 1500, 384]
  Stats: mean=0.00, std=1.02  ✓ (properly normalized)

Step 11: decoder.token_embedding (SOT token)
  Shape: [1, 1, 384]
  Token: &lt;|startoftranscript|&gt; (50258)

  ... (decoder steps) ...

Step 47: Output Logits
  Shape: [1, 12, 51865]
  Top predictions:
    1. &quot;The&quot; (0.94)
    2. &quot;A&quot; (0.03)
    3. &quot;This&quot; (0.01)

═══════════════════════════════════════════════════════════════
Total time: 142ms | Peak memory: 312MB | Tokens generated: 12
</code></pre>
<h5 id="comparing-traces-diff-mode"><a class="header" href="#comparing-traces-diff-mode">Comparing Traces (Diff Mode)</a></h5>
<p>Compare payload path between two models:</p>
<pre><code class="language-bash">apr trace model.apr model-optimized.apr --input test.wav --diff

Trace Diff: model.apr vs model-optimized.apr
═══════════════════════════════════════════════════════════════

Step    Layer                    Original     Optimized    Drift
─────   ─────                    ────────     ─────────    ─────
1       audio_input              ████████     ████████     0.000
2       mel_spectrogram          ████████     ████████     0.000
3       encoder.conv1            ████████     ███████░     0.012
4       encoder.conv2            ████████     ███████░     0.018
...
10      encoder.layer_norm       ████████     ██████░░     0.089 ⚠
11      decoder.token_embed      ████████     ████████     0.001
...
47      output_logits            ████████     ███████░     0.023

Divergence detected at: encoder.layer_norm (step 10)
  Original mean:  0.0023
  Optimized mean: 0.0892

Recommendation: Check layer norm weight quantization
</code></pre>
<h5 id="anomaly-detection"><a class="header" href="#anomaly-detection">Anomaly Detection</a></h5>
<p>Automatically detect unusual activations:</p>
<pre><code class="language-bash">apr trace model.apr --input test.wav --detect-anomalies

Anomaly Report:
═══════════════════════════════════════════════════════════════

⚠ ANOMALY at encoder.layers.2.self_attn (step 8)
  - Activation explosion: max=847.3 (expected &lt;10)
  - Possible cause: NaN propagation or weight corruption
  - Affected tokens: positions 120-135

⚠ ANOMALY at decoder.layer_norm (step 15)
  - Dead neurons: 12% of outputs are exactly 0
  - Possible cause: Aggressive pruning or ReLU saturation

✓ No anomalies in remaining 45 layers
</code></pre>
<h5 id="interactive-trace-mode-tui"><a class="header" href="#interactive-trace-mode-tui">Interactive Trace Mode (TUI)</a></h5>
<pre><code class="language-bash">apr trace model.apr --input test.wav --interactive
</code></pre>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│  Payload Trace: test.wav                        [Interactive]   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─ Pipeline ───────────────────────────────────────────────┐  │
│  │                                                          │  │
│  │  [Audio] ──▶ [Mel] ──▶ [Conv1] ──▶ [Conv2] ──▶ ...      │  │
│  │     ✓         ✓         ✓          ✓                     │  │
│  │                                    ▲                      │  │
│  │                                    │ YOU ARE HERE         │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Current Layer: encoder.conv2 ───────────────────────────┐  │
│  │ Input:  [1, 384, 3000]   Output: [1, 384, 1500]          │  │
│  │ Params: 589,824          Time: 1.8ms                     │  │
│  │                                                          │  │
│  │ Activation Distribution:                                 │  │
│  │     ▁▂▃▄▅▆▇█▇▆▅▄▃▂▁                                      │  │
│  │   -2.0            0            2.0                       │  │
│  │                                                          │  │
│  │ Weight Stats: mean=0.002, std=0.04                       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Payload Snapshot ───────────────────────────────────────┐  │
│  │ [0.12, 0.34, -0.21, 0.08, 0.45, -0.11, 0.02, ...]       │  │
│  │ mean=0.08  std=0.29  min=-1.2  max=2.1                  │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ [←/→] step  [Enter] inspect  [d]iff  [e]xport  [q]uit   4/47   │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h5 id="export-trace-for-analysis"><a class="header" href="#export-trace-for-analysis">Export Trace for Analysis</a></h5>
<pre><code class="language-bash"># Export full trace to JSON
apr trace model.apr --input test.wav --export trace.json

# Export to Chrome trace format (for chrome://tracing)
apr trace model.apr --input test.wav --export trace.perfetto

# Export intermediate activations for debugging
apr trace model.apr --input test.wav --dump-activations ./activations/
</code></pre>
<h4 id="486-debugging-conversion"><a class="header" href="#486-debugging-conversion">4.8.6 Debugging Conversion</a></h4>
<pre><code class="language-bash"># Analyze source tensor stats without converting
apr convert model.safetensors --analyze-source --arch whisper

# Output:
# [PASS] encoder.conv1.weight: mean=0.003 (expected ~0.0)
# [FAIL] encoder.layer_norm.weight: mean=11.2 (expected ~1.0) -&gt; SOURCE ALREADY CORRUPT?
</code></pre>
<h3 id="49-merge-command"><a class="header" href="#49-merge-command">4.9 Merge Command</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>Description</th></tr></thead><tbody>
<tr><td><code>average</code></td><td>Average weights (ensemble)</td></tr>
<tr><td><code>weighted</code></td><td>Weighted average by performance</td></tr>
<tr><td><code>ties</code></td><td>TIES merging (trim, elect, sign)</td></tr>
<tr><td><code>dare</code></td><td>DARE merging (drop and rescale)</td></tr>
<tr><td><code>slerp</code></td><td>Spherical linear interpolation</td></tr>
</tbody></table>
</div>
<pre><code class="language-bash">apr merge model1.apr model2.apr --strategy ties --output merged.apr
</code></pre>
<h3 id="410-trace-command"><a class="header" href="#410-trace-command">4.10 Trace Command</a></h3>
<pre><code class="language-bash">$ apr trace model.apr --input sample.wav

Layer                          Time (ms)   Memory (MB)
encoder.conv1                      12.3         45.2
decoder.attention.0                15.4         12.3
TOTAL                             142.5        312.4
</code></pre>
<h3 id="411-lint-command"><a class="header" href="#411-lint-command">4.11 Lint Command</a></h3>
<p>Static analysis for best practices, conventions, and &quot;soft&quot; requirements. Unlike <code>validate</code> (which checks for corruption/invalidity), <code>lint</code> checks for <em>quality</em> and <em>standardization</em>.</p>
<pre><code class="language-bash">$ apr lint model.apr

[WARN] Metadata: Missing 'license' field
[WARN] Metadata: Missing 'model_card'
[INFO] Tensor Naming: 'encoder.w' should be 'encoder.weight' for auto-mapping
[INFO] Efficiency: 12 tensors could be aligned to 64 bytes (currently 32)
</code></pre>
<p><strong>Falsifiable Guarantees (Must Fail If):</strong></p>
<ul>
<li><strong>Naming</strong>: Any tensor name not matching canonical schema (Section 10.8) raises INFO/WARN.</li>
<li><strong>Metadata</strong>: Missing <code>license</code>, <code>model_card</code>, or <code>provenance</code> raises WARN.</li>
<li><strong>Efficiency</strong>: Tensors unaligned to 64 bytes raise INFO.</li>
<li><strong>Compression</strong>: Uncompressed tensors &gt;1MB raise INFO.</li>
</ul>
<h3 id="412-explain-command"><a class="header" href="#412-explain-command">4.12 Explain Command</a></h3>
<p>Provides human-readable context, architectural explanations, and error troubleshooting.</p>
<h4 id="explain-model-architecture"><a class="header" href="#explain-model-architecture">Explain Model Architecture</a></h4>
<pre><code class="language-bash">$ apr explain model.apr

This is a **Whisper (Tiny)** model.
- **Purpose**: Automatic Speech Recognition (ASR)
- **Architecture**: Encoder-Decoder Transformer
- **Input**: 80-channel Mel spectrograms
- **Output**: Text tokens (multilingual)
</code></pre>
<h4 id="explain-specific-tensor"><a class="header" href="#explain-specific-tensor">Explain Specific Tensor</a></h4>
<pre><code class="language-bash">$ apr explain model.apr --tensor encoder.conv1.weight

**encoder.conv1.weight**
- **Role**: Initial feature extraction (Audio -&gt; Latent)
- **Shape**: [384, 80, 3] (Filters, Input Channels, Kernel Size)
- **Stats**: Mean 0.002, Std 0.04 (Healthy)
</code></pre>
<h4 id="explain-error-codes"><a class="header" href="#explain-error-codes">Explain Error Codes</a></h4>
<pre><code class="language-bash">$ apr explain E002

**E002: Corrupted Data**
The payload checksum does not match the header.
- **Common Causes**: Interrupted download, bit rot, disk error.
- **Troubleshooting**:
  1. Run `apr validate --checksum` to verify.
  2. Check source file integrity (MD5/SHA256).
</code></pre>
<p><strong>Falsifiable Guarantees:</strong></p>
<ul>
<li><strong>Unknown Error</strong>: <code>apr explain E999</code> must return &quot;Unknown Error Code&quot; (not crash).</li>
<li><strong>Unknown Tensor</strong>: <code>apr explain --tensor nonexistent</code> must list fuzzy matches.</li>
<li><strong>Architecture</strong>: Must correctly identify all supported architectures (Section 10).</li>
</ul>
<h3 id="413-tui-command"><a class="header" href="#413-tui-command">4.13 TUI Command</a></h3>
<p>Interactive terminal UI for model exploration, statistics visualization, and comparison. Built with <code>ratatui</code> and <code>trueno-viz</code>.</p>
<pre><code class="language-bash">$ apr tui model.apr
$ apr tui model1.apr model2.apr --compare
</code></pre>
<h4 id="4131-graph-view"><a class="header" href="#4131-graph-view">4.13.1 Graph View</a></h4>
<p>ASCII/Unicode graph visualization of model architecture:</p>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│  Model: whisper-tiny.apr                          [Graph View]  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌─────────┐    ┌─────────┐    ┌─────────┐                    │
│   │  Audio  │───▶│  Conv1  │───▶│  Conv2  │                    │
│   │ [80,3000]│    │[384,80,3]│   │[384,384]│                    │
│   └─────────┘    └─────────┘    └─────────┘                    │
│                                      │                          │
│                                      ▼                          │
│   ┌──────────────────────────────────────────────────────┐     │
│   │              Encoder Layers (×4)                      │     │
│   │  ┌────────┐   ┌────────┐   ┌────────┐   ┌────────┐   │     │
│   │  │Self-Attn│──▶│  LN   │──▶│  FFN   │──▶│  LN    │   │     │
│   │  └────────┘   └────────┘   └────────┘   └────────┘   │     │
│   └──────────────────────────────────────────────────────┘     │
│                           │                                     │
│                           ▼                                     │
│   ┌──────────────────────────────────────────────────────┐     │
│   │              Decoder Layers (×4)                      │     │
│   │  ┌────────┐   ┌────────┐   ┌────────┐   ┌────────┐   │     │
│   │  │Self-Attn│──▶│Cross-Attn│─▶│  FFN   │──▶│  LN    │   │     │
│   │  └────────┘   └────────┘   └────────┘   └────────┘   │     │
│   └──────────────────────────────────────────────────────┘     │
│                           │                                     │
│                           ▼                                     │
│                    ┌─────────────┐                              │
│                    │   Output    │                              │
│                    │  [51865]    │                              │
│                    └─────────────┘                              │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ [g]raph [s]tats [c]ompare [t]ensors [h]ist [q]uit    Page 1/3  │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h4 id="4132-descriptive-statistics-view"><a class="header" href="#4132-descriptive-statistics-view">4.13.2 Descriptive Statistics View</a></h4>
<p>Live-updating tensor statistics dashboard:</p>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│  Model: whisper-tiny.apr                          [Stats View]  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─ Overview ───────────────────────────────────────────────┐  │
│  │ Total Params: 39,000,000    Tensors: 167    Size: 145MB  │  │
│  │ Quantization: f32           Vocab: 51,865   Arch: Whisper│  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Layer Norm Health ──────────────────────────────────────┐  │
│  │ Tensor                        Mean    Std    Status      │  │
│  │ encoder.layer_norm.weight     1.48    0.32   ✓ OK        │  │
│  │ decoder.layer_norm.weight    11.10    0.21   ✗ BAD       │  │
│  │ encoder.layers.0.ln.weight    1.22    0.28   ✓ OK        │  │
│  │ encoder.layers.1.ln.weight    1.35    0.31   ✓ OK        │  │
│  │ encoder.layers.2.ln.weight    1.41    0.29   ✓ OK        │  │
│  │ encoder.layers.3.ln.weight   10.94    0.18   ✗ BAD       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Weight Distribution ────────────────────────────────────┐  │
│  │                                                          │  │
│  │  Attention:  ████████████████████  Mean: 0.002  ✓        │  │
│  │  FFN:        ███████████████████   Mean: 0.001  ✓        │  │
│  │  Embedding:  █████████████████     Mean: 0.015  ✓        │  │
│  │  LayerNorm:  ██████████████████████████████████  ✗       │  │
│  │              ↑ outlier: decoder.layer_norm.weight        │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Validation Score ───────────────────────────────────────┐  │
│  │ ████████████████████░░░░  21/25 FAIL                     │  │
│  │ Critical: 2 Layer Norm weights outside [0.5, 3.0]        │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ [g]raph [s]tats [c]ompare [t]ensors [h]ist [q]uit    Page 1/1  │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h4 id="4133-comparison-view"><a class="header" href="#4133-comparison-view">4.13.3 Comparison View</a></h4>
<p>Side-by-side model comparison with diff highlighting:</p>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│  Comparing: model_v1.apr vs model_v2.apr         [Compare View] │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─ Summary ────────────────────────────────────────────────┐  │
│  │ Similarity: 94.2%    Changed: 12 tensors    New: 0       │  │
│  │ Max Δ: 0.0234        L2 Dist: 1.234         Removed: 0   │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Tensor Comparison ──────────────────────────────────────┐  │
│  │ Tensor                    v1 Mean   v2 Mean   Δ          │  │
│  │ encoder.conv1.weight      0.0023    0.0025    +0.0002    │  │
│  │ encoder.layer_norm.wt     1.4832    1.4901    +0.0069    │  │
│  │ decoder.layer_norm.wt    11.0983    1.0521   -10.0462 !! │  │
│  │ decoder.layers.0.fc1.wt   0.0012    0.0014    +0.0002    │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Distribution Comparison ────────────────────────────────┐  │
│  │                                                          │  │
│  │  decoder.layer_norm.weight:                              │  │
│  │                                                          │  │
│  │  v1: ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░████  (mean=11.1)   │  │
│  │  v2: ░░░░░░░░░░████░░░░░░░░░░░░░░░░░░░░░░  (mean=1.05)   │  │
│  │      ──────────────────────────────────────              │  │
│  │      0         5         10        15                    │  │
│  │                                                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
│  ┌─ Validation Score Comparison ────────────────────────────┐  │
│  │ v1: ████████████████████░░░░  21/25 FAIL                 │  │
│  │ v2: ████████████████████████  25/25 PASS  ← IMPROVED     │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ [g]raph [s]tats [c]ompare [t]ensors [h]ist [q]uit    Page 1/1  │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h4 id="4134-histogram-view"><a class="header" href="#4134-histogram-view">4.13.4 Histogram View</a></h4>
<p>Per-tensor distribution visualization with sparklines:</p>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│  Tensor: decoder.layer_norm.weight               [Histogram]    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Shape: [384]    dtype: f32    Size: 1.5 KB                    │
│  Mean: 11.0983   Std: 0.2134   Min: 10.42   Max: 12.01         │
│                                                                 │
│  Distribution:                                                  │
│                                                                 │
│   150 │                    ▄▄▄▄                                 │
│       │                  ▄██████▄                               │
│   100 │                ▄██████████▄                             │
│       │              ▄██████████████▄                           │
│    50 │            ▄██████████████████▄                         │
│       │          ▄██████████████████████▄                       │
│     0 ├──────────────────────────────────────────────           │
│       10.0      10.5      11.0      11.5      12.0              │
│                                                                 │
│  ⚠ ANOMALY DETECTED:                                           │
│  Expected mean ≈ 1.0 for LayerNorm weight                       │
│  Actual mean = 11.0983 (10x higher than expected)               │
│                                                                 │
│  Possible causes:                                               │
│  • Incorrect tensor scaling during conversion                   │
│  • Wrong tensor mapped to this name                             │
│  • Source model corruption                                      │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ [←/→] prev/next tensor  [Enter] select  [q] back    12/167     │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h4 id="4135-keybindings"><a class="header" href="#4135-keybindings">4.13.5 Keybindings</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody>
<tr><td><code>g</code></td><td>Switch to Graph view</td></tr>
<tr><td><code>s</code></td><td>Switch to Stats view</td></tr>
<tr><td><code>c</code></td><td>Switch to Compare view (if 2 models)</td></tr>
<tr><td><code>t</code></td><td>Switch to Tensor list</td></tr>
<tr><td><code>h</code></td><td>Switch to Histogram view</td></tr>
<tr><td><code>Enter</code></td><td>Select/drill down</td></tr>
<tr><td><code>Esc</code></td><td>Back/cancel</td></tr>
<tr><td><code>↑/↓</code></td><td>Navigate list</td></tr>
<tr><td><code>←/→</code></td><td>Previous/next page or tensor</td></tr>
<tr><td><code>/</code></td><td>Search tensors</td></tr>
<tr><td><code>?</code></td><td>Help</td></tr>
<tr><td><code>q</code></td><td>Quit</td></tr>
</tbody></table>
</div>
<h4 id="4136-implementation"><a class="header" href="#4136-implementation">4.13.6 Implementation</a></h4>
<p><strong>Crates</strong>:</p>
<ul>
<li><code>ratatui = &quot;0.28&quot;</code> - Terminal UI framework</li>
<li><code>crossterm = &quot;0.28&quot;</code> - Cross-platform terminal handling</li>
<li><code>trueno-viz</code> - Tensor visualization utilities (optional)</li>
</ul>
<p><strong>Feature Flag</strong>:</p>
<pre><code class="language-toml">[features]
tui = [&quot;ratatui&quot;, &quot;crossterm&quot;]
</code></pre>
<hr />
<h2 id="5-auxiliary-data-patterns"><a class="header" href="#5-auxiliary-data-patterns">5. Auxiliary Data Patterns</a></h2>
<h3 id="51-json-metadata-pattern"><a class="header" href="#51-json-metadata-pattern">5.1 JSON Metadata Pattern</a></h3>
<pre><code>[APR magic] → [metadata_len] → [JSON metadata] → [tensors] → [CRC32]
                                     ↑
                            Auxiliary data here
</code></pre>
<h3 id="52-common-auxiliary-data-types"><a class="header" href="#52-common-auxiliary-data-types">5.2 Common Auxiliary Data Types</a></h3>
<h4 id="vocabulary-nlp"><a class="header" href="#vocabulary-nlp">Vocabulary (NLP)</a></h4>
<pre><code class="language-json">{&quot;vocab&quot;: [&quot;&lt;pad&gt;&quot;, &quot;&lt;unk&gt;&quot;, &quot;the&quot;, &quot;...&quot;], &quot;vocab_size&quot;: 51865}
</code></pre>
<h4 id="mel-filterbank-audio"><a class="header" href="#mel-filterbank-audio">Mel Filterbank (Audio)</a></h4>
<pre><code class="language-json">{&quot;mel_filterbank&quot;: [0.0, &quot;...&quot;], &quot;mel_filterbank_shape&quot;: [80, 201]}
</code></pre>
<h4 id="tokenizer-config"><a class="header" href="#tokenizer-config">Tokenizer Config</a></h4>
<pre><code class="language-json">{&quot;tokenizer_config&quot;: {&quot;type&quot;: &quot;bpe&quot;, &quot;unk_token&quot;: &quot;&lt;|unk|&gt;&quot;, &quot;eos_token&quot;: &quot;&lt;|endoftext|&gt;&quot;}}
</code></pre>
<h4 id="embedded-tokenizer-pmat-apr-tok-001---v120"><a class="header" href="#embedded-tokenizer-pmat-apr-tok-001---v120">Embedded Tokenizer (PMAT-APR-TOK-001 - v1.2.0)</a></h4>
<p>APR files now automatically embed tokenizers during conversion, making them truly portable single-file models:</p>
<pre><code class="language-json">{
  &quot;tokenizer.vocabulary&quot;: [&quot;&lt;|endoftext|&gt;&quot;, &quot;&lt;|startoftranscript|&gt;&quot;, &quot;the&quot;, &quot;...&quot;],
  &quot;tokenizer.vocab_size&quot;: 151643,
  &quot;tokenizer.bos_token_id&quot;: 151643,
  &quot;tokenizer.eos_token_id&quot;: 151645,
  &quot;tokenizer.model_type&quot;: &quot;BPE&quot;
}
</code></pre>
<p><strong>Conversion Support:</strong></p>
<ul>
<li>SafeTensors → APR: Reads sibling <code>tokenizer.json</code> and embeds vocabulary</li>
<li>GGUF → APR: Extracts vocabulary from GGUF metadata tensors</li>
<li>Inference: Decodes tokens using embedded vocabulary (no external files needed)</li>
</ul>
<h4 id="image-preprocessing-vision"><a class="header" href="#image-preprocessing-vision">Image Preprocessing (Vision)</a></h4>
<pre><code class="language-json">{&quot;image_config&quot;: {&quot;image_size&quot;: 224, &quot;mean&quot;: [0.485, 0.456, 0.406]}}
</code></pre>
<h4 id="label-mapping-classification"><a class="header" href="#label-mapping-classification">Label Mapping (Classification)</a></h4>
<pre><code class="language-json">{&quot;labels&quot;: {&quot;0&quot;: &quot;cat&quot;, &quot;1&quot;: &quot;dog&quot;}, &quot;num_labels&quot;: 2}
</code></pre>
<h3 id="53-tensor-storage-for-large-data"><a class="header" href="#53-tensor-storage-for-large-data">5.3 Tensor Storage for Large Data</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Data Size</th><th>JSON Metadata</th><th>Tensor</th></tr></thead><tbody>
<tr><td>&lt; 100KB</td><td>Preferred</td><td>Overkill</td></tr>
<tr><td>100KB - 1MB</td><td>Acceptable</td><td>Good</td></tr>
<tr><td>&gt; 1MB</td><td>Avoid</td><td>Preferred</td></tr>
</tbody></table>
</div>
<p>Naming convention: <code>audio.mel_filterbank</code>, <code>text.token_embedding</code></p>
<h3 id="54-best-practices"><a class="header" href="#54-best-practices">5.4 Best Practices</a></h3>
<ol>
<li><strong>Use standard keys</strong>: Follow HuggingFace/GGUF conventions</li>
<li><strong>Include shape info</strong>: Always store shape alongside flattened arrays</li>
<li><strong>Version metadata</strong>: Include <code>format_version</code> for compatibility</li>
<li><strong>Document units</strong>: Specify if values are normalized, in Hz, etc.</li>
<li><strong>Validate on load</strong>: Check array lengths match expected shapes</li>
</ol>
<hr />
<h2 id="6-format-comparison"><a class="header" href="#6-format-comparison">6. Format Comparison</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>APR1</th><th>APR2</th><th>GGUF</th><th>SafeTensors</th></tr></thead><tbody>
<tr><td>WASM-first</td><td>Yes</td><td>Yes</td><td>No</td><td>Yes</td></tr>
<tr><td>Tensor alignment</td><td>No</td><td>Yes (64B)</td><td>Yes (32B)</td><td>Yes</td></tr>
<tr><td>Compression</td><td>No</td><td>LZ4</td><td>No</td><td>No</td></tr>
<tr><td>Quantization</td><td>Metadata</td><td>Native</td><td>Native</td><td>No</td></tr>
<tr><td>Sharding</td><td>No</td><td>Yes</td><td>No</td><td>Yes</td></tr>
<tr><td>Streaming</td><td>No</td><td>Yes</td><td>No</td><td>No</td></tr>
<tr><td>JSON metadata</td><td>Yes</td><td>Yes</td><td>Typed KV</td><td>JSON</td></tr>
<tr><td>CRC32</td><td>Yes</td><td>Yes</td><td>No</td><td>No</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="7-error-handling"><a class="header" href="#7-error-handling">7. Error Handling</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Category</th><th>Description</th></tr></thead><tbody>
<tr><td>E001</td><td>FORMAT</td><td>Invalid file format</td></tr>
<tr><td>E002</td><td>CORRUPT</td><td>Corrupted data</td></tr>
<tr><td>E003</td><td>VERSION</td><td>Unsupported version</td></tr>
<tr><td>E004</td><td>CHECKSUM</td><td>Checksum mismatch</td></tr>
<tr><td>E005</td><td>DECRYPT</td><td>Decryption failed</td></tr>
<tr><td>E006</td><td>SIGNATURE</td><td>Signature invalid</td></tr>
<tr><td>E007</td><td>IO</td><td>File I/O error</td></tr>
<tr><td>E008</td><td>MEMORY</td><td>Out of memory</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="8-configuration"><a class="header" href="#8-configuration">8. Configuration</a></h2>
<pre><code class="language-toml"># ~/.config/apr/config.toml

[defaults]
output_format = &quot;text&quot;
color = true

[inspect]
show_vocab = true
max_tokens_display = 20

[debug]
drama_mode = false
hex_limit = 256

[validate]
strict = true
require_signature = false
</code></pre>
<hr />
<h2 id="9-quality-gates"><a class="header" href="#9-quality-gates">9. Quality Gates</a></h2>
<pre><code class="language-toml"># .pmat-gates.toml
[apr-ops]
test_coverage_minimum = 95.0
max_cyclomatic_complexity = 10
satd_maximum = 0
mutation_score_minimum = 85.0
max_inspect_latency_ms = 100
</code></pre>
<hr />
<h2 id="10-multi-format-conversion-specification"><a class="header" href="#10-multi-format-conversion-specification">10. Multi-Format Conversion Specification</a></h2>
<h3 id="101-supported-input-formats"><a class="header" href="#101-supported-input-formats">10.1 Supported Input Formats</a></h3>
<p>APR supports conversion from all major ML model formats:</p>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Extensions</th><th>Source</th><th>Priority</th><th>Status</th></tr></thead><tbody>
<tr><td><strong>SafeTensors</strong></td><td><code>.safetensors</code></td><td>HuggingFace</td><td>P0</td><td>✅ Implemented</td></tr>
<tr><td><strong>PyTorch</strong></td><td><code>.pt</code>, <code>.pth</code>, <code>.bin</code></td><td>PyTorch</td><td>P0</td><td>🔲 Planned</td></tr>
<tr><td><strong>GGUF</strong></td><td><code>.gguf</code></td><td>llama.cpp</td><td>P1</td><td>🔲 Planned</td></tr>
<tr><td><strong>GGML</strong></td><td><code>.bin</code></td><td>Legacy llama.cpp</td><td>P2</td><td>🔲 Planned</td></tr>
<tr><td><strong>ONNX</strong></td><td><code>.onnx</code></td><td>ONNX Runtime</td><td>P1</td><td>🔲 Planned</td></tr>
<tr><td><strong>TensorFlow</strong></td><td><code>.pb</code>, <code>.h5</code>, SavedModel</td><td>TensorFlow/Keras</td><td>P2</td><td>🔲 Planned</td></tr>
<tr><td><strong>Core ML</strong></td><td><code>.mlmodel</code>, <code>.mlpackage</code></td><td>Apple</td><td>P3</td><td>🔲 Future</td></tr>
<tr><td><strong>TensorRT</strong></td><td><code>.engine</code>, <code>.plan</code></td><td>NVIDIA</td><td>P3</td><td>🔲 Future</td></tr>
</tbody></table>
</div>
<p><strong>Critical Lesson Learned</strong>: A single incorrect tensor conversion (e.g., <code>decoder.layer_norm.weight</code> with mean=11 instead of ~1) can cause complete model failure while passing basic structural checks.</p>
<hr />
<h3 id="102-safetensors-huggingface"><a class="header" href="#102-safetensors-huggingface">10.2 SafeTensors (HuggingFace)</a></h3>
<p><strong>Status</strong>: ✅ Primary implementation</p>
<p><strong>File Structure</strong>:</p>
<pre><code>model.safetensors
├── Header (8 bytes): JSON length (u64 LE)
├── JSON Metadata: tensor names, shapes, dtypes, offsets
└── Tensor Data: contiguous f32/f16/bf16 arrays
</code></pre>
<p><strong>CLI Usage</strong>:</p>
<pre><code class="language-bash">apr convert model.safetensors -o model.apr
apr convert model.safetensors --quantize int8 -o model-int8.apr

# From HuggingFace Hub
apr convert hf://openai/whisper-tiny -o whisper-tiny.apr
</code></pre>
<p><strong>Data Types</strong>:
| SafeTensors Type | APR Conversion |
|------------------|----------------|
| F32 | Direct copy |
| F16 | Convert to f32 or keep as f16 |
| BF16 | Convert to f32 |
| I8 | Keep as int8 (quantized) |</p>
<p><strong>Crate</strong>: <code>safetensors = &quot;0.4&quot;</code></p>
<hr />
<h3 id="103-pytorch-pt-pth-bin"><a class="header" href="#103-pytorch-pt-pth-bin">10.3 PyTorch (.pt, .pth, .bin)</a></h3>
<p><strong>Status</strong>: 🔲 Planned (P0)</p>
<p><strong>File Structure</strong>:</p>
<pre><code>model.pt (ZIP archive)
├── data.pkl          # Python pickle with tensor metadata
├── data/0            # Raw tensor bytes
├── data/1
└── ...
</code></pre>
<p><strong>Security Warning</strong>: PyTorch files use Python pickle, which can execute arbitrary code. APR conversion MUST:</p>
<ol>
<li>Use <code>pickle</code> in restricted mode (no arbitrary imports)</li>
<li>Validate tensor shapes before allocation</li>
<li>Reject files with suspicious pickle opcodes</li>
</ol>
<p><strong>CLI Usage</strong>:</p>
<pre><code class="language-bash">apr convert model.pt -o model.apr --arch whisper
apr convert model.pth -o model.apr --arch llama

# With state_dict key prefix
apr convert model.pt -o model.apr --prefix &quot;model.&quot;
</code></pre>
<p><strong>Implementation Notes</strong>:</p>
<ul>
<li>Use <code>zip</code> crate for archive extraction</li>
<li>Implement minimal pickle parser (BINGET, MARK, TUPLE, etc.)</li>
<li>Map <code>torch.float32</code> → f32, <code>torch.float16</code> → f16</li>
<li>Handle both full checkpoints and state_dict-only files</li>
</ul>
<p><strong>Crate</strong>: Custom pickle parser (no Python dependency)</p>
<hr />
<h3 id="104-gguf-llamacpp"><a class="header" href="#104-gguf-llamacpp">10.4 GGUF (llama.cpp)</a></h3>
<p><strong>Status</strong>: 🔲 Planned (P1)</p>
<p><strong>File Structure</strong>:</p>
<pre><code>model.gguf
├── Magic (4 bytes): &quot;GGUF&quot;
├── Version (4 bytes): u32
├── Tensor Count (8 bytes): u64
├── Metadata KV Count (8 bytes): u64
├── Metadata KV Pairs: typed key-value store
├── Tensor Infos: name, dims, type, offset
└── Tensor Data: aligned, possibly quantized
</code></pre>
<p><strong>CLI Usage</strong>:</p>
<pre><code class="language-bash">apr convert model.gguf -o model.apr
apr convert model-q4_k_m.gguf -o model.apr --dequantize f32
apr convert model.gguf -o model.apr --keep-quantization
</code></pre>
<p><strong>Quantization Types</strong>:
| GGUF Type | Bits | APR Handling |
|-----------|------|--------------|
| F32 | 32 | Direct copy |
| F16 | 16 | Convert or keep |
| Q8_0 | 8 | Dequantize or convert to APR int8 |
| Q4_0 | 4 | Dequantize to f32 |
| Q4_K_M | 4.5 | Dequantize to f32 |
| Q5_K_M | 5.5 | Dequantize to f32 |
| Q6_K | 6 | Dequantize to f32 |</p>
<p><strong>Metadata Mapping</strong>:
| GGUF Key | APR Metadata |
|----------|--------------|
| <code>general.architecture</code> | <code>model_type</code> |
| <code>general.name</code> | <code>model_name</code> |
| <code>llama.context_length</code> | <code>context_length</code> |
| <code>llama.embedding_length</code> | <code>hidden_size</code> |
| <code>tokenizer.ggml.tokens</code> | Vocabulary |</p>
<p><strong>Crate</strong>: Custom GGUF parser</p>
<hr />
<h3 id="105-ggml-legacy"><a class="header" href="#105-ggml-legacy">10.5 GGML (Legacy)</a></h3>
<p><strong>Status</strong>: 🔲 Planned (P2)</p>
<p><strong>File Structure</strong>:</p>
<pre><code>model.bin
├── Magic (4 bytes): &quot;lmgg&quot; or &quot;tjgg&quot;
├── Hyperparameters: model-specific struct
├── Vocabulary: token strings
└── Tensors: name + dims + data (unaligned)
</code></pre>
<p><strong>CLI Usage</strong>:</p>
<pre><code class="language-bash">apr convert model.bin -o model.apr --format ggml --arch llama
</code></pre>
<p><strong>Notes</strong>:</p>
<ul>
<li>Legacy format, prefer GGUF for new conversions</li>
<li>No standardized metadata format</li>
<li>Architecture must be specified manually</li>
</ul>
<hr />
<h3 id="106-onnx"><a class="header" href="#106-onnx">10.6 ONNX</a></h3>
<p><strong>Status</strong>: 🔲 Planned (P1)</p>
<p><strong>File Structure</strong>:</p>
<pre><code>model.onnx (Protobuf)
├── ModelProto
│   ├── graph: GraphProto
│   │   ├── node[]: operators
│   │   ├── input[]: model inputs
│   │   ├── output[]: model outputs
│   │   └── initializer[]: weight tensors
│   └── metadata_props: key-value pairs
</code></pre>
<p><strong>CLI Usage</strong>:</p>
<pre><code class="language-bash">apr convert model.onnx -o model.apr
apr convert model.onnx -o model.apr --opset 17
</code></pre>
<p><strong>Data Types</strong>:
| ONNX Type | APR Conversion |
|-----------|----------------|
| FLOAT | f32 |
| FLOAT16 | f16 |
| BFLOAT16 | f32 (convert) |
| INT8 | int8 |
| UINT8 | int8 (reinterpret) |</p>
<p><strong>Crate</strong>: <code>onnx-pb = &quot;0.1&quot;</code> or custom protobuf parser</p>
<hr />
<h3 id="107-tensorflowkeras"><a class="header" href="#107-tensorflowkeras">10.7 TensorFlow/Keras</a></h3>
<p><strong>Status</strong>: 🔲 Planned (P2)</p>
<p><strong>Supported Formats</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Description</th><th>CLI Flag</th></tr></thead><tbody>
<tr><td>SavedModel</td><td>Directory with <code>saved_model.pb</code></td><td><code>--format savedmodel</code></td></tr>
<tr><td>HDF5</td><td>Keras <code>.h5</code> files</td><td><code>--format h5</code></td></tr>
<tr><td>Frozen Graph</td><td>Single <code>.pb</code> file</td><td><code>--format frozen</code></td></tr>
<tr><td>TFLite</td><td><code>.tflite</code> mobile format</td><td><code>--format tflite</code></td></tr>
</tbody></table>
</div>
<p><strong>CLI Usage</strong>:</p>
<pre><code class="language-bash">apr convert saved_model/ -o model.apr --format savedmodel
apr convert model.h5 -o model.apr --format h5
apr convert model.tflite -o model.apr --format tflite
</code></pre>
<p><strong>Notes</strong>:</p>
<ul>
<li>HDF5 requires <code>hdf5</code> crate</li>
<li>SavedModel requires protobuf parsing</li>
<li>TFLite uses FlatBuffers</li>
</ul>
<hr />
<h3 id="108-tensor-name-mapping"><a class="header" href="#108-tensor-name-mapping">10.8 Tensor Name Mapping</a></h3>
<p>Each source format uses different naming conventions. APR standardizes to a canonical form:</p>
<h4 id="whisper-model-mapping"><a class="header" href="#whisper-model-mapping">Whisper Model Mapping</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Source Format</th><th>Source Name</th><th>APR Name</th></tr></thead><tbody>
<tr><td>SafeTensors</td><td><code>model.encoder.conv1.weight</code></td><td><code>encoder.conv1.weight</code></td></tr>
<tr><td>SafeTensors</td><td><code>model.encoder.embed_positions.weight</code></td><td><code>encoder.positional_embedding</code></td></tr>
<tr><td>SafeTensors</td><td><code>model.decoder.embed_tokens.weight</code></td><td><code>decoder.token_embedding</code></td></tr>
<tr><td>PyTorch</td><td><code>encoder.conv1.weight</code></td><td><code>encoder.conv1.weight</code></td></tr>
<tr><td>GGUF</td><td><code>encoder.conv1.weight</code></td><td><code>encoder.conv1.weight</code></td></tr>
<tr><td>ONNX</td><td><code>/encoder/conv1/weight</code></td><td><code>encoder.conv1.weight</code></td></tr>
</tbody></table>
</div>
<h4 id="llama-model-mapping"><a class="header" href="#llama-model-mapping">LLaMA Model Mapping</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Source Format</th><th>Source Name</th><th>APR Name</th></tr></thead><tbody>
<tr><td>SafeTensors</td><td><code>model.embed_tokens.weight</code></td><td><code>token_embedding</code></td></tr>
<tr><td>SafeTensors</td><td><code>model.layers.0.self_attn.q_proj.weight</code></td><td><code>layers.0.attn.q_proj.weight</code></td></tr>
<tr><td>GGUF</td><td><code>token_embd.weight</code></td><td><code>token_embedding</code></td></tr>
<tr><td>GGUF</td><td><code>blk.0.attn_q.weight</code></td><td><code>layers.0.attn.q_proj.weight</code></td></tr>
</tbody></table>
</div>
<h4 id="full-huggingface-whisper-mapping"><a class="header" href="#full-huggingface-whisper-mapping">Full HuggingFace Whisper Mapping</a></h4>
<div class="table-wrapper"><table><thead><tr><th>HuggingFace Name</th><th>APR Name</th></tr></thead><tbody>
<tr><td><code>model.encoder.conv1.weight</code></td><td><code>encoder.conv1.weight</code></td></tr>
<tr><td><code>model.encoder.conv1.bias</code></td><td><code>encoder.conv1.bias</code></td></tr>
<tr><td><code>model.encoder.conv2.weight</code></td><td><code>encoder.conv2.weight</code></td></tr>
<tr><td><code>model.encoder.conv2.bias</code></td><td><code>encoder.conv2.bias</code></td></tr>
<tr><td><code>model.encoder.embed_positions.weight</code></td><td><code>encoder.positional_embedding</code></td></tr>
<tr><td><code>model.encoder.layer_norm.weight</code></td><td><code>encoder.layer_norm.weight</code></td></tr>
<tr><td><code>model.encoder.layer_norm.bias</code></td><td><code>encoder.layer_norm.bias</code></td></tr>
<tr><td><code>model.encoder.layers.N.self_attn_layer_norm.weight</code></td><td><code>encoder.layers.N.self_attn_layer_norm.weight</code></td></tr>
<tr><td><code>model.encoder.layers.N.self_attn.q_proj.weight</code></td><td><code>encoder.layers.N.self_attn.q_proj.weight</code></td></tr>
<tr><td><code>model.decoder.embed_tokens.weight</code></td><td><code>decoder.token_embedding</code></td></tr>
<tr><td><code>model.decoder.embed_positions.weight</code></td><td><code>decoder.positional_embedding</code></td></tr>
<tr><td><code>model.decoder.layer_norm.weight</code></td><td><code>decoder.layer_norm.weight</code></td></tr>
<tr><td><code>model.decoder.layer_norm.bias</code></td><td><code>decoder.layer_norm.bias</code></td></tr>
<tr><td><code>model.decoder.layers.N.self_attn_layer_norm.weight</code></td><td><code>decoder.layers.N.self_attn_layer_norm.weight</code></td></tr>
<tr><td><code>model.decoder.layers.N.encoder_attn_layer_norm.weight</code></td><td><code>decoder.layers.N.encoder_attn_layer_norm.weight</code></td></tr>
<tr><td><code>model.decoder.layers.N.final_layer_norm.weight</code></td><td><code>decoder.layers.N.final_layer_norm.weight</code></td></tr>
</tbody></table>
</div>
<hr />
<h3 id="109-expected-tensor-statistics"><a class="header" href="#109-expected-tensor-statistics">10.9 Expected Tensor Statistics</a></h3>
<p><strong>Layer Norm Weights (gamma)</strong> - MUST have mean ≈ 1.0:</p>
<pre><code>Tensor                                   Expected Mean   Acceptable Range
encoder.layer_norm.weight                1.0 - 2.0       [0.5, 3.0]
decoder.layer_norm.weight                1.0 - 2.0       [0.5, 3.0]
*.self_attn_layer_norm.weight            1.0 - 2.0       [0.5, 3.0]
*.encoder_attn_layer_norm.weight         1.0 - 2.0       [0.5, 3.0]
*.final_layer_norm.weight                1.0 - 2.0       [0.5, 3.0]
</code></pre>
<p><strong>Layer Norm Bias (beta)</strong> - MUST have mean ≈ 0.0:</p>
<pre><code>Tensor                                   Expected Mean   Acceptable Range
*.layer_norm.bias                        0.0             [-0.5, 0.5]
</code></pre>
<p><strong>Attention/Linear Weights</strong> - Should have mean ≈ 0.0:</p>
<pre><code>Tensor                                   Expected Mean   Expected Std
*.q_proj.weight                          ~0.0            0.02 - 0.10
*.k_proj.weight                          ~0.0            0.02 - 0.10
*.v_proj.weight                          ~0.0            0.02 - 0.10
*.out_proj.weight                        ~0.0            0.02 - 0.10
*.fc1.weight                             ~0.0            0.02 - 0.05
*.fc2.weight                             ~0.0            0.02 - 0.05
</code></pre>
<p><strong>Embeddings</strong>:</p>
<pre><code>Tensor                                   Expected Mean   Expected Std
token_embedding                          ~0.0            0.02 - 0.05
positional_embedding                     ~0.0            0.01 - 0.02
</code></pre>
<h3 id="1010-conversion-validation-requirements"><a class="header" href="#1010-conversion-validation-requirements">10.10 Conversion Validation Requirements</a></h3>
<ol>
<li><strong>Shape Validation</strong>: Every tensor must match expected shape for model architecture</li>
<li><strong>Value Validation</strong>: Every tensor must have statistics within expected ranges</li>
<li><strong>Reference Comparison</strong>: Converted model must produce outputs within tolerance of HF reference</li>
<li><strong>Inline Validation (Strict Mode)</strong>: The <code>apr convert</code> tool MUST run the statistical checks (Section 10.9) <em>as tensors are being written</em>.
<ul>
<li><strong>Default Behavior</strong>: If a tensor violates the &quot;Acceptable Range&quot; (e.g., LayerNorm mean &gt; 3.0), the conversion <strong>aborts</strong> with an error.</li>
<li><strong>Override</strong>: Use <code>--force</code> or <code>--relaxed</code> to bypass this check.</li>
<li><strong>Justification</strong>: Better to fail early than produce a &quot;zombie&quot; model.</li>
</ul>
</li>
</ol>
<h3 id="1011-known-failure-modes"><a class="header" href="#1011-known-failure-modes">10.11 Known Failure Modes</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Failure</th><th>Symptom</th><th>Root Cause</th><th>Troubleshooting</th></tr></thead><tbody>
<tr><td>LN weight mean=11</td><td>Repetitive token output (e.g., &quot;...&quot;)</td><td>Incorrect tensor scaling or name mapping</td><td>Use <code>apr tensors --hist</code> to visualize distribution</td></tr>
<tr><td>Missing conv bias</td><td>Zero encoder output</td><td>Conv layer not loaded</td><td>Check <code>--analyze-source</code></td></tr>
<tr><td>Transposed weights</td><td>Garbage output</td><td>Row-major vs column-major confusion</td><td>Run <code>apr diff</code> vs reference</td></tr>
<tr><td>Truncated tensors</td><td>Partial outputs</td><td>Size mismatch during copy</td><td>Verify header vs file size</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="11-master-falsification-qa-checklist-100-points"><a class="header" href="#11-master-falsification-qa-checklist-100-points">11. Master Falsification QA Checklist (100 Points)</a></h2>
<p>This checklist unifies structural, physical, operational, and conversion requirements into a single 100-point quality gate. <strong>Every point must be testable and falsifiable.</strong></p>
<h3 id="a-format--structural-integrity-25-points"><a class="header" href="#a-format--structural-integrity-25-points">A. Format &amp; Structural Integrity (25 Points)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>#</th><th>Claim</th><th>Test Command</th><th>Falsification (How to Fail)</th></tr></thead><tbody>
<tr><td>1</td><td><strong>Magic bytes valid</strong></td><td><code>head -c4 m.apr \| grep APR2</code></td><td>Edit file to start with &quot;APR1&quot; or random bytes</td></tr>
<tr><td>2</td><td><strong>Header size fixed</strong></td><td><code>apr inspect m.apr --header</code></td><td>Insert 1 byte before data offset</td></tr>
<tr><td>3</td><td><strong>Version supported</strong></td><td>Load v2.0 file</td><td>Load v3.0 file (should fail E003)</td></tr>
<tr><td>4</td><td><strong>Checksum valid</strong></td><td><code>apr validate m.apr --checksum</code></td><td>Flip 1 bit in payload (should fail E004)</td></tr>
<tr><td>5</td><td><strong>JSON Metadata</strong></td><td><code>apr inspect m.apr --json</code></td><td>Corrupt JSON syntax in editor</td></tr>
<tr><td>6</td><td><strong>Tensor Alignment</strong></td><td><code>apr lint m.apr</code> checks 64B</td><td>Create file with 1-byte alignment (should warn)</td></tr>
<tr><td>7</td><td><strong>Index Sorted</strong></td><td>Validate index sort order</td><td>Swap two entries in binary index</td></tr>
<tr><td>8</td><td><strong>Compression</strong></td><td><code>apr info</code> shows <code>lz4</code></td><td>Compress with unsupported algo (should fail)</td></tr>
<tr><td>9</td><td><strong>Sharding Manifest</strong></td><td>Load sharded model</td><td>Delete one shard file (should fail E007)</td></tr>
<tr><td>10</td><td><strong>Endianness</strong></td><td>Read on Big Endian system</td><td>(Simulate BE) Read LE floats incorrectly</td></tr>
<tr><td>11</td><td><strong>Flags Parsed</strong></td><td>Check specific flag bits</td><td>Set undefined flag bit (should warn/ignore)</td></tr>
<tr><td>12</td><td><strong>Footer Magic</strong></td><td>Check <code>2RPA</code> at EOF</td><td>Truncate last 16 bytes (should fail)</td></tr>
<tr><td>13</td><td><strong>File Size</strong></td><td>Header size == <code>ls -l</code></td><td>Append garbage to EOF (should warn)</td></tr>
<tr><td>14</td><td><strong>Tensor Offsets</strong></td><td>Read last tensor</td><td>Set offset beyond EOF (should fail E002)</td></tr>
<tr><td>15</td><td><strong>Empty Model</strong></td><td>Load model with 0 tensors</td><td>Create valid header, 0 tensors (should pass)</td></tr>
<tr><td>16</td><td><strong>Huge Header</strong></td><td>Metadata &gt; 100MB</td><td>Create 200MB JSON header (should stream/fail gracefully)</td></tr>
<tr><td>17</td><td><strong>UTF-8 Names</strong></td><td>Tensor names are UTF-8</td><td>Insert invalid UTF-8 in name (should fail)</td></tr>
<tr><td>18</td><td><strong>Duplicate Names</strong></td><td>Index has unique names</td><td>Duplicate &quot;tensor.a&quot; in index (should fail)</td></tr>
<tr><td>19</td><td><strong>Dimension Limit</strong></td><td>Support 8 dims</td><td>Create 9-dim tensor (should fail)</td></tr>
<tr><td>20</td><td><strong>Zero Dims</strong></td><td>Support scalar (0-dim)</td><td>Create 0-dim tensor (should pass)</td></tr>
<tr><td>21</td><td><strong>Datatypes</strong></td><td>Support all <code>DType</code> enums</td><td>Use invalid enum id 255 (should fail)</td></tr>
<tr><td>22</td><td><strong>Padding Bytes</strong></td><td>Padding is zeroed</td><td>Fill padding with 0xFF (should warn in lint)</td></tr>
<tr><td>23</td><td><strong>Signature</strong></td><td>Verify Ed25519 (if signed)</td><td>Modify 1 byte of signature (should fail E006)</td></tr>
<tr><td>24</td><td><strong>Encryption</strong></td><td>Decrypt AES-256-GCM</td><td>Provide wrong key (should fail E005)</td></tr>
<tr><td>25</td><td><strong>WASM Load</strong></td><td>Load in <code>wasm32</code> env</td><td>Run in browser (must work)</td></tr>
</tbody></table>
</div>
<h3 id="b-tensor-physics--statistics-25-points"><a class="header" href="#b-tensor-physics--statistics-25-points">B. Tensor Physics &amp; Statistics (25 Points)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>#</th><th>Claim</th><th>Test Command</th><th>Falsification (How to Fail)</th></tr></thead><tbody>
<tr><td>26</td><td><strong>No NaNs</strong></td><td><code>apr validate --nan-check</code></td><td>Manually inject <code>0x7FC00000</code> (NaN) into f32 tensor</td></tr>
<tr><td>27</td><td><strong>No Infs</strong></td><td><code>apr validate --nan-check</code></td><td>Inject <code>0x7F800000</code> (+Inf)</td></tr>
<tr><td>28</td><td><strong>LayerNorm Mean</strong></td><td><code>apr tensors --stats</code> in [0.5, 3]</td><td>Set LN weights to 11.0 (should fail/warn)</td></tr>
<tr><td>29</td><td><strong>LayerNorm Bias</strong></td><td><code>apr tensors --stats</code> in [-0.5, 0.5]</td><td>Set LN bias to 5.0 (should fail/warn)</td></tr>
<tr><td>30</td><td><strong>Embedding Std</strong></td><td><code>apr tensors --stats</code> &lt; 0.2</td><td>Set embedding std to 1.0 (should warn)</td></tr>
<tr><td>31</td><td><strong>Zero Tensors</strong></td><td><code>apr validate --zero-check</code></td><td>Set entire tensor to 0.0 (should warn)</td></tr>
<tr><td>32</td><td><strong>Shape Match</strong></td><td><code>apr validate --shapes</code></td><td>Resize tensor [384]-&gt;[383] (should fail)</td></tr>
<tr><td>33</td><td><strong>Vocab Match</strong></td><td>Metadata <code>n_vocab</code> == tensor dim</td><td>Change metadata <code>n_vocab</code> to mismatch (should fail)</td></tr>
<tr><td>34</td><td><strong>Quantization Range</strong></td><td>q8_0 values in [-127, 127]</td><td>Manually set byte -128 (if using symm quant)</td></tr>
<tr><td>35</td><td><strong>Attn/Linear Mean</strong></td><td>Mean approx 0.0</td><td>Set Linear weight mean to 1.0 (should warn)</td></tr>
<tr><td>36</td><td><strong>Softmax Valid</strong></td><td>(If traceable) Output sums to 1.0</td><td>(Hard to fuzz statically, use trace)</td></tr>
<tr><td>37</td><td><strong>Mel Filters</strong></td><td>Values &gt;= 0.0</td><td>Set negative filter bank value (should warn)</td></tr>
<tr><td>38</td><td><strong>Pos Embeddings</strong></td><td>Correct shape for ctx len</td><td>Truncate pos embedding (should fail shape)</td></tr>
<tr><td>39</td><td><strong>Token IDs</strong></td><td>(Trace) Output tokens &lt; vocab</td><td>(Trace) Force output token &gt; vocab_max</td></tr>
<tr><td>40</td><td><strong>Audio Range</strong></td><td>(Trace) Input in [-1, 1]</td><td>Feed audio with amp 10.0 (trace should warn)</td></tr>
<tr><td>41</td><td><strong>FP16 Range</strong></td><td>Values within FP16 limits</td><td>value &gt; 65504 in FP16 tensor (should become Inf)</td></tr>
<tr><td>42</td><td><strong>Sparsity</strong></td><td>(If sparse) Check non-zero %</td><td>Claim sparse but 100% dense (lint warning)</td></tr>
<tr><td>43</td><td><strong>Dead Neurons</strong></td><td>(Trace) Activations never &gt; 0</td><td>(Trace) Detect 0-activation neuron across 100 inputs</td></tr>
<tr><td>44</td><td><strong>Exploding Grads</strong></td><td>(Trace) Values &gt; 1e6</td><td>(Trace) Detect activation spike</td></tr>
<tr><td>45</td><td><strong>Repeat Tokens</strong></td><td>(Trace) Repetition &gt; 5x</td><td>(Trace) Feed silence, check for hallucination</td></tr>
<tr><td>46</td><td><strong>Silence Input</strong></td><td>(Trace) Output is empty/silence</td><td>Feed silence, check non-empty output</td></tr>
<tr><td>47</td><td><strong>White Noise</strong></td><td>(Trace) Output is garbage</td><td>Feed noise, check for confident output (bad)</td></tr>
<tr><td>48</td><td><strong>Mel Shape</strong></td><td>Filterbank matches audio/mels</td><td>Mismatch n_mels 80 vs 128 (should fail)</td></tr>
<tr><td>49</td><td><strong>Text Context</strong></td><td>Pos embed covers text ctx</td><td>Input text &gt; max context (should truncate/fail)</td></tr>
<tr><td>50</td><td><strong>L2 Distance</strong></td><td><code>apr diff</code> vs ref &lt; 1.0</td><td>Compare against random tensor (should fail L2)</td></tr>
</tbody></table>
</div>
<h3 id="c-tooling--operations-25-points"><a class="header" href="#c-tooling--operations-25-points">C. Tooling &amp; Operations (25 Points)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>#</th><th>Claim</th><th>Test Command</th><th>Falsification (How to Fail)</th></tr></thead><tbody>
<tr><td>51</td><td><strong>Inspect Speed</strong></td><td><code>inspect</code> &lt; 100ms</td><td>(Perf) Load 100GB model (should be fast)</td></tr>
<tr><td>52</td><td><strong>Lint Defaults</strong></td><td><code>apr lint</code> runs default checks</td><td>Create file with no license (must warn)</td></tr>
<tr><td>53</td><td><strong>Drama Mode</strong></td><td><code>apr debug --drama</code></td><td>Run on CI (no tty) - should output text</td></tr>
<tr><td>54</td><td><strong>TUI Graph</strong></td><td><code>apr tui</code> renders graph</td><td>Create cyclic graph (should handle/error)</td></tr>
<tr><td>55</td><td><strong>TUI Stats</strong></td><td><code>apr tui</code> stats match CLI</td><td>(Manual) Compare TUI number vs CLI number</td></tr>
<tr><td>56</td><td><strong>Diff Identity</strong></td><td><code>apr diff a.apr a.apr</code></td><td>Diff same file (must show 100% match)</td></tr>
<tr><td>57</td><td><strong>Diff Detection</strong></td><td><code>apr diff a.apr b.apr</code></td><td>Diff modified file (must show mismatch)</td></tr>
<tr><td>58</td><td><strong>Merge Average</strong></td><td><code>apr merge</code> averages weights</td><td>Merge [1.0] and [3.0] -&gt; expect [2.0]</td></tr>
<tr><td>59</td><td><strong>Merge TIES</strong></td><td><code>apr merge --strategy ties</code></td><td>(Complex) Verify TIES masking logic</td></tr>
<tr><td>60</td><td><strong>Export ONNX</strong></td><td><code>apr export --format onnx</code></td><td>Validate output with <code>onnx.checker</code></td></tr>
<tr><td>61</td><td><strong>Export GGUF</strong></td><td><code>apr export --format gguf</code></td><td>Load output in <code>llama.cpp</code></td></tr>
<tr><td>62</td><td><strong>Convert Quant</strong></td><td><code>apr convert --quantize int8</code></td><td>Check output size &lt; 25% of input</td></tr>
<tr><td>63</td><td><strong>Convert Prune</strong></td><td><code>apr convert --prune 0.5</code></td><td>Check non-zero count is 50%</td></tr>
<tr><td>64</td><td><strong>Trace Output</strong></td><td><code>apr trace</code> produces JSON</td><td>Corrupt input audio (should err/warn)</td></tr>
<tr><td>65</td><td><strong>Explain Error</strong></td><td><code>apr explain E001</code></td><td>Ask for E999 (should say unknown)</td></tr>
<tr><td>66</td><td><strong>Explain Tensor</strong></td><td><code>apr explain --tensor</code></td><td>Ask for random name (should fuzzy match)</td></tr>
<tr><td>67</td><td><strong>Analyze Source</strong></td><td><code>convert --analyze-source</code></td><td>Run on corrupt safetensors (must fail)</td></tr>
<tr><td>68</td><td><strong>Inline Valid</strong></td><td><code>convert</code> fails on bad stat</td><td>Force bad mean in source, run convert (must abort)</td></tr>
<tr><td>69</td><td><strong>Force Override</strong></td><td><code>convert --force</code></td><td>Same as 68, but use --force (must pass)</td></tr>
<tr><td>70</td><td><strong>Cache Dir</strong></td><td>Uses <code>APR_CACHE</code></td><td>Set APR_CACHE=/tmp/x (check files there)</td></tr>
<tr><td>71</td><td><strong>Config Load</strong></td><td>Uses <code>config.toml</code></td><td>Set output_format=json in config (check output)</td></tr>
<tr><td>72</td><td><strong>Canary Check</strong></td><td><code>apr canary check</code></td><td>Modify weights to cause regression (should fail canary)</td></tr>
<tr><td>73</td><td><strong>JSON Output</strong></td><td><code>apr inspect --json</code></td><td>Pipe to <code>jq</code> (must parse)</td></tr>
<tr><td>74</td><td><strong>Trace Payload</strong></td><td><code>apr trace --payload</code></td><td>Corrupt tensor, check for anomaly in trace output</td></tr>
<tr><td>75</td><td><strong>Trace Diff</strong></td><td><code>apr trace --diff</code></td><td>Diff identical models (should show 0 drift)</td></tr>
</tbody></table>
</div>
<h3 id="d-conversion--interoperability-25-points"><a class="header" href="#d-conversion--interoperability-25-points">D. Conversion &amp; Interoperability (25 Points)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>#</th><th>Claim</th><th>Test Command</th><th>Falsification (How to Fail)</th></tr></thead><tbody>
<tr><td>76</td><td><strong>SafeTensors</strong></td><td>Import <code>.safetensors</code></td><td>Import renamed .txt file (should fail)</td></tr>
<tr><td>77</td><td><strong>PyTorch</strong></td><td>Import <code>.pt</code> (pickle)</td><td>Import malicious pickle (should fail/block)</td></tr>
<tr><td>78</td><td><strong>GGUF Import</strong></td><td>Import <code>.gguf</code></td><td>Import GGUF with unknown arch (should fail)</td></tr>
<tr><td>79</td><td><strong>Roundtrip</strong></td><td>APR-&gt;ONNX-&gt;APR</td><td>Compare tensor values (drift &lt; 1e-5)</td></tr>
<tr><td>80</td><td><strong>HF Mapping</strong></td><td>Maps <code>model.layers.0</code> correctly</td><td>Rename layer in source (should fail map)</td></tr>
<tr><td>81</td><td><strong>Q-DeepCopy</strong></td><td>Preserves quantization</td><td>Convert q8-&gt;apr (should stay q8 if supported)</td></tr>
<tr><td>82</td><td><strong>F32-&gt;BF16</strong></td><td><code>convert --precision bf16</code></td><td>Check dtype is BF16</td></tr>
<tr><td>83</td><td><strong>BF16-&gt;F32</strong></td><td><code>convert --precision f32</code></td><td>Check dtype is F32</td></tr>
<tr><td>84</td><td><strong>Vocab Import</strong></td><td>Imports full vocab</td><td>Truncate vocab in source (check count)</td></tr>
<tr><td>85</td><td><strong>Special Tokens</strong></td><td>Preserves BOS/EOS/UNK</td><td>Check metadata for token IDs</td></tr>
<tr><td>86</td><td><strong>Metadata Copy</strong></td><td>Copies model card/license</td><td>Remove metadata from source (check warnings)</td></tr>
<tr><td>87</td><td><strong>Tensor Name Norm</strong></td><td>Normalizes to <code>encoder.x</code></td><td>Check for &quot;model.encoder.x&quot; (bad)</td></tr>
<tr><td>88</td><td><strong>Permutation</strong></td><td>Transposes weights if needed</td><td>Disable transpose (check output garbage)</td></tr>
<tr><td>89</td><td><strong>Scale Factors</strong></td><td>Applies rescaling (e.g. div 2)</td><td>Disable scaling (check mean drift)</td></tr>
<tr><td>90</td><td><strong>Sharded Import</strong></td><td>Imports <code>model-0001...</code></td><td>Missing shard 2 (should fail)</td></tr>
<tr><td>91</td><td><strong>Remote Import</strong></td><td><code>apr import hf://...</code></td><td>Network down (should fail gracefully)</td></tr>
<tr><td>92</td><td><strong>Cache Hit</strong></td><td>Second import is fast</td><td>Clear cache, time it; run again, time it</td></tr>
<tr><td>93</td><td><strong>Checksum Verify</strong></td><td>Verify source SHA256</td><td>Modify source file (should fail checksum)</td></tr>
<tr><td>94</td><td><strong>License Warning</strong></td><td>Warns on non-commercial</td><td>Import CC-BY-NC model (check warning)</td></tr>
<tr><td>95</td><td><strong>Arch Detect</strong></td><td>Auto-detects Whisper/LLaMA</td><td>Import unknown arch (should ask user)</td></tr>
<tr><td>96</td><td><strong>Output Path</strong></td><td>Honors <code>--output</code></td><td>Check file exists at path</td></tr>
<tr><td>97</td><td><strong>Overwrite</strong></td><td>Fails if exists (no -f)</td><td>Create file, run export (should fail)</td></tr>
<tr><td>98</td><td><strong>Disk Full</strong></td><td>Handle ENOSPC</td><td>Simulate small disk (should fail clean)</td></tr>
<tr><td>99</td><td><strong>Memory Limit</strong></td><td>Respect <code>APR_RAM_LIMIT</code></td><td>Set low limit, load big model (should error/mmap)</td></tr>
<tr><td>100</td><td><strong>Golden Trace</strong></td><td>Passes canonical trace</td><td>Run against <code>golden_traces/</code> (must pass)</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="12-automated-validation-script"><a class="header" href="#12-automated-validation-script">12. Automated Validation Script</a></h2>
<p>The <code>apr-qa</code> tool runs this 100-point checklist automatically.</p>
<pre><code class="language-bash"># Run the full suite
apr-qa verify model.apr --score

# Run specific category
apr-qa verify model.apr --category physics

# CI/CD usage (fail if score &lt; 95)
apr-qa verify model.apr --min-score 95
</code></pre>
<hr />
<h2 id="13-importconvert-pipeline"><a class="header" href="#13-importconvert-pipeline">13. Import/Convert Pipeline</a></h2>
<p>The complete pipeline for downloading, converting, validating, and optimizing models.</p>
<h3 id="131-pipeline-overview"><a class="header" href="#131-pipeline-overview">13.1 Pipeline Overview</a></h3>
<pre><code>┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Source    │───▶│   Import    │───▶│  Validate   │───▶│   Output    │
│ (HF/Local)  │    │ (Converter) │    │ (100-Point) │    │   (.apr)    │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
      │                  │                  │                  │
      ▼                  ▼                  ▼                  ▼
  hf://openai/     SafeTensors→APR    Inline checks      Quantized/
  whisper-tiny     Name mapping       Tensor stats       Compressed
</code></pre>
<h3 id="132-cli-interface"><a class="header" href="#132-cli-interface">13.2 CLI Interface</a></h3>
<pre><code class="language-bash"># Full pipeline: download → convert → validate
apr import hf://openai/whisper-tiny -o whisper.apr

# With quantization
apr import hf://openai/whisper-tiny -o whisper-int8.apr --quantize int8

# Local file conversion
apr import model.safetensors -o model.apr

# Validate after import (automatic, but can run standalone)
apr validate whisper.apr --quality --min-score 95

# Post-import optimization
apr convert whisper.apr --quantize int8 --compress lz4 -o whisper-optimized.apr
</code></pre>
<h3 id="133-sdk-interface"><a class="header" href="#133-sdk-interface">13.3 SDK Interface</a></h3>
<pre><code class="language-rust">use aprender::format::{AprConverter, ImportOptions, ValidationConfig};

// Full pipeline with builder pattern
let apr_bytes = AprConverter::new()
    .source(&quot;hf://openai/whisper-tiny&quot;)
    .architecture(&quot;whisper&quot;)
    .validate(ValidationConfig::strict())  // Inline validation
    .quantize(Quantization::Int8)
    .compress(Compression::Lz4)
    .convert()?;

// Save to file
std::fs::write(&quot;whisper.apr&quot;, apr_bytes)?;

// Or use the high-level API
apr_import(&quot;hf://openai/whisper-tiny&quot;, &quot;whisper.apr&quot;, ImportOptions::default())?;</code></pre>
<h3 id="134-source-types"><a class="header" href="#134-source-types">13.4 Source Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Source</th><th>Format</th><th>Example</th></tr></thead><tbody>
<tr><td>HuggingFace Hub</td><td><code>hf://org/repo</code></td><td><code>hf://openai/whisper-tiny</code></td></tr>
<tr><td>HuggingFace File</td><td><code>hf://org/repo/file</code></td><td><code>hf://openai/whisper-tiny/model.safetensors</code></td></tr>
<tr><td>Local SafeTensors</td><td>Path</td><td><code>./model.safetensors</code></td></tr>
<tr><td>Local PyTorch</td><td>Path</td><td><code>./model.pt</code></td></tr>
<tr><td>Local GGUF</td><td>Path</td><td><code>./model.gguf</code></td></tr>
<tr><td>URL</td><td><code>https://</code></td><td><code>https://example.com/model.safetensors</code></td></tr>
</tbody></table>
</div>
<h3 id="135-tensor-name-mapping"><a class="header" href="#135-tensor-name-mapping">13.5 Tensor Name Mapping</a></h3>
<p>During import, tensor names are normalized from source format to APR canonical form:</p>
<pre><code class="language-rust">/// Tensor name mapper trait
pub trait TensorNameMapper {
    /// Map source tensor name to APR name
    fn map_name(&amp;self, source_name: &amp;str) -&gt; Option&lt;String&gt;;

    /// Get expected tensor statistics for validation
    fn expected_stats(&amp;self, apr_name: &amp;str) -&gt; Option&lt;TensorExpectation&gt;;
}

/// Built-in mappers
pub enum Architecture {
    Whisper,  // HuggingFace Whisper → APR Whisper
    Llama,    // HuggingFace LLaMA → APR LLaMA
    Bert,     // HuggingFace BERT → APR BERT
    Custom(Box&lt;dyn TensorNameMapper&gt;),
}</code></pre>
<p><strong>Whisper Mapping Example:</strong></p>
<pre><code>HuggingFace                           → APR
model.encoder.conv1.weight            → encoder.conv1.weight
model.decoder.layer_norm.weight       → decoder.layer_norm.weight
model.decoder.layers.0.self_attn...   → decoder.layers.0.self_attn...
</code></pre>
<h3 id="136-inline-validation"><a class="header" href="#136-inline-validation">13.6 Inline Validation</a></h3>
<p><strong>Critical</strong>: Validation runs DURING conversion, not after. If a tensor fails validation, conversion aborts immediately.</p>
<pre><code class="language-rust">/// Validation that runs inline during conversion
pub struct InlineValidator {
    config: ValidationConfig,
    report: ValidationReport,
}

impl InlineValidator {
    /// Called for each tensor during conversion
    pub fn validate_tensor(&amp;mut self, name: &amp;str, data: &amp;[f32]) -&gt; Result&lt;(), ValidationError&gt; {
        let stats = TensorStats::compute(name, data);

        // Check for NaN/Inf
        if stats.nan_count &gt; 0 {
            return Err(ValidationError::NanDetected { name: name.to_string(), count: stats.nan_count });
        }

        // Check LayerNorm weights (mean should be ~1.0)
        if name.contains(&quot;layer_norm&quot;) &amp;&amp; name.ends_with(&quot;.weight&quot;) {
            if stats.mean &lt; 0.5 || stats.mean &gt; 3.0 {
                return Err(ValidationError::LayerNormMean {
                    name: name.to_string(),
                    mean: stats.mean,
                    expected: (0.5, 3.0),
                });
            }
        }

        Ok(())
    }
}</code></pre>
<h3 id="137-import-options"><a class="header" href="#137-import-options">13.7 Import Options</a></h3>
<pre><code class="language-rust">/// Options for the import pipeline
#[derive(Debug, Clone)]
pub struct ImportOptions {
    /// Target architecture for name mapping
    pub architecture: Architecture,

    /// Validation configuration
    pub validation: ValidationConfig,

    /// Quantization (None = keep original precision)
    pub quantize: Option&lt;Quantization&gt;,

    /// Compression algorithm
    pub compress: Option&lt;Compression&gt;,

    /// Force import even if validation fails
    pub force: bool,

    /// Cache downloaded files
    pub cache: bool,

    /// HuggingFace token (from env HF_TOKEN if None)
    pub hf_token: Option&lt;String&gt;,
}

impl Default for ImportOptions {
    fn default() -&gt; Self {
        Self {
            architecture: Architecture::Auto,  // Auto-detect
            validation: ValidationConfig::strict(),
            quantize: None,
            compress: None,
            force: false,
            cache: true,
            hf_token: None,
        }
    }
}</code></pre>
<h3 id="138-error-handling"><a class="header" href="#138-error-handling">13.8 Error Handling</a></h3>
<p>Import errors are specific and actionable:</p>
<pre><code class="language-rust">#[derive(Debug, thiserror::Error)]
pub enum ImportError {
    #[error(&quot;Download failed: {source} - {reason}&quot;)]
    DownloadFailed { source: String, reason: String },

    #[error(&quot;Unsupported format: {extension}&quot;)]
    UnsupportedFormat { extension: String },

    #[error(&quot;Tensor validation failed: {name} - {reason}&quot;)]
    ValidationFailed { name: String, reason: String },

    #[error(&quot;Name mapping failed: unknown tensor '{source_name}'&quot;)]
    UnknownTensor { source_name: String },

    #[error(&quot;Architecture mismatch: expected {expected}, found {found}&quot;)]
    ArchitectureMismatch { expected: String, found: String },

    #[error(&quot;Missing required tensor: {name}&quot;)]
    MissingTensor { name: String },
}</code></pre>
<h3 id="139-caching"><a class="header" href="#139-caching">13.9 Caching</a></h3>
<p>Downloaded models are cached to avoid re-downloading:</p>
<pre><code>~/.cache/apr/
├── hf/
│   └── openai/
│       └── whisper-tiny/
│           ├── model.safetensors
│           └── config.json
└── checksum.json
</code></pre>
<pre><code class="language-bash"># Clear cache
apr cache clear

# Show cache usage
apr cache info

# Pre-download without converting
apr download hf://openai/whisper-tiny
</code></pre>
<h3 id="1310-testing-requirements"><a class="header" href="#1310-testing-requirements">13.10 Testing Requirements</a></h3>
<p>Every import path must have:</p>
<ol>
<li><strong>Unit Test</strong>: Test name mapping and validation logic</li>
<li><strong>Integration Test</strong>: Download real model, convert, validate</li>
<li><strong>Golden Test</strong>: Compare output against known-good .apr file</li>
<li><strong>Regression Test</strong>: Ensure tensor statistics match expected values</li>
</ol>
<pre><code class="language-rust">#[test]
fn test_whisper_tiny_import() {
    let result = apr_import(
        &quot;hf://openai/whisper-tiny&quot;,
        &quot;/tmp/test.apr&quot;,
        ImportOptions::default(),
    );

    assert!(result.is_ok());

    // Validate the output
    let validator = AprValidator::new();
    let report = validator.validate(&amp;std::fs::read(&quot;/tmp/test.apr&quot;).unwrap());

    assert!(report.passed(95), &quot;Score: {}/100&quot;, report.total_score);

    // Check specific tensor that was previously buggy
    let reader = AprReader::new(&amp;std::fs::read(&quot;/tmp/test.apr&quot;).unwrap()).unwrap();
    let ln_weight = reader.load_tensor(&quot;decoder.layer_norm.weight&quot;).unwrap();
    let stats = TensorStats::compute(&quot;decoder.layer_norm.weight&quot;, &amp;ln_weight);

    assert!(stats.mean &gt;= 0.5 &amp;&amp; stats.mean &lt;= 3.0,
        &quot;decoder.layer_norm.weight mean={} should be in [0.5, 3.0]&quot;, stats.mean);
}</code></pre>
<hr />
<h2 id="14-implementation-roadmap"><a class="header" href="#14-implementation-roadmap">14. Implementation Roadmap</a></h2>
<h3 id="phase-1-alignment-v20"><a class="header" href="#phase-1-alignment-v20">Phase 1: Alignment (v2.0)</a></h3>
<ul>
<li>64-byte tensor alignment</li>
<li>Binary tensor index</li>
<li>Backward-compatible reader</li>
</ul>
<h3 id="phase-2-compression-v21"><a class="header" href="#phase-2-compression-v21">Phase 2: Compression (v2.1)</a></h3>
<ul>
<li>LZ4 block compression</li>
<li>Per-tensor compression flag</li>
<li>Streaming decompression</li>
</ul>
<h3 id="phase-3-sharding-v22"><a class="header" href="#phase-3-sharding-v22">Phase 3: Sharding (v2.2)</a></h3>
<ul>
<li>Manifest file format</li>
<li>Multi-file loader</li>
<li>Tensor-level demand loading</li>
</ul>
<hr />
<h2 id="15-references"><a class="header" href="#15-references">15. References</a></h2>
<ol>
<li>Sculley, D., et al. (2015). &quot;Hidden Technical Debt in Machine Learning Systems.&quot; <em>NeurIPS 2015</em></li>
<li>Amershi, S., et al. (2019). &quot;Software Engineering for Machine Learning.&quot; <em>ICSE 2019</em></li>
<li>Vartak, M., et al. (2016). &quot;ModelDB: A System for ML Model Management.&quot; <em>SIGMOD 2016</em></li>
<li>Baylor, D., et al. (2017). &quot;TFX: A TensorFlow-Based Production-Scale ML Platform.&quot; <em>KDD 2017</em></li>
<li>Zaharia, M., et al. (2018). &quot;Accelerating the ML Lifecycle with MLflow.&quot; <em>IEEE Data Eng. Bull.</em></li>
</ol>
<p><strong>Code References:</strong></p>
<ul>
<li>APR v1: <code>src/serialization/apr.rs</code></li>
<li>GGUF: <code>src/format/gguf.rs</code></li>
<li>Bundle system: <code>src/bundle/</code></li>
<li>SafeTensors: <code>src/serialization/safetensors.rs</code></li>
</ul>
<hr />
<h2 id="16-appendices"><a class="header" href="#16-appendices">16. Appendices</a></h2>
<h3 id="a-exit-codes"><a class="header" href="#a-exit-codes">A. Exit Codes</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Meaning</th></tr></thead><tbody>
<tr><td>0</td><td>Success</td></tr>
<tr><td>1</td><td>General error</td></tr>
<tr><td>2</td><td>Invalid arguments</td></tr>
<tr><td>3</td><td>File not found</td></tr>
<tr><td>4</td><td>Format error</td></tr>
<tr><td>5</td><td>Validation failed</td></tr>
</tbody></table>
</div>
<h3 id="b-environment-variables"><a class="header" href="#b-environment-variables">B. Environment Variables</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td><code>APR_CONFIG</code></td><td>Config file path</td><td><code>~/.config/apr/config.toml</code></td></tr>
<tr><td><code>APR_CACHE</code></td><td>Cache directory</td><td><code>~/.cache/apr</code></td></tr>
<tr><td><code>APR_LOG_LEVEL</code></td><td>Log level</td><td><code>info</code></td></tr>
<tr><td><code>APR_COLOR</code></td><td>Enable colors</td><td><code>auto</code></td></tr>
</tbody></table>
</div>
<hr />
<p><em>Document generated following Toyota Way principles and PMAT quality standards.</em></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../tools/apr-cli.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../best-practices/error-handling.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../tools/apr-cli.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../best-practices/error-handling.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../editor.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
