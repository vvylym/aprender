// CONTRACT: qk-norm-v1.yaml
// HASH: sha256:f2a3b4c5d6e78902
// Generated by: pv probar --binding
//
// FALSIFY-QKN-001..004: Original CPU invariant tests
// FALSIFY-QKN-005: SIMD scalar equivalence (ignored — trueno domain)
// FALSIFY-QKN-006: Cross-backend equivalence (GPU reference vs CPU)
// FALSIFY-QKN-007: Per-head independence

use aprender::autograd::Tensor;
use aprender::nn::Module;
use aprender::nn::RMSNorm;
use proptest::prelude::*;

// ============================================================================
// GPU Reference Implementation (Pure Rust)
//
// Simulates the exact algorithm of trueno-gpu's PerHeadRmsNormKernel:
//   - Per-head: each head normalized independently
//   - rsqrt.approx: NVIDIA approximate reciprocal square root (~23-bit mantissa)
//   - warp reduction: sum of squares via butterfly shuffle (exact in f32)
//   - FMA accumulation: fused multiply-add for sum of squares
//
// This does NOT require CUDA — it tests algorithmic equivalence in pure Rust.
// ============================================================================

/// Simulate NVIDIA rsqrt.approx.f32 — relative error up to 2^{-22} ≈ 2.4e-7.
/// We use exact rsqrt here since we're testing algorithm, not hardware precision.
/// The tolerance in the test accounts for the hardware approximation.
fn rsqrt_approx(x: f32) -> f32 {
    1.0 / x.sqrt()
}

/// GPU reference: per-head RMSNorm as implemented in PerHeadRmsNormKernel.
///
/// Algorithm (from trueno-gpu/src/kernels/layernorm/per_head_rmsnorm.rs):
/// ```text
/// For each head h in 0..num_heads:
///     slice = input[h*head_dim .. (h+1)*head_dim]
///     sq_sum = Σ(slice[i]²)           // warp-reduced
///     mean_sq = sq_sum / head_dim
///     rms_inv = rsqrt(mean_sq + eps)
///     output[h*head_dim+i] = slice[i] * rms_inv * gamma[i]
/// ```
fn gpu_reference_per_head_rmsnorm(
    input: &[f32],
    gamma: &[f32],
    num_heads: usize,
    head_dim: usize,
    eps: f32,
) -> Vec<f32> {
    assert_eq!(input.len(), num_heads * head_dim);
    assert_eq!(gamma.len(), head_dim);

    let mut output = vec![0.0f32; input.len()];

    for h in 0..num_heads {
        let offset = h * head_dim;
        let slice = &input[offset..offset + head_dim];

        // Pass 1: sum of squares (FMA accumulation, warp-reduced)
        let sq_sum: f32 = slice.iter().map(|&v| v * v).sum();

        // Compute rms_inv = rsqrt(mean_sq + eps)
        let mean_sq = sq_sum / head_dim as f32;
        let rms_inv = rsqrt_approx(mean_sq + eps);

        // Pass 2: normalize and scale
        for i in 0..head_dim {
            output[offset + i] = slice[i] * rms_inv * gamma[i];
        }
    }

    output
}

/// CPU reference: uses aprender's RMSNorm::forward applied per-head.
///
/// RMSNorm::forward treats the last dimension as the normalized dimension.
/// With input shape [num_heads, head_dim] and normalized_shape=[head_dim],
/// each head is normalized independently.
fn cpu_reference_per_head_rmsnorm(
    input: &[f32],
    gamma: &[f32],
    num_heads: usize,
    head_dim: usize,
) -> Vec<f32> {
    let mut norm = RMSNorm::new(&[head_dim]);
    norm.set_weight(Tensor::new(gamma, &[head_dim]));

    let x = Tensor::new(input, &[num_heads, head_dim]);
    let y = norm.forward(&x);
    y.data().to_vec()
}

proptest! {
    /// FALSIFY-QKN-001: Unit RMS after normalization (invariant)
    /// Formal: RMS(RMSNorm(x, 1)) ≈ 1.0
    #[test]
    fn prop_rms_unit_norm(
        data in proptest::collection::vec(-10.0f32..10.0, 2..64usize)
            .prop_filter("non-zero input", |d| d.iter().any(|v| v.abs() > 0.01))
    ) {
        let n = data.len();
        let norm = RMSNorm::without_affine(&[n]);
        let x = Tensor::new(&data, &[1, n]);
        let y = norm.forward(&x);
        let y_data = y.data();

        // Compute RMS of output
        let sum_sq: f32 = y_data.iter().map(|v| v * v).sum();
        let rms = (sum_sq / n as f32).sqrt();

        prop_assert!(
            (rms - 1.0).abs() < 0.1,
            "RMS of normalized output = {rms}, expected ≈ 1.0"
        );
    }

    /// FALSIFY-QKN-002: Output amplitude bounded (bound)
    /// Formal: |output_i| <= |weight_i| * sqrt(d_k / ε)
    #[test]
    fn prop_output_bounded(
        data in proptest::collection::vec(-100.0f32..100.0, 1..64usize)
    ) {
        let n = data.len();
        let norm = RMSNorm::new(&[n]);
        let x = Tensor::new(&data, &[1, n]);
        let y = norm.forward(&x);

        let eps = 1e-5_f32;
        let bound = (n as f32 / eps).sqrt();

        for (i, &val) in y.data().iter().enumerate() {
            prop_assert!(
                val.abs() <= bound,
                "output[{i}]={val} exceeds bound {bound}"
            );
        }
    }

    /// FALSIFY-QKN-003: Idempotent with unit weight (invariant)
    /// Formal: RMSNorm(RMSNorm(x, 1), 1) ≈ RMSNorm(x, 1)
    #[test]
    fn prop_idempotent(
        data in proptest::collection::vec(-10.0f32..10.0, 2..32usize)
            .prop_filter("non-zero input", |d| d.iter().any(|v| v.abs() > 0.01))
    ) {
        let n = data.len();
        let norm = RMSNorm::without_affine(&[n]);
        let x = Tensor::new(&data, &[1, n]);

        let y_once = norm.forward(&x);
        let y_twice = norm.forward(&y_once);

        let once_data = y_once.data();
        let twice_data = y_twice.data();
        for i in 0..n {
            let diff = (once_data[i] - twice_data[i]).abs();
            prop_assert!(
                diff < 0.1,
                "idempotent: y_once[{i}]={} vs y_twice[{i}]={}, diff={diff}",
                once_data[i], twice_data[i]
            );
        }
    }

    /// FALSIFY-QKN-004: Zero-input stability (invariant)
    /// Formal: RMSNorm(0, w) = 0
    #[test]
    fn prop_zero_input(
        n in 2usize..64
    ) {
        let data = vec![0.0f32; n];
        let norm = RMSNorm::new(&[n]);
        let x = Tensor::new(&data, &[1, n]);
        let y = norm.forward(&x);

        for (i, &val) in y.data().iter().enumerate() {
            prop_assert!(
                val.abs() < 1e-6,
                "RMSNorm(0)[{i}]={val}, expected 0"
            );
        }
    }

    /// FALSIFY-QKN-006: Cross-backend equivalence (GPU reference vs CPU)
    ///
    /// Tests that the GPU PerHeadRmsNormKernel algorithm produces the same
    /// output as CPU RMSNorm::forward when applied per-head.
    ///
    /// Tolerance: 1e-3 (accounts for rsqrt.approx vs 1/sqrt and FMA vs
    /// separate mul+add on GPU hardware).
    ///
    /// If this test fails, the GPU kernel diverges from the CPU reference —
    /// check argument order, head count, or kernel launch grid.
    #[test]
    fn prop_cross_backend_equivalence(
        // Use realistic Qwen3-like dimensions: 2-8 heads, 32-128 head_dim
        num_heads in 2usize..9,
        head_dim in prop::sample::select(vec![32usize, 64, 128]),
        data_seed in proptest::collection::vec(-5.0f32..5.0, 128 * 8),
        gamma_seed in proptest::collection::vec(0.5f32..2.0, 128)
    ) {
        let total = num_heads * head_dim;
        // Trim seeds to exact size
        let input: Vec<f32> = data_seed.into_iter().take(total).collect();
        let gamma: Vec<f32> = gamma_seed.into_iter().take(head_dim).collect();

        // Skip if we don't have enough data
        prop_assume!(input.len() == total);
        prop_assume!(gamma.len() == head_dim);

        let eps = 1e-6_f32;

        let gpu_out = gpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim, eps);
        let cpu_out = cpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim);

        // Element-wise comparison
        for i in 0..total {
            let diff = (gpu_out[i] - cpu_out[i]).abs();
            let magnitude = gpu_out[i].abs().max(cpu_out[i].abs()).max(1e-8);
            let rel_err = diff / magnitude;
            prop_assert!(
                rel_err < 1e-3,
                "cross-backend divergence at [{i}]: gpu={} cpu={} diff={diff} rel_err={rel_err} \
                 (head={}, pos_in_head={})",
                gpu_out[i], cpu_out[i], i / head_dim, i % head_dim
            );
        }

        // Cosine similarity
        let dot: f32 = gpu_out.iter().zip(&cpu_out).map(|(a, b)| a * b).sum();
        let norm_gpu: f32 = gpu_out.iter().map(|v| v * v).sum::<f32>().sqrt();
        let norm_cpu: f32 = cpu_out.iter().map(|v| v * v).sum::<f32>().sqrt();
        let cosine = if norm_gpu > 0.0 && norm_cpu > 0.0 {
            dot / (norm_gpu * norm_cpu)
        } else {
            1.0 // both zero → equivalent
        };
        prop_assert!(
            cosine > 0.9999,
            "cross-backend cosine similarity = {cosine}, expected > 0.9999"
        );
    }

    /// FALSIFY-QKN-007: Per-head independence
    ///
    /// Normalizing N heads as a batch must produce the same result as
    /// normalizing each head independently. This catches offset bugs
    /// in the GPU kernel's head_idx * head_dim calculation.
    #[test]
    fn prop_per_head_independence(
        num_heads in 2usize..9,
        head_dim in prop::sample::select(vec![32usize, 64, 128]),
        data_seed in proptest::collection::vec(-5.0f32..5.0, 128 * 8),
        gamma_seed in proptest::collection::vec(0.5f32..2.0, 128)
    ) {
        let total = num_heads * head_dim;
        let input: Vec<f32> = data_seed.into_iter().take(total).collect();
        let gamma: Vec<f32> = gamma_seed.into_iter().take(head_dim).collect();

        prop_assume!(input.len() == total);
        prop_assume!(gamma.len() == head_dim);

        let eps = 1e-6_f32;

        // Batch: all heads at once
        let batch_out = gpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim, eps);

        // Individual: each head separately
        let mut individual_out = vec![0.0f32; total];
        for h in 0..num_heads {
            let offset = h * head_dim;
            let head_input = &input[offset..offset + head_dim];
            let head_out = gpu_reference_per_head_rmsnorm(head_input, &gamma, 1, head_dim, eps);
            individual_out[offset..offset + head_dim].copy_from_slice(&head_out);
        }

        // Must be bitwise identical (same algorithm, same data)
        for i in 0..total {
            prop_assert!(
                (batch_out[i] - individual_out[i]).abs() < f32::EPSILON,
                "per-head independence violated at [{i}]: batch={} individual={} \
                 (head={}, pos={})",
                batch_out[i], individual_out[i], i / head_dim, i % head_dim
            );
        }
    }
}

// ============================================================================
// Deterministic tests at exact Qwen3-8B dimensions
// ============================================================================

/// FALSIFY-QKN-006 (deterministic): Qwen3-8B Q dimensions (32 heads × 128 dim)
#[test]
fn test_cross_backend_qwen3_q_dimensions() {
    let num_heads = 32;
    let head_dim = 128;
    let total = num_heads * head_dim;
    let eps = 1e-6_f32;

    // Deterministic input (sin wave for variety)
    let input: Vec<f32> = (0..total).map(|i| (i as f32 * 0.037).sin() * 2.0).collect();
    let gamma: Vec<f32> = (0..head_dim).map(|i| 0.8 + (i as f32 * 0.003)).collect();

    let gpu_out = gpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim, eps);
    let cpu_out = cpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim);

    let mut max_rel_err: f32 = 0.0;
    for i in 0..total {
        let diff = (gpu_out[i] - cpu_out[i]).abs();
        let magnitude = gpu_out[i].abs().max(cpu_out[i].abs()).max(1e-8);
        let rel_err = diff / magnitude;
        max_rel_err = max_rel_err.max(rel_err);
        assert!(
            rel_err < 1e-3,
            "Q cross-backend divergence at [{i}]: gpu={} cpu={} rel_err={rel_err}",
            gpu_out[i],
            cpu_out[i]
        );
    }
    eprintln!("Qwen3-8B Q (32×128): max relative error = {max_rel_err:.2e} — PASS");
}

/// FALSIFY-QKN-006 (deterministic): Qwen3-8B K dimensions (8 heads × 128 dim)
#[test]
fn test_cross_backend_qwen3_k_dimensions() {
    let num_heads = 8;
    let head_dim = 128;
    let total = num_heads * head_dim;
    let eps = 1e-6_f32;

    let input: Vec<f32> = (0..total).map(|i| (i as f32 * 0.051).cos() * 1.5).collect();
    let gamma: Vec<f32> = (0..head_dim).map(|i| 0.9 + (i as f32 * 0.002)).collect();

    let gpu_out = gpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim, eps);
    let cpu_out = cpu_reference_per_head_rmsnorm(&input, &gamma, num_heads, head_dim);

    let mut max_rel_err: f32 = 0.0;
    for i in 0..total {
        let diff = (gpu_out[i] - cpu_out[i]).abs();
        let magnitude = gpu_out[i].abs().max(cpu_out[i].abs()).max(1e-8);
        let rel_err = diff / magnitude;
        max_rel_err = max_rel_err.max(rel_err);
        assert!(
            rel_err < 1e-3,
            "K cross-backend divergence at [{i}]: gpu={} cpu={} rel_err={rel_err}",
            gpu_out[i],
            cpu_out[i]
        );
    }
    eprintln!("Qwen3-8B K (8×128): max relative error = {max_rel_err:.2e} — PASS");
}

/// FALSIFY-QKN-007 (deterministic): Wrong num_heads detection
///
/// If the GPU kernel receives wrong num_heads (e.g., 8 instead of 32 for Q),
/// it only normalizes 1/4 of the buffer. This test verifies that the output
/// differs dramatically, proving the contract catches the bug.
#[test]
fn test_wrong_num_heads_detection() {
    let correct_heads = 32;
    let wrong_heads = 8; // GQA K heads, not Q heads
    let head_dim = 128;
    let total = correct_heads * head_dim;
    let eps = 1e-6_f32;

    let input: Vec<f32> = (0..total).map(|i| (i as f32 * 0.037).sin() * 2.0).collect();
    let gamma: Vec<f32> = (0..head_dim).map(|i| 0.8 + (i as f32 * 0.003)).collect();

    let correct_out = gpu_reference_per_head_rmsnorm(&input, &gamma, correct_heads, head_dim, eps);

    // Simulate the bug: GPU only processes wrong_heads heads, rest is uninitialized/zero
    let mut wrong_out = vec![0.0f32; total];
    let partial = gpu_reference_per_head_rmsnorm(
        &input[..wrong_heads * head_dim],
        &gamma,
        wrong_heads,
        head_dim,
        eps,
    );
    wrong_out[..wrong_heads * head_dim].copy_from_slice(&partial);

    // Cosine similarity should be very low (proving the bug is detectable)
    let dot: f32 = correct_out.iter().zip(&wrong_out).map(|(a, b)| a * b).sum();
    let norm_correct: f32 = correct_out.iter().map(|v| v * v).sum::<f32>().sqrt();
    let norm_wrong: f32 = wrong_out.iter().map(|v| v * v).sum::<f32>().sqrt();
    let cosine = dot / (norm_correct * norm_wrong);

    // With 8/32 heads processed, cosine ≈ sqrt(8/32) ≈ 0.5 (only 1/4 of data overlaps).
    // Correct normalization would give cosine > 0.9999, so anything < 0.9 detects the bug.
    eprintln!("Wrong num_heads (8 vs 32): cosine similarity = {cosine:.6} — should be < 0.9");
    assert!(
        cosine < 0.9,
        "Wrong num_heads should produce dramatically different output, got cosine={cosine}"
    );
}
