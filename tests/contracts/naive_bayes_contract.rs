// CONTRACT: naive-bayes-v1.yaml
// HASH: sha256:a3b7c1d9e5f20468
// Generated by: pv probar --binding
// DO NOT EDIT â€” regenerate with `pv probar --binding`

use aprender::classification::GaussianNB;
use aprender::primitives::Matrix;
use proptest::prelude::*;

/// Strategy: generate training data with n samples, d features, and K classes.
/// Each sample gets a random class label in 0..K. We ensure at least 4 samples
/// per class by constructing per-class blocks.
fn nb_training_strategy() -> impl Strategy<Value = (Matrix<f32>, Vec<usize>, usize)> {
    // K = number of classes (2..=4), d = features (2..=4),
    // samples_per_class = 4..=8
    (2usize..=4, 2usize..=4, 4usize..=8)
        .prop_flat_map(|(k, d, samples_per_class)| {
            let n = k * samples_per_class;
            let features = proptest::collection::vec(-10.0f32..10.0f32, n * d);
            let k_val = Just(k);
            let d_val = Just(d);
            let spc = Just(samples_per_class);
            (features, k_val, d_val, spc)
        })
        .prop_map(|(features, k, d, samples_per_class)| {
            let n = k * samples_per_class;
            let x = Matrix::from_vec(n, d, features).expect("valid matrix dimensions");
            // Assign classes: first samples_per_class to class 0, next to class 1, etc.
            let y: Vec<usize> = (0..k)
                .flat_map(|c| std::iter::repeat(c).take(samples_per_class))
                .collect();
            (x, y, k)
        })
}

proptest! {
    #![proptest_config(ProptestConfig::with_cases(256))]

    /// FALSIFY-NB-001: predict_proba probabilities valid on single point.
    /// Fit with known data, call predict_proba on a single point, assert each
    /// probability is in [0, 1] and they sum to approximately 1.0.
    #[test]
    fn prop_predict_proba_valid_single_point(
        (x_train, y_train, k) in nb_training_strategy(),
        query_features in proptest::collection::vec(-10.0f32..10.0f32, 2usize..=4),
    ) {
        // query_features length must match training dimensions
        let (_, d) = x_train.shape();
        prop_assume!(query_features.len() >= d);
        let query_data: Vec<f32> = query_features[..d].to_vec();
        let x_test = Matrix::from_vec(1, d, query_data).expect("valid 1xd matrix");

        let mut model = GaussianNB::new();
        model.fit(&x_train, &y_train).expect("fit succeeds");
        let proba = model.predict_proba(&x_test).expect("predict_proba succeeds");

        prop_assert!(
            proba.len() == 1,
            "expected 1 row of probabilities, got {}", proba.len()
        );
        let probs = &proba[0];
        prop_assert!(
            probs.len() == k,
            "expected {} class probabilities, got {}", k, probs.len()
        );
        for (i, &p) in probs.iter().enumerate() {
            prop_assert!(
                (0.0..=1.0).contains(&p),
                "prob[{}] = {}, expected in [0, 1]", i, p
            );
        }
        let sum: f32 = probs.iter().sum();
        prop_assert!(
            (sum - 1.0).abs() < 1e-4,
            "probability sum = {}, expected ~1.0", sum
        );
    }

    /// FALSIFY-NB-002: Predictions are in the set of training labels.
    /// Fit, then predict. All predicted labels must be in the training label set.
    #[test]
    fn prop_predictions_in_training_classes(
        (x_train, y_train, _k) in nb_training_strategy(),
    ) {
        let mut model = GaussianNB::new();
        model.fit(&x_train, &y_train).expect("fit succeeds");
        let predictions = model.predict(&x_train).expect("predict succeeds");

        let mut unique_labels: Vec<usize> = y_train.clone();
        unique_labels.sort_unstable();
        unique_labels.dedup();

        for (i, &pred) in predictions.iter().enumerate() {
            prop_assert!(
                unique_labels.contains(&pred),
                "prediction[{}] = {}, not in training classes {:?}", i, pred, unique_labels
            );
        }
    }

    /// FALSIFY-NB-003: Prediction deterministic.
    /// Fit, predict twice on the same data, assert results are identical.
    #[test]
    fn prop_prediction_deterministic(
        (x_train, y_train, _k) in nb_training_strategy(),
    ) {
        let mut model = GaussianNB::new();
        model.fit(&x_train, &y_train).expect("fit succeeds");

        let pred1 = model.predict(&x_train).expect("predict succeeds (1st)");
        let pred2 = model.predict(&x_train).expect("predict succeeds (2nd)");

        prop_assert!(
            pred1 == pred2,
            "predictions differ: first call != second call"
        );
    }

    /// FALSIFY-NB-004: predict_proba probabilities valid for all samples.
    /// Call predict_proba on training data. Assert each sample's probs are
    /// in [0, 1] and sum to approximately 1.0.
    #[test]
    fn prop_predict_proba_valid_all_samples(
        (x_train, y_train, k) in nb_training_strategy(),
    ) {
        let mut model = GaussianNB::new();
        model.fit(&x_train, &y_train).expect("fit succeeds");
        let proba = model.predict_proba(&x_train).expect("predict_proba succeeds");

        let (n, _) = x_train.shape();
        prop_assert!(
            proba.len() == n,
            "expected {} rows of probabilities, got {}", n, proba.len()
        );

        for (row_idx, probs) in proba.iter().enumerate() {
            prop_assert!(
                probs.len() == k,
                "sample {}: expected {} class probs, got {}", row_idx, k, probs.len()
            );
            for (col_idx, &p) in probs.iter().enumerate() {
                prop_assert!(
                    (0.0..=1.0).contains(&p),
                    "sample {} class {}: prob = {}, expected in [0, 1]",
                    row_idx, col_idx, p
                );
            }
            let sum: f32 = probs.iter().sum();
            prop_assert!(
                (sum - 1.0).abs() < 1e-4,
                "sample {}: probability sum = {}, expected ~1.0", row_idx, sum
            );
        }
    }

    /// FALSIFY-NB-005: Separable data yields high accuracy.
    /// Two well-separated Gaussian clusters with small noise. Accuracy > 0.9.
    #[test]
    fn prop_separable_data_high_accuracy(
        gap in 8.0f32..20.0,
        noise_scale in 0.01f32..0.3,
        seed in 0u64..1000,
    ) {
        // Deterministic RNG from seed for reproducibility
        let n_per_class = 20usize;
        let n = 2 * n_per_class;

        // Simple LCG for reproducible noise
        let mut rng_state = seed;
        let mut next_noise = || -> f32 {
            // xorshift64
            rng_state ^= rng_state << 13;
            rng_state ^= rng_state >> 7;
            rng_state ^= rng_state << 17;
            // Map to [-1, 1] range then scale
            let val = (rng_state as f32 / u64::MAX as f32) * 2.0 - 1.0;
            val * noise_scale
        };

        let mut data = Vec::with_capacity(n * 2);
        let mut labels = Vec::with_capacity(n);

        // Cluster A centered at (0, 0)
        for _ in 0..n_per_class {
            data.push(0.0 + next_noise());
            data.push(0.0 + next_noise());
            labels.push(0);
        }
        // Cluster B centered at (gap, gap)
        for _ in 0..n_per_class {
            data.push(gap + next_noise());
            data.push(gap + next_noise());
            labels.push(1);
        }

        let x = Matrix::from_vec(n, 2, data).expect("valid matrix");
        let mut model = GaussianNB::new();
        model.fit(&x, &labels).expect("fit succeeds");
        let predictions = model.predict(&x).expect("predict succeeds");

        let correct: usize = predictions
            .iter()
            .zip(labels.iter())
            .filter(|(&pred, &actual)| pred == actual)
            .count();
        let accuracy = correct as f32 / n as f32;

        prop_assert!(
            accuracy > 0.9,
            "accuracy = {} ({}/{}), expected > 0.9 with gap={} noise={}",
            accuracy, correct, n, gap, noise_scale
        );
    }
}
