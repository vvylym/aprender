//! Gradient-based optimizers for neural network training.
//!
//! These optimizers work with autograd Tensors to update parameters
//! based on computed gradients.
//!
//! # Example
//!
//! ```ignore
//! use aprender::nn::{Linear, Module, optim::SGD};
//! use aprender::nn::loss::MSELoss;
//! use aprender::autograd::Tensor;
//!
//! // Create model and optimizer
//! let mut model = Linear::new(10, 5);
//! let mut optimizer = SGD::new(model.parameters_mut(), 0.01);
//!
//! // Training loop
//! for epoch in 0..100 {
//!     let x = Tensor::randn(&[32, 10]);
//!     let y = Tensor::randn(&[32, 5]);
//!
//!     // Forward pass
//!     let pred = model.forward(&x);
//!     let loss = MSELoss::new().forward(&pred, &y);
//!
//!     // Backward pass
//!     optimizer.zero_grad();
//!     loss.backward();
//!     optimizer.step();
//! }
//! ```
//!
//! # References
//!
//! - Robbins, H., & Monro, S. (1951). A stochastic approximation method.
//! - Kingma, D. P., & Ba, J. (2015). Adam: A method for stochastic optimization. ICLR.
//! - Loshchilov, I., & Hutter, F. (2019). Decoupled weight decay regularization. ICLR.

use crate::autograd::{get_grad, Tensor, TensorId};
use serde::{Deserialize, Serialize};

/// Common trait for all optimizers.
pub trait Optimizer {
    /// Type of the optimizer's state.
    /// Use `()` for stateless optimizers, or a concrete state type for optimizers with state.
    type State: Serialize + for<'de> Deserialize<'de>;

    /// Perform a single optimization step using computed gradients.
    fn step(&mut self);

    /// Zero all parameter gradients.
    fn zero_grad(&mut self);

    /// Get current learning rate.
    fn lr(&self) -> f32;

    /// Set learning rate (for schedulers).
    fn set_lr(&mut self, lr: f32);

    /// Get optimizer state for serialization (if supported).
    ///
    /// Returns `None` for optimizers without state (e.g., vanilla SGD without momentum).
    /// Returns `Some(state)` for optimizers with state that can be serialized.
    ///
    /// # Returns
    /// `Option<Self::State>` - Serializable state, or None if not supported
    fn get_state(&self) -> Option<Self::State>;

    /// Restore optimizer state from serialized representation (if supported).
    ///
    /// # Arguments
    /// * `state` - Serialized optimizer state
    /// * `params` - Current model parameters (must match original parameter order)
    ///
    /// # Errors
    /// Returns error if state restoration is not supported, parameter count mismatch, or invalid state
    fn restore_state(&mut self, state: Self::State, params: &[&Tensor]) -> Result<(), String>;
}

/// Stochastic Gradient Descent optimizer with momentum.
///
/// Update rule:
/// ```text
/// v_t = momentum * v_{t-1} + grad
/// param = param - lr * v_t
/// ```
///
/// With Nesterov momentum:
/// ```text
/// v_t = momentum * v_{t-1} + grad
/// param = param - lr * (momentum * v_t + grad)
/// ```
#[derive(Debug)]
pub struct SGD {
    /// Parameter tensor IDs to optimize
    param_ids: Vec<TensorId>,
    /// Learning rate
    lr: f32,
    /// Momentum factor (0 = no momentum)
    momentum: f32,
    /// Weight decay (L2 regularization)
    weight_decay: f32,
    /// Nesterov momentum
    nesterov: bool,
    /// Velocity buffers for momentum
    velocities: Vec<Vec<f32>>,
    /// Whether velocities have been initialized
    initialized: bool,
}

impl SGD {
    /// Create a new SGD optimizer.
    ///
    /// # Arguments
    ///
    /// * `params` - Mutable references to parameter tensors
    /// * `lr` - Learning rate
    #[allow(clippy::needless_pass_by_value)]
    pub fn new(params: Vec<&mut Tensor>, lr: f32) -> Self {
        let param_ids: Vec<TensorId> = params.iter().map(|p| p.id()).collect();
        Self {
            param_ids,
            lr,
            momentum: 0.0,
            weight_decay: 0.0,
            nesterov: false,
            velocities: Vec::new(),
            initialized: false,
        }
    }

    /// Create SGD with momentum.
    #[allow(clippy::needless_pass_by_value)]
    pub fn with_momentum(params: Vec<&mut Tensor>, lr: f32, momentum: f32) -> Self {
        let param_ids: Vec<TensorId> = params.iter().map(|p| p.id()).collect();
        Self {
            param_ids,
            lr,
            momentum,
            weight_decay: 0.0,
            nesterov: false,
            velocities: Vec::new(),
            initialized: false,
        }
    }

    /// Enable Nesterov momentum.
    pub fn nesterov(mut self) -> Self {
        self.nesterov = true;
        self
    }

    /// Set weight decay (L2 regularization).
    pub fn weight_decay(mut self, wd: f32) -> Self {
        self.weight_decay = wd;
        self
    }

    /// Update a single parameter tensor.
    #[allow(clippy::if_not_else)]
    fn update_param(&mut self, param: &mut Tensor, idx: usize) {
        let Some(grad) = get_grad(param.id()) else {
            return; // No gradient available
        };

        let grad_data = grad.data();
        let param_data = param.data_mut();

        // Initialize velocity if needed
        if !self.initialized || idx >= self.velocities.len() {
            if idx >= self.velocities.len() {
                self.velocities.resize(idx + 1, Vec::new());
            }
            self.velocities[idx] = vec![0.0; param_data.len()];
        }

        let velocity = &mut self.velocities[idx];

        for i in 0..param_data.len() {
            let mut g = grad_data[i];

            // Apply weight decay
            if self.weight_decay != 0.0 {
                g += self.weight_decay * param_data[i];
            }

            if self.momentum != 0.0 {
                // Update velocity
                velocity[i] = self.momentum * velocity[i] + g;

                if self.nesterov {
                    // Nesterov: look ahead
                    param_data[i] -= self.lr * (self.momentum * velocity[i] + g);
                } else {
                    // Standard momentum
                    param_data[i] -= self.lr * velocity[i];
                }
            } else {
                // Vanilla SGD
                param_data[i] -= self.lr * g;
            }
        }
    }
}

impl Optimizer for SGD {
    type State = SGDState;

    fn step(&mut self) {
        self.initialized = true;
    }

    fn zero_grad(&mut self) {
        for &id in &self.param_ids {
            crate::autograd::clear_grad(id);
        }
    }

    fn lr(&self) -> f32 {
        self.lr
    }

    fn set_lr(&mut self, lr: f32) {
        self.lr = lr;
    }

    fn get_state(&self) -> Option<Self::State> {
        // Only support state if momentum is enabled (has velocities)
        if self.momentum == 0.0 && self.velocities.is_empty() {
            return None;
        }
        Some(self.get_state_internal())
    }

    fn restore_state(&mut self, state: Self::State, params: &[&Tensor]) -> Result<(), String> {
        self.restore_state_internal(state, params)
    }
}

/// Serializable optimizer state for SGD.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SGDState {
    /// Learning rate
    pub lr: f32,
    /// Momentum factor
    pub momentum: f32,
    /// Weight decay
    pub weight_decay: f32,
    /// Nesterov momentum enabled
    pub nesterov: bool,
    /// Velocity buffers (one Vec<f32> per parameter)
    pub velocities: Vec<Vec<f32>>,
}

impl SGD {
    /// Perform optimization step with direct tensor access.
    ///
    /// This is the recommended way to use SGD in a training loop.
    pub fn step_with_params(&mut self, params: &mut [&mut Tensor]) {
        // Initialize state for all parameters (even if no gradients)
        if !self.initialized || self.velocities.len() < params.len() {
            if self.velocities.len() < params.len() {
                self.velocities.resize(params.len(), Vec::new());
            }
            for (idx, param) in params.iter().enumerate() {
                if self.velocities[idx].is_empty() {
                    let param_data = param.data();
                    self.velocities[idx] = vec![0.0; param_data.len()];
                }
            }
        }

        for (idx, param) in params.iter_mut().enumerate() {
            self.update_param(param, idx);
        }
        self.initialized = true;
    }

    /// Get optimizer state for serialization (internal helper).
    fn get_state_internal(&self) -> SGDState {
        SGDState {
            lr: self.lr,
            momentum: self.momentum,
            weight_decay: self.weight_decay,
            nesterov: self.nesterov,
            velocities: self.velocities.clone(),
        }
    }

    /// Restore optimizer state from serialized representation (internal helper).
    fn restore_state_internal(
        &mut self,
        state: SGDState,
        params: &[&Tensor],
    ) -> Result<(), String> {
        if state.velocities.len() != params.len() {
            return Err(format!(
                "Parameter count mismatch: state has {}, model has {}",
                state.velocities.len(),
                params.len()
            ));
        }

        self.lr = state.lr;
        self.momentum = state.momentum;
        self.weight_decay = state.weight_decay;
        self.nesterov = state.nesterov;
        self.velocities = state.velocities;
        self.initialized = true;

        Ok(())
    }
}

/// Adam optimizer (Kingma & Ba, 2015).
///
/// Combines momentum with adaptive learning rates using first and second
/// moment estimates.
///
/// Update rule:
/// ```text
/// m_t = β₁ * m_{t-1} + (1 - β₁) * grad
/// v_t = β₂ * v_{t-1} + (1 - β₂) * grad²
/// m̂_t = m_t / (1 - β₁ᵗ)
/// v̂_t = v_t / (1 - β₂ᵗ)
/// param = param - lr * m̂_t / (√v̂_t + ε)
/// ```
#[derive(Debug)]
pub struct Adam {
    param_ids: Vec<TensorId>,
    lr: f32,
    beta1: f32,
    beta2: f32,
    eps: f32,
    weight_decay: f32,
    /// First moment estimates
    m: Vec<Vec<f32>>,
    /// Second moment estimates
    v: Vec<Vec<f32>>,
    /// Current timestep for bias correction
    t: usize,
    initialized: bool,
}

impl Adam {
    /// Create a new Adam optimizer with default hyperparameters.
    ///
    /// Default: β₁=0.9, β₂=0.999, ε=1e-8
    #[allow(clippy::needless_pass_by_value)]
    pub fn new(params: Vec<&mut Tensor>, lr: f32) -> Self {
        let param_ids: Vec<TensorId> = params.iter().map(|p| p.id()).collect();
        Self {
            param_ids,
            lr,
            beta1: 0.9,
            beta2: 0.999,
            eps: 1e-8,
            weight_decay: 0.0,
            m: Vec::new(),
            v: Vec::new(),
            t: 0,
            initialized: false,
        }
    }

    /// Set beta parameters.
    pub fn betas(mut self, beta1: f32, beta2: f32) -> Self {
        self.beta1 = beta1;
        self.beta2 = beta2;
        self
    }

    /// Set epsilon for numerical stability.
    pub fn eps(mut self, eps: f32) -> Self {
        self.eps = eps;
        self
    }

    /// Set weight decay (L2 regularization, applied to gradient).
    pub fn weight_decay(mut self, wd: f32) -> Self {
        self.weight_decay = wd;
        self
    }

    fn update_param(&mut self, param: &mut Tensor, idx: usize) {
        let Some(grad) = get_grad(param.id()) else {
            return;
        };

        let grad_data = grad.data();
        let param_data = param.data_mut();

        // Initialize state if needed
        if !self.initialized || idx >= self.m.len() {
            if idx >= self.m.len() {
                self.m.resize(idx + 1, Vec::new());
                self.v.resize(idx + 1, Vec::new());
            }
            self.m[idx] = vec![0.0; param_data.len()];
            self.v[idx] = vec![0.0; param_data.len()];
        }

        let m = &mut self.m[idx];
        let v = &mut self.v[idx];

        // Bias correction factors
        let bias_correction1 = 1.0 - self.beta1.powi(self.t as i32);
        let bias_correction2 = 1.0 - self.beta2.powi(self.t as i32);

        for i in 0..param_data.len() {
            let mut g = grad_data[i];

            // L2 regularization (applied to gradient, not decoupled)
            if self.weight_decay != 0.0 {
                g += self.weight_decay * param_data[i];
            }

            // Update biased first moment estimate
            m[i] = self.beta1 * m[i] + (1.0 - self.beta1) * g;

            // Update biased second moment estimate
            v[i] = self.beta2 * v[i] + (1.0 - self.beta2) * g * g;

            // Compute bias-corrected estimates
            let m_hat = m[i] / bias_correction1;
            let v_hat = v[i] / bias_correction2;

            // Update parameter
            param_data[i] -= self.lr * m_hat / (v_hat.sqrt() + self.eps);
        }
    }

    /// Perform optimization step with direct tensor access.
    pub fn step_with_params(&mut self, params: &mut [&mut Tensor]) {
        self.t += 1;

        // Initialize state for all parameters
        if !self.initialized || self.m.len() < params.len() {
            if self.m.len() < params.len() {
                self.m.resize(params.len(), Vec::new());
                self.v.resize(params.len(), Vec::new());
            }
            for (idx, param) in params.iter().enumerate() {
                if self.m[idx].is_empty() {
                    let param_data = param.data();
                    self.m[idx] = vec![0.0; param_data.len()];
                    self.v[idx] = vec![0.0; param_data.len()];
                }
            }
        }

        for (idx, param) in params.iter_mut().enumerate() {
            self.update_param(param, idx);
        }
        self.initialized = true;
    }

    /// Get optimizer state for serialization (internal helper).
    fn get_state_internal(&self) -> AdamState {
        AdamState {
            step: self.t,
            lr: self.lr,
            m: self.m.clone(),
            v: self.v.clone(),
            beta1: self.beta1,
            beta2: self.beta2,
            eps: self.eps,
            weight_decay: self.weight_decay,
        }
    }

    /// Restore optimizer state from serialized representation (internal helper).
    fn restore_state_internal(
        &mut self,
        state: AdamState,
        params: &[&Tensor],
    ) -> Result<(), String> {
        if state.m.len() != params.len() {
            return Err(format!(
                "Parameter count mismatch: state has {}, model has {}",
                state.m.len(),
                params.len()
            ));
        }

        self.t = state.step;
        self.lr = state.lr;
        self.m = state.m;
        self.v = state.v;
        self.beta1 = state.beta1;
        self.beta2 = state.beta2;
        self.eps = state.eps;
        self.weight_decay = state.weight_decay;
        self.initialized = true;

        Ok(())
    }
}

/// Serializable optimizer state for Adam.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AdamState {
    /// Step counter
    pub step: usize,
    /// Learning rate
    pub lr: f32,
    /// First moment estimates (one Vec<f32> per parameter)
    pub m: Vec<Vec<f32>>,
    /// Second moment estimates (one Vec<f32> per parameter)
    pub v: Vec<Vec<f32>>,
    /// Beta1 hyperparameter
    pub beta1: f32,
    /// Beta2 hyperparameter
    pub beta2: f32,
    /// Epsilon hyperparameter
    pub eps: f32,
    /// Weight decay hyperparameter
    pub weight_decay: f32,
}

impl Optimizer for Adam {
    type State = AdamState;

    fn step(&mut self) {
        self.t += 1;
        self.initialized = true;
    }

    fn zero_grad(&mut self) {
        for &id in &self.param_ids {
            crate::autograd::clear_grad(id);
        }
    }

    fn lr(&self) -> f32 {
        self.lr
    }

    fn set_lr(&mut self, lr: f32) {
        self.lr = lr;
    }

    fn get_state(&self) -> Option<Self::State> {
        Some(self.get_state_internal())
    }

    fn restore_state(&mut self, state: Self::State, params: &[&Tensor]) -> Result<(), String> {
        self.restore_state_internal(state, params)
    }
}

/// AdamW optimizer (Loshchilov & Hutter, 2019).
///
/// Like Adam but with decoupled weight decay, which is more effective
/// for regularization.
///
/// The key difference from Adam:
/// ```text
/// param = param - lr * weight_decay * param  // Decoupled weight decay
/// param = param - lr * m̂_t / (√v̂_t + ε)      // Then Adam update
/// ```
#[derive(Debug)]
pub struct AdamW {
    param_ids: Vec<TensorId>,
    lr: f32,
    beta1: f32,
    beta2: f32,
    eps: f32,
    weight_decay: f32,
    m: Vec<Vec<f32>>,
    v: Vec<Vec<f32>>,
    t: usize,
    initialized: bool,
}

/// Serializable optimizer state for AdamW.
///
/// This struct contains all optimizer state needed to resume training
/// from a checkpoint, including moment estimates (m, v) and step count.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AdamWState {
    /// Step counter
    pub step: usize,
    /// Learning rate
    pub lr: f32,
    /// First moment estimates (one Vec<f32> per parameter)
    pub m: Vec<Vec<f32>>,
    /// Second moment estimates (one Vec<f32> per parameter)
    pub v: Vec<Vec<f32>>,
    /// Beta1 hyperparameter
    pub beta1: f32,
    /// Beta2 hyperparameter
    pub beta2: f32,
    /// Epsilon hyperparameter
    pub eps: f32,
    /// Weight decay hyperparameter
    pub weight_decay: f32,
}

impl AdamW {
    /// Create a new AdamW optimizer.
    ///
    /// Default: β₁=0.9, β₂=0.999, ε=1e-8, weight_decay=0.01
    #[allow(clippy::needless_pass_by_value)]
    pub fn new(params: Vec<&mut Tensor>, lr: f32) -> Self {
        let param_ids: Vec<TensorId> = params.iter().map(|p| p.id()).collect();
        Self {
            param_ids,
            lr,
            beta1: 0.9,
            beta2: 0.999,
            eps: 1e-8,
            weight_decay: 0.01,
            m: Vec::new(),
            v: Vec::new(),
            t: 0,
            initialized: false,
        }
    }

    pub fn betas(mut self, beta1: f32, beta2: f32) -> Self {
        self.beta1 = beta1;
        self.beta2 = beta2;
        self
    }

    pub fn eps(mut self, eps: f32) -> Self {
        self.eps = eps;
        self
    }

    pub fn weight_decay(mut self, wd: f32) -> Self {
        self.weight_decay = wd;
        self
    }

    fn update_param(&mut self, param: &mut Tensor, idx: usize) {
        let Some(grad) = get_grad(param.id()) else {
            return;
        };

        let grad_data = grad.data();
        let param_data = param.data_mut();

        // Initialize state if needed
        if !self.initialized || idx >= self.m.len() {
            if idx >= self.m.len() {
                self.m.resize(idx + 1, Vec::new());
                self.v.resize(idx + 1, Vec::new());
            }
            self.m[idx] = vec![0.0; param_data.len()];
            self.v[idx] = vec![0.0; param_data.len()];
        }

        let m = &mut self.m[idx];
        let v = &mut self.v[idx];

        let bias_correction1 = 1.0 - self.beta1.powi(self.t as i32);
        let bias_correction2 = 1.0 - self.beta2.powi(self.t as i32);

        for i in 0..param_data.len() {
            let g = grad_data[i];

            // Update moment estimates (no weight decay in gradient)
            m[i] = self.beta1 * m[i] + (1.0 - self.beta1) * g;
            v[i] = self.beta2 * v[i] + (1.0 - self.beta2) * g * g;

            let m_hat = m[i] / bias_correction1;
            let v_hat = v[i] / bias_correction2;

            // Decoupled weight decay: applied directly to parameter
            param_data[i] -= self.lr * self.weight_decay * param_data[i];

            // Adam update
            param_data[i] -= self.lr * m_hat / (v_hat.sqrt() + self.eps);
        }
    }

    pub fn step_with_params(&mut self, params: &mut [&mut Tensor]) {
        self.t += 1;

        // Initialize state for all parameters (even if no gradients)
        // This ensures get_state() returns valid state
        if !self.initialized || self.m.len() < params.len() {
            if self.m.len() < params.len() {
                self.m.resize(params.len(), Vec::new());
                self.v.resize(params.len(), Vec::new());
            }
            for (idx, param) in params.iter().enumerate() {
                if self.m[idx].is_empty() {
                    let param_data = param.data();
                    self.m[idx] = vec![0.0; param_data.len()];
                    self.v[idx] = vec![0.0; param_data.len()];
                }
            }
        }

        for (idx, param) in params.iter_mut().enumerate() {
            self.update_param(param, idx);
        }
        self.initialized = true;
    }

    /// Get optimizer state for serialization (internal helper).
    fn get_state_internal(&self) -> AdamWState {
        AdamWState {
            step: self.t,
            lr: self.lr,
            m: self.m.clone(),
            v: self.v.clone(),
            beta1: self.beta1,
            beta2: self.beta2,
            eps: self.eps,
            weight_decay: self.weight_decay,
        }
    }

    /// Restore optimizer state from serialized representation (internal helper).
    fn restore_state_internal(
        &mut self,
        state: AdamWState,
        params: &[&Tensor],
    ) -> Result<(), String> {
        if state.m.len() != params.len() {
            return Err(format!(
                "Parameter count mismatch: state has {}, model has {}",
                state.m.len(),
                params.len()
            ));
        }

        // Verify param_ids match (optional, for safety)
        let current_ids: Vec<TensorId> = params.iter().map(|p| p.id()).collect();
        if current_ids != self.param_ids {
            // Log warning but continue (parameter order might have changed)
            eprintln!("Warning: Parameter IDs don't match, state may be invalid");
        }

        self.t = state.step;
        self.lr = state.lr;
        self.m = state.m;
        self.v = state.v;
        self.beta1 = state.beta1;
        self.beta2 = state.beta2;
        self.eps = state.eps;
        self.weight_decay = state.weight_decay;
        self.initialized = true;

        Ok(())
    }
}

impl Optimizer for AdamW {
    type State = AdamWState;

    fn step(&mut self) {
        self.t += 1;
        self.initialized = true;
    }

    fn zero_grad(&mut self) {
        for &id in &self.param_ids {
            crate::autograd::clear_grad(id);
        }
    }

    fn lr(&self) -> f32 {
        self.lr
    }

    fn set_lr(&mut self, lr: f32) {
        self.lr = lr;
    }

    fn get_state(&self) -> Option<Self::State> {
        Some(self.get_state_internal())
    }

    fn restore_state(&mut self, state: Self::State, params: &[&Tensor]) -> Result<(), String> {
        self.restore_state_internal(state, params)
    }
}

/// RMSprop optimizer.
///
/// Maintains a moving average of squared gradients for adaptive learning rates.
///
/// Update rule:
/// ```text
/// v_t = α * v_{t-1} + (1 - α) * grad²
/// param = param - lr * grad / (√v_t + ε)
/// ```
#[derive(Debug)]
pub struct RMSprop {
    param_ids: Vec<TensorId>,
    lr: f32,
    alpha: f32,
    eps: f32,
    weight_decay: f32,
    momentum: f32,
    /// Running average of squared gradients
    v: Vec<Vec<f32>>,
    /// Momentum buffer
    buffer: Vec<Vec<f32>>,
    initialized: bool,
}

impl RMSprop {
    /// Create a new RMSprop optimizer.
    ///
    /// Default: α=0.99, ε=1e-8
    #[allow(clippy::needless_pass_by_value)]
    pub fn new(params: Vec<&mut Tensor>, lr: f32) -> Self {
        let param_ids: Vec<TensorId> = params.iter().map(|p| p.id()).collect();
        Self {
            param_ids,
            lr,
            alpha: 0.99,
            eps: 1e-8,
            weight_decay: 0.0,
            momentum: 0.0,
            v: Vec::new(),
            buffer: Vec::new(),
            initialized: false,
        }
    }

    pub fn alpha(mut self, alpha: f32) -> Self {
        self.alpha = alpha;
        self
    }

    pub fn eps(mut self, eps: f32) -> Self {
        self.eps = eps;
        self
    }

    pub fn momentum(mut self, momentum: f32) -> Self {
        self.momentum = momentum;
        self
    }

    pub fn weight_decay(mut self, wd: f32) -> Self {
        self.weight_decay = wd;
        self
    }

    fn update_param(&mut self, param: &mut Tensor, idx: usize) {
        let Some(grad) = get_grad(param.id()) else {
            return;
        };

        let grad_data = grad.data();
        let param_data = param.data_mut();

        // Initialize state if needed
        if !self.initialized || idx >= self.v.len() {
            if idx >= self.v.len() {
                self.v.resize(idx + 1, Vec::new());
                self.buffer.resize(idx + 1, Vec::new());
            }
            self.v[idx] = vec![0.0; param_data.len()];
            self.buffer[idx] = vec![0.0; param_data.len()];
        }

        let v = &mut self.v[idx];
        let buffer = &mut self.buffer[idx];

        for i in 0..param_data.len() {
            let mut g = grad_data[i];

            // Weight decay
            if self.weight_decay != 0.0 {
                g += self.weight_decay * param_data[i];
            }

            // Update running average of squared gradients
            v[i] = self.alpha * v[i] + (1.0 - self.alpha) * g * g;

            // Compute update
            let update = g / (v[i].sqrt() + self.eps);

            if self.momentum > 0.0 {
                buffer[i] = self.momentum * buffer[i] + update;
                param_data[i] -= self.lr * buffer[i];
            } else {
                param_data[i] -= self.lr * update;
            }
        }
    }

    pub fn step_with_params(&mut self, params: &mut [&mut Tensor]) {
        // Initialize state for all parameters
        if !self.initialized || self.v.len() < params.len() {
            if self.v.len() < params.len() {
                self.v.resize(params.len(), Vec::new());
                self.buffer.resize(params.len(), Vec::new());
            }
            for (idx, param) in params.iter().enumerate() {
                if self.v[idx].is_empty() {
                    let param_data = param.data();
                    self.v[idx] = vec![0.0; param_data.len()];
                    self.buffer[idx] = vec![0.0; param_data.len()];
                }
            }
        }

        for (idx, param) in params.iter_mut().enumerate() {
            self.update_param(param, idx);
        }
        self.initialized = true;
    }

    /// Get optimizer state for serialization (internal helper).
    fn get_state_internal(&self) -> RMSpropState {
        RMSpropState {
            lr: self.lr,
            v: self.v.clone(),
            buffer: self.buffer.clone(),
            alpha: self.alpha,
            eps: self.eps,
            weight_decay: self.weight_decay,
            momentum: self.momentum,
        }
    }

    /// Restore optimizer state from serialized representation (internal helper).
    fn restore_state_internal(
        &mut self,
        state: RMSpropState,
        params: &[&Tensor],
    ) -> Result<(), String> {
        if state.v.len() != params.len() {
            return Err(format!(
                "Parameter count mismatch: state has {}, model has {}",
                state.v.len(),
                params.len()
            ));
        }

        self.lr = state.lr;
        self.v = state.v;
        self.buffer = state.buffer;
        self.alpha = state.alpha;
        self.eps = state.eps;
        self.weight_decay = state.weight_decay;
        self.momentum = state.momentum;
        self.initialized = true;

        Ok(())
    }
}

/// Serializable optimizer state for RMSprop.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RMSpropState {
    /// Learning rate
    pub lr: f32,
    /// Running average of squared gradients (one Vec<f32> per parameter)
    pub v: Vec<Vec<f32>>,
    /// Momentum buffer (one Vec<f32> per parameter)
    pub buffer: Vec<Vec<f32>>,
    /// Alpha hyperparameter
    pub alpha: f32,
    /// Epsilon hyperparameter
    pub eps: f32,
    /// Weight decay hyperparameter
    pub weight_decay: f32,
    /// Momentum hyperparameter
    pub momentum: f32,
}

impl Optimizer for RMSprop {
    type State = RMSpropState;

    fn step(&mut self) {
        self.initialized = true;
    }

    fn zero_grad(&mut self) {
        for &id in &self.param_ids {
            crate::autograd::clear_grad(id);
        }
    }

    fn lr(&self) -> f32 {
        self.lr
    }

    fn set_lr(&mut self, lr: f32) {
        self.lr = lr;
    }

    fn get_state(&self) -> Option<Self::State> {
        Some(self.get_state_internal())
    }

    fn restore_state(&mut self, state: Self::State, params: &[&Tensor]) -> Result<(), String> {
        self.restore_state_internal(state, params)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::autograd::clear_graph;

    #[test]
    fn test_sgd_basic() {
        clear_graph();

        // Create a simple tensor
        let mut param = Tensor::from_slice(&[1.0, 2.0, 3.0]).requires_grad();
        let param_id = param.id();

        // Simulate a loss: sum of squared elements
        let loss = param.pow(2.0).sum();
        loss.backward();

        // Check gradient exists
        let grad = get_grad(param_id).expect("Should have gradient");
        assert_eq!(grad.data(), &[2.0, 4.0, 6.0]); // d/dx(x²) = 2x

        // Create optimizer and step
        let mut sgd = SGD::new(vec![&mut param], 0.1);
        sgd.step_with_params(&mut [&mut param]);

        // param = param - lr * grad = [1, 2, 3] - 0.1 * [2, 4, 6] = [0.8, 1.6, 2.4]
        let expected = [0.8, 1.6, 2.4];
        for (p, e) in param.data().iter().zip(expected.iter()) {
            assert!((p - e).abs() < 1e-5, "Expected {e}, got {p}");
        }
    }

    #[test]
    fn test_sgd_with_momentum() {
        clear_graph();

        let mut param = Tensor::from_slice(&[1.0]).requires_grad();

        // First step
        let loss = param.pow(2.0).sum();
        loss.backward();

        let mut sgd = SGD::with_momentum(vec![&mut param], 0.1, 0.9);
        sgd.step_with_params(&mut [&mut param]);

        // v = 0.9 * 0 + 2.0 = 2.0
        // param = 1.0 - 0.1 * 2.0 = 0.8
        assert!((param.data()[0] - 0.8).abs() < 1e-5);

        // Second step
        clear_graph();
        let loss = param.pow(2.0).sum();
        loss.backward();

        sgd.step_with_params(&mut [&mut param]);

        // grad = 2 * 0.8 = 1.6
        // v = 0.9 * 2.0 + 1.6 = 3.4
        // param = 0.8 - 0.1 * 3.4 = 0.46
        assert!((param.data()[0] - 0.46).abs() < 1e-5);
    }

    #[test]
    fn test_adam_basic() {
        clear_graph();

        let mut param = Tensor::from_slice(&[1.0, 2.0]).requires_grad();

        let loss = param.pow(2.0).sum();
        loss.backward();

        let mut adam = Adam::new(vec![&mut param], 0.1);
        adam.step_with_params(&mut [&mut param]);

        // After one step, params should decrease
        assert!(param.data()[0] < 1.0);
        assert!(param.data()[1] < 2.0);
    }

    #[test]
    fn test_adam_convergence() {
        // Test that Adam can minimize a simple quadratic
        clear_graph();

        let mut param = Tensor::from_slice(&[5.0]).requires_grad();
        let mut adam = Adam::new(vec![&mut param], 0.5);

        // Minimize x² (optimal at x=0)
        for _ in 0..100 {
            clear_graph();
            let loss = param.pow(2.0).sum();
            loss.backward();
            adam.step_with_params(&mut [&mut param]);
        }

        // Should be close to 0
        assert!(
            param.data()[0].abs() < 0.1,
            "Parameter should converge to 0, got {}",
            param.data()[0]
        );
    }

    #[test]
    fn test_adamw_weight_decay() {
        clear_graph();

        let mut param = Tensor::from_slice(&[10.0]).requires_grad();

        // With zero gradient, only weight decay applies
        // We need a loss that has zero gradient at current point
        // Actually, let's just test the decoupled nature

        let loss = param.pow(2.0).sum();
        loss.backward();

        let mut adamw = AdamW::new(vec![&mut param], 0.1).weight_decay(0.1);
        adamw.step_with_params(&mut [&mut param]);

        // With weight decay, param should decrease more
        assert!(param.data()[0] < 10.0);
    }

    #[test]
    fn test_rmsprop_basic() {
        clear_graph();

        let mut param = Tensor::from_slice(&[3.0]).requires_grad();

        let loss = param.pow(2.0).sum();
        loss.backward();

        let mut rmsprop = RMSprop::new(vec![&mut param], 0.1);
        rmsprop.step_with_params(&mut [&mut param]);

        // Param should decrease
        assert!(param.data()[0] < 3.0);
    }

    #[test]
    fn test_zero_grad() {
        clear_graph();

        let mut param = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let param_id = param.id();

        let loss = param.pow(2.0).sum();
        loss.backward();

        // Gradient should exist
        assert!(get_grad(param_id).is_some());

        // Zero grad
        let mut sgd = SGD::new(vec![&mut param], 0.1);
        sgd.zero_grad();

        // Gradient should be cleared
        assert!(get_grad(param_id).is_none());
    }

    #[test]
    fn test_learning_rate_change() {
        let mut param = Tensor::from_slice(&[1.0]).requires_grad();
        let mut sgd = SGD::new(vec![&mut param], 0.1);

        assert!((sgd.lr() - 0.1).abs() < 1e-6);

        sgd.set_lr(0.01);
        assert!((sgd.lr() - 0.01).abs() < 1e-6);
    }

    #[test]
    fn test_adamw_get_state() {
        let mut param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let mut optimizer = AdamW::new(vec![&mut param1, &mut param2], 0.001);

        // Run a few steps to populate state
        // Note: step_with_params increments t and calls update_param which initializes m and v
        for _ in 0..3 {
            optimizer.zero_grad();
            // Simulate gradients by directly setting them in the graph
            let grad1 = Tensor::from_slice(&[0.1, 0.2]);
            let grad2 = Tensor::from_slice(&[0.3, 0.4]);
            param1.accumulate_grad(grad1);
            param2.accumulate_grad(grad2);
            optimizer.step_with_params(&mut [&mut param1, &mut param2]);
        }

        let state = optimizer.get_state().expect("should have state");
        assert_eq!(state.step, 3);
        assert!((state.lr - 0.001).abs() < 1e-6);
        // After step_with_params, m and v should be initialized
        assert_eq!(state.m.len(), 2);
        assert_eq!(state.v.len(), 2);
        assert_eq!(state.m[0].len(), 2); // param1 has 2 elements
        assert_eq!(state.m[1].len(), 2); // param2 has 2 elements
        assert_eq!(state.v[0].len(), 2);
        assert_eq!(state.v[1].len(), 2);
    }

    #[test]
    fn test_adamw_restore_state() {
        let mut param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let mut optimizer = AdamW::new(vec![&mut param1, &mut param2], 0.001);

        // Run a few steps
        for _ in 0..5 {
            optimizer.zero_grad();
            let grad1 = Tensor::from_slice(&[0.1, 0.2]);
            let grad2 = Tensor::from_slice(&[0.3, 0.4]);
            param1.accumulate_grad(grad1);
            param2.accumulate_grad(grad2);
            optimizer.step_with_params(&mut [&mut param1, &mut param2]);
        }

        // Save state
        let saved_state = optimizer.get_state().expect("should have state");
        assert_eq!(saved_state.step, 5);

        // Create new optimizer and restore state
        let mut new_param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut new_param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let mut new_optimizer = AdamW::new(vec![&mut new_param1, &mut new_param2], 0.001);

        new_optimizer
            .restore_state(saved_state.clone(), &[&new_param1, &new_param2])
            .expect("restore_state should succeed");

        let restored_state = new_optimizer.get_state().expect("should have state");
        assert_eq!(restored_state.step, 5);
        assert!((restored_state.lr - 0.001).abs() < 1e-6);
        assert_eq!(restored_state.m.len(), 2);
        assert_eq!(restored_state.v.len(), 2);
    }

    #[test]
    fn test_adamw_restore_state_parameter_mismatch() {
        let mut param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let optimizer = AdamW::new(vec![&mut param1, &mut param2], 0.001);

        let state = optimizer.get_state().expect("should have state");

        // Try to restore with wrong number of parameters
        let mut wrong_param = Tensor::from_slice(&[1.0]).requires_grad();
        let mut wrong_optimizer = AdamW::new(vec![&mut wrong_param], 0.001);

        let result = wrong_optimizer.restore_state(state, &[&wrong_param]);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Parameter count mismatch"));
    }

    #[test]
    fn test_sgd_get_state() {
        let mut param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let mut optimizer = SGD::with_momentum(vec![&mut param1, &mut param2], 0.01, 0.9);

        // Run a few steps
        for _ in 0..3 {
            optimizer.zero_grad();
            let grad1 = Tensor::from_slice(&[0.1, 0.2]);
            let grad2 = Tensor::from_slice(&[0.3, 0.4]);
            param1.accumulate_grad(grad1);
            param2.accumulate_grad(grad2);
            optimizer.step_with_params(&mut [&mut param1, &mut param2]);
        }

        let state = optimizer.get_state().expect("should have state");
        assert!((state.lr - 0.01).abs() < 1e-6);
        assert!((state.momentum - 0.9).abs() < 1e-6);
        assert_eq!(state.velocities.len(), 2);
    }

    #[test]
    fn test_adam_get_state() {
        let mut param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let mut optimizer = Adam::new(vec![&mut param1, &mut param2], 0.001);

        // Run a few steps
        for _ in 0..3 {
            optimizer.zero_grad();
            let grad1 = Tensor::from_slice(&[0.1, 0.2]);
            let grad2 = Tensor::from_slice(&[0.3, 0.4]);
            param1.accumulate_grad(grad1);
            param2.accumulate_grad(grad2);
            optimizer.step_with_params(&mut [&mut param1, &mut param2]);
        }

        let state = optimizer.get_state().expect("should have state");
        assert_eq!(state.step, 3);
        assert_eq!(state.m.len(), 2);
        assert_eq!(state.v.len(), 2);
    }

    #[test]
    fn test_rmsprop_get_state() {
        let mut param1 = Tensor::from_slice(&[1.0, 2.0]).requires_grad();
        let mut param2 = Tensor::from_slice(&[3.0, 4.0]).requires_grad();
        let mut optimizer = RMSprop::new(vec![&mut param1, &mut param2], 0.01).momentum(0.9);

        // Run a few steps
        for _ in 0..3 {
            optimizer.zero_grad();
            let grad1 = Tensor::from_slice(&[0.1, 0.2]);
            let grad2 = Tensor::from_slice(&[0.3, 0.4]);
            param1.accumulate_grad(grad1);
            param2.accumulate_grad(grad2);
            optimizer.step_with_params(&mut [&mut param1, &mut param2]);
        }

        let state = optimizer.get_state().expect("should have state");
        assert!((state.lr - 0.01).abs() < 1e-6);
        assert!((state.momentum - 0.9).abs() < 1e-6);
        assert_eq!(state.v.len(), 2);
        assert_eq!(state.buffer.len(), 2);
    }
}
