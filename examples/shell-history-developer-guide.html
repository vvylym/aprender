<!DOCTYPE HTML>
<html lang="en" class="rust" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Developer&#x27;s Guide: Shell History Models - EXTREME TDD - The Aprender Guide to Zero-Defect Machine Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="A comprehensive guide to EXTREME TDD methodology: RED-GREEN-REFACTOR cycles, mutation testing, and Toyota Way principles demonstrated through ML library development">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('rust')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Core Methodology</li><li class="chapter-item expanded "><a href="../methodology/what-is-extreme-tdd.html"><strong aria-hidden="true">1.</strong> What is EXTREME TDD?</a></li><li class="chapter-item expanded "><a href="../methodology/red-green-refactor.html"><strong aria-hidden="true">2.</strong> The RED-GREEN-REFACTOR Cycle</a></li><li class="chapter-item expanded "><a href="../methodology/test-first-philosophy.html"><strong aria-hidden="true">3.</strong> Test-First Philosophy</a></li><li class="chapter-item expanded "><a href="../methodology/zero-tolerance.html"><strong aria-hidden="true">4.</strong> Zero Tolerance Quality</a></li><li class="chapter-item expanded affix "><li class="part-title">The RED Phase</li><li class="chapter-item expanded "><a href="../red-phase/failing-tests-first.html"><strong aria-hidden="true">5.</strong> Writing Failing Tests First</a></li><li class="chapter-item expanded "><a href="../red-phase/test-categories.html"><strong aria-hidden="true">6.</strong> Test Categories</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../red-phase/unit-tests.html"><strong aria-hidden="true">6.1.</strong> Unit Tests</a></li><li class="chapter-item expanded "><a href="../red-phase/integration-tests.html"><strong aria-hidden="true">6.2.</strong> Integration Tests</a></li><li class="chapter-item expanded "><a href="../red-phase/property-based-tests.html"><strong aria-hidden="true">6.3.</strong> Property-Based Tests</a></li></ol></li><li class="chapter-item expanded "><a href="../red-phase/verification-strategy.html"><strong aria-hidden="true">7.</strong> Verification Strategy</a></li><li class="chapter-item expanded affix "><li class="part-title">The GREEN Phase</li><li class="chapter-item expanded "><a href="../green-phase/minimal-implementation.html"><strong aria-hidden="true">8.</strong> Minimal Implementation</a></li><li class="chapter-item expanded "><a href="../green-phase/making-tests-pass.html"><strong aria-hidden="true">9.</strong> Making Tests Pass</a></li><li class="chapter-item expanded "><a href="../green-phase/avoiding-over-engineering.html"><strong aria-hidden="true">10.</strong> Avoiding Over-Engineering</a></li><li class="chapter-item expanded "><a href="../green-phase/simplest-thing.html"><strong aria-hidden="true">11.</strong> The Simplest Thing That Works</a></li><li class="chapter-item expanded affix "><li class="part-title">The REFACTOR Phase</li><li class="chapter-item expanded "><a href="../refactor-phase/refactoring-with-confidence.html"><strong aria-hidden="true">12.</strong> Refactoring with Confidence</a></li><li class="chapter-item expanded "><a href="../refactor-phase/code-quality.html"><strong aria-hidden="true">13.</strong> Code Quality Improvements</a></li><li class="chapter-item expanded "><a href="../refactor-phase/performance-optimization.html"><strong aria-hidden="true">14.</strong> Performance Optimization</a></li><li class="chapter-item expanded "><a href="../refactor-phase/documentation.html"><strong aria-hidden="true">15.</strong> Documentation</a></li><li class="chapter-item expanded affix "><li class="part-title">Advanced Testing</li><li class="chapter-item expanded "><a href="../advanced-testing/popperian-falsification.html"><strong aria-hidden="true">16.</strong> Popperian Falsification</a></li><li class="chapter-item expanded "><a href="../advanced-testing/property-based-testing.html"><strong aria-hidden="true">17.</strong> Property-Based Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../advanced-testing/proptest-fundamentals.html"><strong aria-hidden="true">17.1.</strong> Proptest Fundamentals</a></li><li class="chapter-item expanded "><a href="../advanced-testing/strategies-generators.html"><strong aria-hidden="true">17.2.</strong> Strategies and Generators</a></li><li class="chapter-item expanded "><a href="../advanced-testing/testing-invariants.html"><strong aria-hidden="true">17.3.</strong> Testing Invariants</a></li></ol></li><li class="chapter-item expanded "><a href="../advanced-testing/mutation-testing.html"><strong aria-hidden="true">18.</strong> Mutation Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../advanced-testing/what-is-mutation-testing.html"><strong aria-hidden="true">18.1.</strong> What is Mutation Testing?</a></li><li class="chapter-item expanded "><a href="../advanced-testing/using-cargo-mutants.html"><strong aria-hidden="true">18.2.</strong> Using cargo-mutants</a></li><li class="chapter-item expanded "><a href="../advanced-testing/mutation-score-targets.html"><strong aria-hidden="true">18.3.</strong> Mutation Score Targets</a></li><li class="chapter-item expanded "><a href="../advanced-testing/killing-mutants.html"><strong aria-hidden="true">18.4.</strong> Killing Mutants</a></li></ol></li><li class="chapter-item expanded "><a href="../advanced-testing/fuzzing.html"><strong aria-hidden="true">19.</strong> Fuzzing</a></li><li class="chapter-item expanded "><a href="../advanced-testing/benchmark-testing.html"><strong aria-hidden="true">20.</strong> Benchmark Testing</a></li><li class="chapter-item expanded affix "><li class="part-title">Quality Gates</li><li class="chapter-item expanded "><a href="../quality-gates/pre-commit-hooks.html"><strong aria-hidden="true">21.</strong> Pre-Commit Hooks</a></li><li class="chapter-item expanded "><a href="../quality-gates/continuous-integration.html"><strong aria-hidden="true">22.</strong> Continuous Integration</a></li><li class="chapter-item expanded "><a href="../quality-gates/code-formatting.html"><strong aria-hidden="true">23.</strong> Code Formatting (rustfmt)</a></li><li class="chapter-item expanded "><a href="../quality-gates/linting-clippy.html"><strong aria-hidden="true">24.</strong> Linting (clippy)</a></li><li class="chapter-item expanded "><a href="../quality-gates/coverage-measurement.html"><strong aria-hidden="true">25.</strong> Coverage Measurement</a></li><li class="chapter-item expanded "><a href="../quality-gates/complexity-analysis.html"><strong aria-hidden="true">26.</strong> Complexity Analysis</a></li><li class="chapter-item expanded "><a href="../quality-gates/tdg-score.html"><strong aria-hidden="true">27.</strong> Technical Debt Gradient (TDG)</a></li><li class="chapter-item expanded affix "><li class="part-title">Toyota Way Principles</li><li class="chapter-item expanded "><a href="../toyota-way/overview.html"><strong aria-hidden="true">28.</strong> Overview</a></li><li class="chapter-item expanded "><a href="../toyota-way/kaizen.html"><strong aria-hidden="true">29.</strong> Kaizen (Continuous Improvement)</a></li><li class="chapter-item expanded "><a href="../toyota-way/genchi-genbutsu.html"><strong aria-hidden="true">30.</strong> Genchi Genbutsu (Go and See)</a></li><li class="chapter-item expanded "><a href="../toyota-way/jidoka.html"><strong aria-hidden="true">31.</strong> Jidoka (Built-in Quality)</a></li><li class="chapter-item expanded "><a href="../toyota-way/pdca-cycle.html"><strong aria-hidden="true">32.</strong> PDCA Cycle</a></li><li class="chapter-item expanded "><a href="../toyota-way/respect-for-people.html"><strong aria-hidden="true">33.</strong> Respect for People</a></li><li class="chapter-item expanded affix "><li class="part-title">Machine Learning Fundamentals</li><li class="chapter-item expanded "><a href="../ml-fundamentals/linear-regression.html"><strong aria-hidden="true">34.</strong> Linear Regression Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/regularization.html"><strong aria-hidden="true">35.</strong> Regularization Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/logistic-regression.html"><strong aria-hidden="true">36.</strong> Logistic Regression Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/knn.html"><strong aria-hidden="true">37.</strong> K-Nearest Neighbors (kNN) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/naive-bayes.html"><strong aria-hidden="true">38.</strong> Naive Bayes Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/bayesian-inference.html"><strong aria-hidden="true">39.</strong> Bayesian Inference Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/svm.html"><strong aria-hidden="true">40.</strong> Support Vector Machines (SVM) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/decision-trees.html"><strong aria-hidden="true">41.</strong> Decision Trees Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/ensemble-methods.html"><strong aria-hidden="true">42.</strong> Ensemble Methods Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/kmeans-clustering.html"><strong aria-hidden="true">43.</strong> K-Means Clustering Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/pca.html"><strong aria-hidden="true">44.</strong> Principal Component Analysis (PCA) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/tsne.html"><strong aria-hidden="true">45.</strong> t-SNE (t-Distributed Stochastic Neighbor Embedding) Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/regression-metrics.html"><strong aria-hidden="true">46.</strong> Regression Metrics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/classification-metrics.html"><strong aria-hidden="true">47.</strong> Classification Metrics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/cross-validation.html"><strong aria-hidden="true">48.</strong> Cross-Validation Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/gradient-descent.html"><strong aria-hidden="true">49.</strong> Gradient Descent Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/advanced-optimizers.html"><strong aria-hidden="true">50.</strong> Advanced Optimizers Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/metaheuristics.html"><strong aria-hidden="true">51.</strong> Metaheuristics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/automl.html"><strong aria-hidden="true">52.</strong> AutoML: Automated Machine Learning</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/compiler-in-the-loop.html"><strong aria-hidden="true">53.</strong> Compiler-in-the-Loop Learning</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/online-learning.html"><strong aria-hidden="true">54.</strong> Online Learning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/neuro-symbolic.html"><strong aria-hidden="true">55.</strong> Neuro-Symbolic Reasoning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/transfer-learning.html"><strong aria-hidden="true">56.</strong> Transfer Learning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/active-learning.html"><strong aria-hidden="true">57.</strong> Active Learning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/weak-supervision.html"><strong aria-hidden="true">58.</strong> Weak Supervision Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/automatic-differentiation.html"><strong aria-hidden="true">59.</strong> Automatic Differentiation Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-neural-networks.html"><strong aria-hidden="true">60.</strong> Graph Neural Networks Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/neural-network-pruning.html"><strong aria-hidden="true">61.</strong> Neural Network Pruning Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/lottery-ticket-hypothesis.html"><strong aria-hidden="true">62.</strong> Lottery Ticket Hypothesis Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/monte-carlo.html"><strong aria-hidden="true">63.</strong> Monte Carlo Simulation Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/speech-voice-processing.html"><strong aria-hidden="true">64.</strong> Speech and Voice Processing Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/probability-calibration.html"><strong aria-hidden="true">65.</strong> Probability Calibration Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/chaos-engineering.html"><strong aria-hidden="true">66.</strong> Chaos Engineering for ML</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/webassembly-ml.html"><strong aria-hidden="true">67.</strong> WebAssembly for ML</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/feature-scaling.html"><strong aria-hidden="true">68.</strong> Feature Scaling Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/audio-processing.html"><strong aria-hidden="true">69.</strong> Audio Processing Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-algorithms.html"><strong aria-hidden="true">70.</strong> Graph Algorithms Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-pathfinding.html"><strong aria-hidden="true">71.</strong> Graph Pathfinding Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-components-traversal.html"><strong aria-hidden="true">72.</strong> Graph Components and Traversal</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/graph-link-prediction.html"><strong aria-hidden="true">73.</strong> Graph Link Prediction and Community Detection</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/descriptive-statistics.html"><strong aria-hidden="true">74.</strong> Descriptive Statistics Theory</a></li><li class="chapter-item expanded "><a href="../ml-fundamentals/apriori.html"><strong aria-hidden="true">75.</strong> Apriori Algorithm Theory</a></li><li class="chapter-item expanded affix "><li class="part-title">Real-World Examples from Aprender</li><li class="chapter-item expanded "><a href="../examples/examples-reference.html"><strong aria-hidden="true">76.</strong> Examples Reference</a></li><li class="chapter-item expanded "><a href="../examples/linear-regression.html"><strong aria-hidden="true">77.</strong> Case Study: Linear Regression</a></li><li class="chapter-item expanded "><a href="../examples/boston-housing.html"><strong aria-hidden="true">78.</strong> Case Study: Boston Housing</a></li><li class="chapter-item expanded "><a href="../examples/cross-validation.html"><strong aria-hidden="true">79.</strong> Case Study: Cross-Validation</a></li><li class="chapter-item expanded "><a href="../examples/grid-search-tuning.html"><strong aria-hidden="true">80.</strong> Case Study: Grid Search Hyperparameter Tuning</a></li><li class="chapter-item expanded "><a href="../examples/automl-clustering.html"><strong aria-hidden="true">81.</strong> Case Study: AutoML Clustering (TPE)</a></li><li class="chapter-item expanded "><a href="../examples/random-forest.html"><strong aria-hidden="true">82.</strong> Case Study: Random Forest</a></li><li class="chapter-item expanded "><a href="../examples/random-forest-iris.html"><strong aria-hidden="true">83.</strong> Case Study: Random Forest Iris</a></li><li class="chapter-item expanded "><a href="../examples/random-forest-regression.html"><strong aria-hidden="true">84.</strong> Case Study: Random Forest Regression</a></li><li class="chapter-item expanded "><a href="../examples/decision-tree-iris.html"><strong aria-hidden="true">85.</strong> Case Study: Decision Tree Iris</a></li><li class="chapter-item expanded "><a href="../examples/decision-tree-regression.html"><strong aria-hidden="true">86.</strong> Case Study: Decision Tree Regression</a></li><li class="chapter-item expanded "><a href="../examples/model-serialization.html"><strong aria-hidden="true">87.</strong> Case Study: Model Serialization</a></li><li class="chapter-item expanded "><a href="../examples/model-format.html"><strong aria-hidden="true">88.</strong> Case Study: Model Format (.apr)</a></li><li class="chapter-item expanded "><a href="../examples/apr-format-deep-dive.html"><strong aria-hidden="true">89.</strong> The .apr Format: A Five Whys Deep Dive</a></li><li class="chapter-item expanded "><a href="../examples/model-bundling-paging.html"><strong aria-hidden="true">90.</strong> Case Study: Model Bundling and Memory Paging</a></li><li class="chapter-item expanded "><a href="../examples/tracing-memory-paging.html"><strong aria-hidden="true">91.</strong> Case Study: Tracing Memory Paging with Renacer</a></li><li class="chapter-item expanded "><a href="../examples/bundle-trace-demo.html"><strong aria-hidden="true">92.</strong> Case Study: Bundle Trace Demo</a></li><li class="chapter-item expanded "><a href="../examples/synthetic-data-generation.html"><strong aria-hidden="true">93.</strong> Case Study: Synthetic Data Generation</a></li><li class="chapter-item expanded "><a href="../examples/code-eda.html"><strong aria-hidden="true">94.</strong> Case Study: Code-Aware EDA</a></li><li class="chapter-item expanded "><a href="../examples/code-feature-extractor.html"><strong aria-hidden="true">95.</strong> Case Study: Code Feature Extraction</a></li><li class="chapter-item expanded "><a href="../examples/code-analysis.html"><strong aria-hidden="true">96.</strong> Case Study: Code Analysis with Code2Vec and MPNN</a></li><li class="chapter-item expanded "><a href="../examples/kmeans-clustering.html"><strong aria-hidden="true">97.</strong> Case Study: KMeans Clustering</a></li><li class="chapter-item expanded "><a href="../examples/dbscan-clustering.html"><strong aria-hidden="true">98.</strong> Case Study: DBSCAN Clustering</a></li><li class="chapter-item expanded "><a href="../examples/hierarchical-clustering.html"><strong aria-hidden="true">99.</strong> Case Study: Hierarchical Clustering</a></li><li class="chapter-item expanded "><a href="../examples/gmm-clustering.html"><strong aria-hidden="true">100.</strong> Case Study: GMM Clustering</a></li><li class="chapter-item expanded "><a href="../examples/iris-clustering.html"><strong aria-hidden="true">101.</strong> Case Study: Iris Clustering</a></li><li class="chapter-item expanded "><a href="../examples/logistic-regression.html"><strong aria-hidden="true">102.</strong> Case Study: Logistic Regression</a></li><li class="chapter-item expanded "><a href="../examples/knn-iris.html"><strong aria-hidden="true">103.</strong> Case Study: KNN Iris</a></li><li class="chapter-item expanded "><a href="../examples/naive-bayes-iris.html"><strong aria-hidden="true">104.</strong> Case Study: Naive Bayes Iris</a></li><li class="chapter-item expanded "><a href="../examples/beta-binomial-inference.html"><strong aria-hidden="true">105.</strong> Case Study: Beta-Binomial Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/gamma-poisson-inference.html"><strong aria-hidden="true">106.</strong> Case Study: Gamma-Poisson Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/normal-inverse-gamma-inference.html"><strong aria-hidden="true">107.</strong> Case Study: Normal-InverseGamma Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/dirichlet-multinomial-inference.html"><strong aria-hidden="true">108.</strong> Case Study: Dirichlet-Multinomial Bayesian Inference</a></li><li class="chapter-item expanded "><a href="../examples/bayesian-linear-regression.html"><strong aria-hidden="true">109.</strong> Case Study: Bayesian Linear Regression</a></li><li class="chapter-item expanded "><a href="../examples/bayesian-logistic-regression.html"><strong aria-hidden="true">110.</strong> Case Study: Bayesian Logistic Regression</a></li><li class="chapter-item expanded "><a href="../examples/negative-binomial-glm.html"><strong aria-hidden="true">111.</strong> Case Study: Negative Binomial GLM (Overdispersed Counts)</a></li><li class="chapter-item expanded "><a href="../examples/svm-iris.html"><strong aria-hidden="true">112.</strong> Case Study: SVM Iris</a></li><li class="chapter-item expanded "><a href="../examples/gbm-iris.html"><strong aria-hidden="true">113.</strong> Case Study: Gradient Boosting Iris</a></li><li class="chapter-item expanded "><a href="../examples/regularized-regression.html"><strong aria-hidden="true">114.</strong> Case Study: Regularized Regression</a></li><li class="chapter-item expanded "><a href="../examples/optimizer-demo.html"><strong aria-hidden="true">115.</strong> Case Study: Optimizer Demo</a></li><li class="chapter-item expanded "><a href="../examples/batch-optimization.html"><strong aria-hidden="true">116.</strong> Case Study: Batch Optimization</a></li><li class="chapter-item expanded "><a href="../examples/convex-optimization.html"><strong aria-hidden="true">117.</strong> Case Study: Convex Optimization (FISTA + Coordinate Descent)</a></li><li class="chapter-item expanded "><a href="../examples/constrained-optimization.html"><strong aria-hidden="true">118.</strong> Case Study: Constrained Optimization (Projected GD + Augmented Lagrangian + Interior Point)</a></li><li class="chapter-item expanded "><a href="../examples/admm-optimization.html"><strong aria-hidden="true">119.</strong> Case Study: ADMM Optimization (Distributed ML + Federated Learning)</a></li><li class="chapter-item expanded "><a href="../examples/differential-evolution.html"><strong aria-hidden="true">120.</strong> Case Study: Differential Evolution (Metaheuristics)</a></li><li class="chapter-item expanded "><a href="../examples/metaheuristics-optimization.html"><strong aria-hidden="true">121.</strong> Case Study: Metaheuristics Optimization</a></li><li class="chapter-item expanded "><a href="../examples/aco-tsp.html"><strong aria-hidden="true">122.</strong> Case Study: Ant Colony Optimization (TSP)</a></li><li class="chapter-item expanded "><a href="../examples/tabu-tsp.html"><strong aria-hidden="true">123.</strong> Case Study: Tabu Search (TSP)</a></li><li class="chapter-item expanded "><a href="../examples/tsp-solver-crate.html"><strong aria-hidden="true">124.</strong> Case Study: aprender-tsp Sub-Crate</a></li><li class="chapter-item expanded "><a href="../examples/predator-prey-optimization.html"><strong aria-hidden="true">125.</strong> Case Study: Predator-Prey Optimization</a></li><li class="chapter-item expanded "><a href="../examples/dataframe-basics.html"><strong aria-hidden="true">126.</strong> Case Study: DataFrame Basics</a></li><li class="chapter-item expanded "><a href="../examples/data-preprocessing-scalers.html"><strong aria-hidden="true">127.</strong> Case Study: Data Preprocessing with Scalers</a></li><li class="chapter-item expanded "><a href="../examples/graph-social-network.html"><strong aria-hidden="true">128.</strong> Case Study: Graph Social Network</a></li><li class="chapter-item expanded "><a href="../examples/community-detection.html"><strong aria-hidden="true">129.</strong> Case Study: Community Detection with Louvain</a></li><li class="chapter-item expanded "><a href="../examples/graph-algorithms-comprehensive.html"><strong aria-hidden="true">130.</strong> Case Study: Comprehensive Graph Algorithms</a></li><li class="chapter-item expanded "><a href="../examples/descriptive-statistics.html"><strong aria-hidden="true">131.</strong> Case Study: Descriptive Statistics</a></li><li class="chapter-item expanded "><a href="../examples/bayesian-blocks-histogram.html"><strong aria-hidden="true">132.</strong> Case Study: Bayesian Blocks Histogram</a></li><li class="chapter-item expanded "><a href="../examples/pca-iris.html"><strong aria-hidden="true">133.</strong> Case Study: PCA Iris</a></li><li class="chapter-item expanded "><a href="../examples/isolation-forest-anomaly.html"><strong aria-hidden="true">134.</strong> Case Study: Isolation Forest Anomaly Detection</a></li><li class="chapter-item expanded "><a href="../examples/lof-anomaly.html"><strong aria-hidden="true">135.</strong> Case Study: Local Outlier Factor (LOF)</a></li><li class="chapter-item expanded "><a href="../examples/spectral-clustering.html"><strong aria-hidden="true">136.</strong> Case Study: Spectral Clustering</a></li><li class="chapter-item expanded "><a href="../examples/tsne-visualization.html"><strong aria-hidden="true">137.</strong> Case Study: t-SNE Visualization</a></li><li class="chapter-item expanded "><a href="../examples/market-basket-apriori.html"><strong aria-hidden="true">138.</strong> Case Study: Market Basket Analysis (Apriori)</a></li><li class="chapter-item expanded "><a href="../examples/time-series-forecasting.html"><strong aria-hidden="true">139.</strong> Case Study: ARIMA Time Series Forecasting</a></li><li class="chapter-item expanded "><a href="../examples/text-preprocessing.html"><strong aria-hidden="true">140.</strong> Case Study: Text Preprocessing for NLP</a></li><li class="chapter-item expanded "><a href="../examples/text-classification.html"><strong aria-hidden="true">141.</strong> Case Study: Text Classification with TF-IDF</a></li><li class="chapter-item expanded "><a href="../examples/chat-template.html"><strong aria-hidden="true">142.</strong> Case Study: Chat Templates for LLM Inference</a></li><li class="chapter-item expanded "><a href="../examples/advanced-nlp.html"><strong aria-hidden="true">143.</strong> Case Study: Advanced NLP (Similarity, Entities, Summarization)</a></li><li class="chapter-item expanded "><a href="../examples/xor-neural-network.html"><strong aria-hidden="true">144.</strong> Case Study: XOR Neural Network (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../examples/xor-training.html"><strong aria-hidden="true">145.</strong> Case Study: XOR Training</a></li><li class="chapter-item expanded "><a href="../examples/neural-network-training.html"><strong aria-hidden="true">146.</strong> Case Study: Neural Network Training Pipeline</a></li><li class="chapter-item expanded "><a href="../examples/classification-training.html"><strong aria-hidden="true">147.</strong> Case Study: Classification Training</a></li><li class="chapter-item expanded "><a href="../examples/nlp-advanced.html"><strong aria-hidden="true">148.</strong> Case Study: Advanced NLP</a></li><li class="chapter-item expanded "><a href="../examples/topic-sentiment-analysis.html"><strong aria-hidden="true">149.</strong> Case Study: Topic & Sentiment Analysis</a></li><li class="chapter-item expanded "><a href="../examples/recommend-content.html"><strong aria-hidden="true">150.</strong> Case Study: Content-Based Recommendations</a></li><li class="chapter-item expanded "><a href="../examples/content-recommender.html"><strong aria-hidden="true">151.</strong> Case Study: Content-Based Recommender System</a></li><li class="chapter-item expanded "><a href="../examples/shell-completion.html"><strong aria-hidden="true">152.</strong> Case Study: AI Shell Completion</a></li><li class="chapter-item expanded "><a href="../examples/shell-completion-benchmarks.html"><strong aria-hidden="true">153.</strong> Case Study: Shell Completion Benchmarks</a></li><li class="chapter-item expanded "><a href="../examples/shell-hf-hub-publishing.html"><strong aria-hidden="true">154.</strong> Case Study: Publishing Shell Models to HF Hub</a></li><li class="chapter-item expanded "><a href="../examples/shell-encryption-tiers.html"><strong aria-hidden="true">155.</strong> Case Study: Model Encryption Tiers</a></li><li class="chapter-item expanded "><a href="../examples/shell-encryption-demo.html"><strong aria-hidden="true">156.</strong> Case Study: Shell Encryption Demo</a></li><li class="chapter-item expanded "><a href="../examples/shell-homomorphic-encryption.html"><strong aria-hidden="true">157.</strong> Case Study: Shell Homomorphic Encryption</a></li><li class="chapter-item expanded "><a href="../examples/shell-model-format.html"><strong aria-hidden="true">158.</strong> Case Study: Shell Model Format</a></li><li class="chapter-item expanded "><a href="../examples/mixture-of-experts.html"><strong aria-hidden="true">159.</strong> Case Study: Mixture of Experts (MoE)</a></li><li class="chapter-item expanded "><a href="../examples/shell-history-developer-guide.html" class="active"><strong aria-hidden="true">160.</strong> Developer's Guide: Shell History Models</a></li><li class="chapter-item expanded "><a href="../examples/custom-error-classifier.html"><strong aria-hidden="true">161.</strong> Building Custom Error Classifiers</a></li><li class="chapter-item expanded "><a href="../examples/citl-automated-repair.html"><strong aria-hidden="true">162.</strong> Case Study: CITL Automated Program Repair</a></li><li class="chapter-item expanded "><a href="../examples/batuta-integration.html"><strong aria-hidden="true">163.</strong> Case Study: Batuta - Automated Migration to Aprender</a></li><li class="chapter-item expanded "><a href="../examples/online-learning.html"><strong aria-hidden="true">164.</strong> Case Study: Online Learning and Dynamic Retraining</a></li><li class="chapter-item expanded "><a href="../examples/apr-loading-modes.html"><strong aria-hidden="true">165.</strong> Case Study: APR Loading Modes</a></li><li class="chapter-item expanded "><a href="../examples/apr-inspection.html"><strong aria-hidden="true">166.</strong> Case Study: APR Model Inspection</a></li><li class="chapter-item expanded "><a href="../examples/apr-scoring.html"><strong aria-hidden="true">167.</strong> Case Study: APR 100-Point Quality Scoring</a></li><li class="chapter-item expanded "><a href="../examples/poka-yoke-validation.html"><strong aria-hidden="true">168.</strong> Case Study: APR Poka-Yoke Validation</a></li><li class="chapter-item expanded "><a href="../examples/apr-cache.html"><strong aria-hidden="true">169.</strong> Case Study: APR Model Cache</a></li><li class="chapter-item expanded "><a href="../examples/apr-embed.html"><strong aria-hidden="true">170.</strong> Case Study: APR Data Embedding</a></li><li class="chapter-item expanded "><a href="../examples/apr-with-metadata.html"><strong aria-hidden="true">171.</strong> Case Study: APR with JSON Metadata</a></li><li class="chapter-item expanded "><a href="../examples/cuda-backend.html"><strong aria-hidden="true">172.</strong> Case Study: CUDA and GPU Backends</a></li><li class="chapter-item expanded "><a href="../examples/trueno-compute-integration.html"><strong aria-hidden="true">173.</strong> Case Study: Trueno Compute Integration</a></li><li class="chapter-item expanded "><a href="../examples/apr-cli-demo.html"><strong aria-hidden="true">174.</strong> Case Study: APR CLI Tool Demo</a></li><li class="chapter-item expanded "><a href="../examples/create-test-apr.html"><strong aria-hidden="true">175.</strong> Case Study: Create Test APR Files</a></li><li class="chapter-item expanded "><a href="../examples/apr-cli-commands.html"><strong aria-hidden="true">176.</strong> Case Study: APR CLI Commands Demo</a></li><li class="chapter-item expanded "><a href="../examples/model-zoo.html"><strong aria-hidden="true">177.</strong> Case Study: Model Zoo</a></li><li class="chapter-item expanded "><a href="../examples/sovereign-stack.html"><strong aria-hidden="true">178.</strong> Case Study: Sovereign AI Stack Integration</a></li><li class="chapter-item expanded "><a href="../examples/sovereign-offline.html"><strong aria-hidden="true">179.</strong> Case Study: Sovereign AI Offline Mode</a></li><li class="chapter-item expanded "><a href="../examples/explainability-audit.html"><strong aria-hidden="true">180.</strong> Case Study: Model Explainability and Audit Trails</a></li><li class="chapter-item expanded "><a href="../examples/model-serving.html"><strong aria-hidden="true">181.</strong> Case Study: Model Serving</a></li><li class="chapter-item expanded "><a href="../examples/federation-gateway.html"><strong aria-hidden="true">182.</strong> Case Study: Federation Gateway</a></li><li class="chapter-item expanded "><a href="../examples/federation-routing.html"><strong aria-hidden="true">183.</strong> Case Study: Federation Routing Policies</a></li><li class="chapter-item expanded "><a href="../examples/probar-tui-testing.html"><strong aria-hidden="true">184.</strong> Case Study: Probar TUI Testing</a></li><li class="chapter-item expanded "><a href="../examples/pipeline-verification.html"><strong aria-hidden="true">185.</strong> Case Study: Pipeline Verification</a></li><li class="chapter-item expanded "><a href="../examples/state-machine-playbooks.html"><strong aria-hidden="true">186.</strong> Case Study: State Machine Playbooks</a></li><li class="chapter-item expanded "><a href="../examples/tensorlogic-reasoning.html"><strong aria-hidden="true">187.</strong> Case Study: TensorLogic Neuro-Symbolic Reasoning</a></li><li class="chapter-item expanded "><a href="../examples/audio-mel-spectrogram.html"><strong aria-hidden="true">188.</strong> Case Study: Audio Mel Spectrogram Processing</a></li><li class="chapter-item expanded "><a href="../examples/monte-carlo-simulation.html"><strong aria-hidden="true">189.</strong> Case Study: Monte Carlo Financial Simulation</a></li><li class="chapter-item expanded "><a href="../examples/autograd-training.html"><strong aria-hidden="true">190.</strong> Case Study: Automatic Differentiation Training</a></li><li class="chapter-item expanded "><a href="../examples/gnn-node-classification.html"><strong aria-hidden="true">191.</strong> Case Study: Graph Neural Networks</a></li><li class="chapter-item expanded "><a href="../examples/pruning-magnitude.html"><strong aria-hidden="true">192.</strong> Case Study: Magnitude Pruning</a></li><li class="chapter-item expanded "><a href="../examples/lottery-ticket-pruning.html"><strong aria-hidden="true">193.</strong> Case Study: Lottery Ticket Pruning</a></li><li class="chapter-item expanded "><a href="../examples/bench-comparison.html"><strong aria-hidden="true">194.</strong> Case Study: Benchmark Comparison</a></li><li class="chapter-item expanded "><a href="../examples/showcase-benchmark.html"><strong aria-hidden="true">195.</strong> Case Study: Showcase Benchmark</a></li><li class="chapter-item expanded "><a href="../examples/qa-falsification.html"><strong aria-hidden="true">196.</strong> Case Study: QA Falsification Protocol</a></li><li class="chapter-item expanded "><a href="../examples/qwen-qa-playbook.html"><strong aria-hidden="true">197.</strong> Case Study: Qwen2.5-Coder QA Playbook</a></li><li class="chapter-item expanded "><a href="../examples/ptx-parity-validation.html"><strong aria-hidden="true">198.</strong> Case Study: PTX Parity Validation (GH-219)</a></li><li class="chapter-item expanded "><a href="../examples/hex-forensics.html"><strong aria-hidden="true">199.</strong> Case Study: Hex Forensics — Binary Model Inspection</a></li><li class="chapter-item expanded "><a href="../examples/rosetta-stone.html"><strong aria-hidden="true">200.</strong> Case Study: Rosetta Stone — Universal Format Converter</a></li><li class="chapter-item expanded "><a href="../examples/validated-tensors.html"><strong aria-hidden="true">201.</strong> Case Study: Validated Tensors — Compile-Time Contracts</a></li><li class="chapter-item expanded "><a href="../examples/qwen-inference.html"><strong aria-hidden="true">202.</strong> Case Study: Qwen Inference with realizar</a></li><li class="chapter-item expanded "><a href="../examples/sharded-safetensors-serve.html"><strong aria-hidden="true">203.</strong> Case Study: Sharded SafeTensors Serving (GH-213)</a></li><li class="chapter-item expanded "><a href="../examples/model-merge-strategies.html"><strong aria-hidden="true">204.</strong> Case Study: Model Merge Strategies (GH-245)</a></li><li class="chapter-item expanded affix "><li class="part-title">Sprint-Based Development</li><li class="chapter-item expanded "><a href="../sprints/sprint-planning.html"><strong aria-hidden="true">205.</strong> Sprint Planning</a></li><li class="chapter-item expanded "><a href="../sprints/sprint-execution.html"><strong aria-hidden="true">206.</strong> Sprint Execution</a></li><li class="chapter-item expanded "><a href="../sprints/sprint-review.html"><strong aria-hidden="true">207.</strong> Sprint Review</a></li><li class="chapter-item expanded "><a href="../sprints/sprint-retrospective.html"><strong aria-hidden="true">208.</strong> Sprint Retrospective</a></li><li class="chapter-item expanded "><a href="../sprints/issue-management.html"><strong aria-hidden="true">209.</strong> Issue Management</a></li><li class="chapter-item expanded affix "><li class="part-title">Anti-Hallucination Enforcement</li><li class="chapter-item expanded "><a href="../anti-hallucination/test-backed-examples.html"><strong aria-hidden="true">210.</strong> Test-Backed Examples</a></li><li class="chapter-item expanded "><a href="../anti-hallucination/example-verification.html"><strong aria-hidden="true">211.</strong> Example Verification</a></li><li class="chapter-item expanded "><a href="../anti-hallucination/ci-validation.html"><strong aria-hidden="true">212.</strong> CI Validation</a></li><li class="chapter-item expanded "><a href="../anti-hallucination/documentation-testing.html"><strong aria-hidden="true">213.</strong> Documentation Testing</a></li><li class="chapter-item expanded affix "><li class="part-title">Tools and Setup</li><li class="chapter-item expanded "><a href="../tools/development-environment.html"><strong aria-hidden="true">214.</strong> Development Environment</a></li><li class="chapter-item expanded "><a href="../tools/cargo-test.html"><strong aria-hidden="true">215.</strong> cargo test</a></li><li class="chapter-item expanded "><a href="../tools/cargo-clippy.html"><strong aria-hidden="true">216.</strong> cargo clippy</a></li><li class="chapter-item expanded "><a href="../tools/cargo-fmt.html"><strong aria-hidden="true">217.</strong> cargo fmt</a></li><li class="chapter-item expanded "><a href="../tools/cargo-mutants.html"><strong aria-hidden="true">218.</strong> cargo mutants</a></li><li class="chapter-item expanded "><a href="../tools/proptest.html"><strong aria-hidden="true">219.</strong> proptest</a></li><li class="chapter-item expanded "><a href="../tools/criterion.html"><strong aria-hidden="true">220.</strong> criterion</a></li><li class="chapter-item expanded "><a href="../tools/pmat.html"><strong aria-hidden="true">221.</strong> pmat (Toyota AI Toolkit)</a></li><li class="chapter-item expanded "><a href="../tools/apr-cli.html"><strong aria-hidden="true">222.</strong> apr (APR Model Operations CLI)</a></li><li class="chapter-item expanded "><a href="../tools/apr-spec.html"><strong aria-hidden="true">223.</strong> APR Format Specification</a></li><li class="chapter-item expanded affix "><li class="part-title">Best Practices</li><li class="chapter-item expanded "><a href="../best-practices/error-handling.html"><strong aria-hidden="true">224.</strong> Error Handling</a></li><li class="chapter-item expanded "><a href="../best-practices/api-design.html"><strong aria-hidden="true">225.</strong> API Design</a></li><li class="chapter-item expanded "><a href="../best-practices/builder-pattern.html"><strong aria-hidden="true">226.</strong> Builder Pattern</a></li><li class="chapter-item expanded "><a href="../best-practices/type-safety.html"><strong aria-hidden="true">227.</strong> Type Safety</a></li><li class="chapter-item expanded "><a href="../best-practices/performance.html"><strong aria-hidden="true">228.</strong> Performance Considerations</a></li><li class="chapter-item expanded "><a href="../best-practices/documentation-standards.html"><strong aria-hidden="true">229.</strong> Documentation Standards</a></li><li class="chapter-item expanded affix "><li class="part-title">Metrics and Measurement</li><li class="chapter-item expanded "><a href="../metrics/test-coverage.html"><strong aria-hidden="true">230.</strong> Test Coverage</a></li><li class="chapter-item expanded "><a href="../metrics/mutation-score.html"><strong aria-hidden="true">231.</strong> Mutation Score</a></li><li class="chapter-item expanded "><a href="../metrics/cyclomatic-complexity.html"><strong aria-hidden="true">232.</strong> Cyclomatic Complexity</a></li><li class="chapter-item expanded "><a href="../metrics/code-churn.html"><strong aria-hidden="true">233.</strong> Code Churn</a></li><li class="chapter-item expanded "><a href="../metrics/build-times.html"><strong aria-hidden="true">234.</strong> Build Times</a></li><li class="chapter-item expanded "><a href="../metrics/tdg-breakdown.html"><strong aria-hidden="true">235.</strong> TDG Score Breakdown</a></li><li class="chapter-item expanded affix "><li class="part-title">Common Pitfalls</li><li class="chapter-item expanded "><a href="../pitfalls/skipping-tests.html"><strong aria-hidden="true">236.</strong> Skipping Tests</a></li><li class="chapter-item expanded "><a href="../pitfalls/insufficient-coverage.html"><strong aria-hidden="true">237.</strong> Insufficient Test Coverage</a></li><li class="chapter-item expanded "><a href="../pitfalls/ignoring-warnings.html"><strong aria-hidden="true">238.</strong> Ignoring Warnings</a></li><li class="chapter-item expanded "><a href="../pitfalls/over-mocking.html"><strong aria-hidden="true">239.</strong> Over-Mocking</a></li><li class="chapter-item expanded "><a href="../pitfalls/flaky-tests.html"><strong aria-hidden="true">240.</strong> Flaky Tests</a></li><li class="chapter-item expanded "><a href="../pitfalls/technical-debt.html"><strong aria-hidden="true">241.</strong> Technical Debt Accumulation</a></li><li class="chapter-item expanded affix "><li class="part-title">Appendix</li><li class="chapter-item expanded "><a href="../appendix/glossary.html"><strong aria-hidden="true">242.</strong> Glossary</a></li><li class="chapter-item expanded "><a href="../appendix/references.html"><strong aria-hidden="true">243.</strong> References</a></li><li class="chapter-item expanded "><a href="../appendix/further-reading.html"><strong aria-hidden="true">244.</strong> Further Reading</a></li><li class="chapter-item expanded "><a href="../appendix/contributing.html"><strong aria-hidden="true">245.</strong> Contributing to This Book</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">EXTREME TDD - The Aprender Guide to Zero-Defect Machine Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/aprender" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/aprender/edit/main/book/src/examples/shell-history-developer-guide.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="developers-guide-to-shell-history-models"><a class="header" href="#developers-guide-to-shell-history-models">Developer's Guide to Shell History Models</a></h1>
<p>Build personalized ML models from your shell history using the <code>.apr</code> format. This guide follows <strong>EXTREME TDD</strong> methodology—every code example compiles and runs.</p>
<h2 id="why-shell-history-is-perfect-for-ml"><a class="header" href="#why-shell-history-is-perfect-for-ml">Why Shell History is Perfect for ML</a></h2>
<p>Shell commands exhibit strong <strong>Markov properties</strong>:</p>
<pre><code class="language-text">P(next_token | all_previous) ≈ P(next_token | last_n_tokens)
</code></pre>
<p>Translation: What you type next depends mostly on your last few words, not your entire history.</p>
<p><strong>Evidence from real data:</strong></p>
<ul>
<li><code>git</code> → 65% followed by <code>status</code>, <code>commit</code>, <code>push</code>, <code>pull</code></li>
<li><code>cargo</code> → 70% followed by <code>build</code>, <code>test</code>, <code>run</code>, <code>clippy</code></li>
<li><code>cd</code> → 80% followed by <code>..</code>, project names, or <code>~</code></li>
</ul>
<p>This predictability makes N-gram models highly effective with minimal compute.</p>
<h2 id="part-1-first-principles---building-from-scratch"><a class="header" href="#part-1-first-principles---building-from-scratch">Part 1: First Principles - Building from Scratch</a></h2>
<h3 id="step-1-define-the-core-data-structure-red"><a class="header" href="#step-1-define-the-core-data-structure-red">Step 1: Define the Core Data Structure (RED)</a></h3>
<pre><code class="language-rust">use std::collections::HashMap;

/// N-gram frequency table
/// Maps context (previous n-1 tokens) → next token → count
#[derive(Default)]
struct NgramTable {
    /// context → (next_token → frequency)
    table: HashMap&lt;String, HashMap&lt;String, u32&gt;&gt;,
}

impl NgramTable {
    fn new() -&gt; Self {
        Self::default()
    }

    /// Record an observation: given context, next token appeared
    fn observe(&amp;mut self, context: &amp;str, next_token: &amp;str) {
        self.table
            .entry(context.to_string())
            .or_default()
            .entry(next_token.to_string())
            .and_modify(|c| *c += 1)
            .or_insert(1);
    }

    /// Get probability distribution for context
    fn predict(&amp;self, context: &amp;str) -&gt; Vec&lt;(String, f32)&gt; {
        let Some(counts) = self.table.get(context) else {
            return vec![];
        };

        let total: u32 = counts.values().sum();
        let mut probs: Vec&lt;_&gt; = counts
            .iter()
            .map(|(token, count)| {
                (token.clone(), *count as f32 / total as f32)
            })
            .collect();

        // Sort by probability descending
        probs.sort_by(|a, b| b.1.partial_cmp(&amp;a.1).unwrap());
        probs
    }
}

// Test: Empty table returns empty predictions
let table = NgramTable::new();
assert!(table.predict(&quot;git&quot;).is_empty());

// Test: Single observation
let mut table = NgramTable::new();
table.observe(&quot;git&quot;, &quot;status&quot;);
let preds = table.predict(&quot;git&quot;);
assert_eq!(preds.len(), 1);
assert_eq!(preds[0].0, &quot;status&quot;);
assert!((preds[0].1 - 1.0).abs() &lt; 0.001); // 100% probability</code></pre>
<h3 id="step-2-train-on-command-sequences-green"><a class="header" href="#step-2-train-on-command-sequences-green">Step 2: Train on Command Sequences (GREEN)</a></h3>
<pre><code class="language-rust">use std::collections::HashMap;

#[derive(Default)]
struct NgramTable {
    table: HashMap&lt;String, HashMap&lt;String, u32&gt;&gt;,
    n: usize,
}

impl NgramTable {
    fn with_n(n: usize) -&gt; Self {
        Self { table: HashMap::new(), n: n.max(2) }
    }

    fn observe(&amp;mut self, context: &amp;str, next_token: &amp;str) {
        self.table
            .entry(context.to_string())
            .or_default()
            .entry(next_token.to_string())
            .and_modify(|c| *c += 1)
            .or_insert(1);
    }

    /// Train on a single command
    fn train_command(&amp;mut self, command: &amp;str) {
        let tokens: Vec&lt;&amp;str&gt; = command.split_whitespace().collect();
        if tokens.is_empty() {
            return;
        }

        // Empty context predicts first token
        self.observe(&quot;&quot;, tokens[0]);

        // Build n-grams from token sequence
        for i in 0..tokens.len() {
            let context_start = i.saturating_sub(self.n - 1);
            let context = tokens[context_start..=i].join(&quot; &quot;);

            if i + 1 &lt; tokens.len() {
                self.observe(&amp;context, tokens[i + 1]);
            }
        }
    }

    fn predict(&amp;self, context: &amp;str) -&gt; Vec&lt;(String, f32)&gt; {
        let Some(counts) = self.table.get(context) else {
            return vec![];
        };
        let total: u32 = counts.values().sum();
        let mut probs: Vec&lt;_&gt; = counts
            .iter()
            .map(|(t, c)| (t.clone(), *c as f32 / total as f32))
            .collect();
        probs.sort_by(|a, b| b.1.partial_cmp(&amp;a.1).unwrap());
        probs
    }
}

// Train on real command patterns
let mut model = NgramTable::with_n(3);

let commands = [
    &quot;git status&quot;,
    &quot;git commit -m fix&quot;,
    &quot;git push&quot;,
    &quot;git status&quot;,      // Repeated - should have higher probability
    &quot;git status&quot;,
    &quot;cargo build&quot;,
    &quot;cargo test&quot;,
    &quot;cargo build&quot;,     // Repeated
];

for cmd in &amp;commands {
    model.train_command(cmd);
}

// Test: &quot;git&quot; context should predict &quot;status&quot; highest (3x vs 1x each)
let preds = model.predict(&quot;git&quot;);
assert!(!preds.is_empty());
assert_eq!(preds[0].0, &quot;status&quot;); // Most frequent

// Test: &quot;cargo&quot; context
let preds = model.predict(&quot;cargo&quot;);
assert_eq!(preds[0].0, &quot;build&quot;); // 2x vs 1x for test

// Test: Empty context predicts first tokens
let preds = model.predict(&quot;&quot;);
assert!(preds.iter().any(|(t, _)| t == &quot;git&quot;));
assert!(preds.iter().any(|(t, _)| t == &quot;cargo&quot;));</code></pre>
<h3 id="step-3-add-prefix-trie-for-o1-lookup-refactor"><a class="header" href="#step-3-add-prefix-trie-for-o1-lookup-refactor">Step 3: Add Prefix Trie for O(1) Lookup (REFACTOR)</a></h3>
<pre><code class="language-rust">use std::collections::HashMap;

/// Trie node for prefix matching
#[derive(Default)]
struct TrieNode {
    children: HashMap&lt;char, TrieNode&gt;,
    is_end: bool,
    count: u32,
}

/// Trie for fast prefix-based command lookup
#[derive(Default)]
struct Trie {
    root: TrieNode,
}

impl Trie {
    fn new() -&gt; Self {
        Self::default()
    }

    fn insert(&amp;mut self, word: &amp;str) {
        let mut node = &amp;mut self.root;
        for ch in word.chars() {
            node = node.children.entry(ch).or_default();
        }
        node.is_end = true;
        node.count += 1;
    }

    /// Find completions for prefix, sorted by frequency
    fn find_prefix(&amp;self, prefix: &amp;str, limit: usize) -&gt; Vec&lt;(String, u32)&gt; {
        // Navigate to prefix node
        let mut node = &amp;self.root;
        for ch in prefix.chars() {
            match node.children.get(&amp;ch) {
                Some(n) =&gt; node = n,
                None =&gt; return vec![],
            }
        }

        // Collect all completions
        let mut results = Vec::new();
        self.collect(node, prefix.to_string(), &amp;mut results, limit * 10);

        // Sort by frequency and take top N
        results.sort_by(|a, b| b.1.cmp(&amp;a.1));
        results.truncate(limit);
        results
    }

    fn collect(&amp;self, node: &amp;TrieNode, current: String, results: &amp;mut Vec&lt;(String, u32)&gt;, limit: usize) {
        if results.len() &gt;= limit {
            return;
        }
        if node.is_end {
            results.push((current.clone(), node.count));
        }
        for (ch, child) in &amp;node.children {
            let mut next = current.clone();
            next.push(*ch);
            self.collect(child, next, results, limit);
        }
    }
}

// Test: Basic insertion and lookup
let mut trie = Trie::new();
trie.insert(&quot;git status&quot;);
trie.insert(&quot;git commit&quot;);
trie.insert(&quot;git push&quot;);

let results = trie.find_prefix(&quot;git &quot;, 10);
assert_eq!(results.len(), 3);

// Test: Frequency ordering
let mut trie = Trie::new();
trie.insert(&quot;git status&quot;);
trie.insert(&quot;git status&quot;);
trie.insert(&quot;git status&quot;);
trie.insert(&quot;git commit&quot;);

let results = trie.find_prefix(&quot;git &quot;, 10);
assert_eq!(results[0].0, &quot;git status&quot;);
assert_eq!(results[0].1, 3); // Appeared 3 times

// Test: No match returns empty
let results = trie.find_prefix(&quot;docker &quot;, 10);
assert!(results.is_empty());</code></pre>
<h2 id="part-2-the-apr-format-integration"><a class="header" href="#part-2-the-apr-format-integration">Part 2: The .apr Format Integration</a></h2>
<h3 id="saving-models-with-aprender"><a class="header" href="#saving-models-with-aprender">Saving Models with aprender</a></h3>
<p>The <code>.apr</code> format provides:</p>
<ul>
<li><strong>32-byte header</strong> with magic, version, CRC32</li>
<li><strong>MessagePack metadata</strong> for model info</li>
<li><strong>Bincode payload</strong> for efficient serialization</li>
<li><strong>Optional encryption</strong> for privacy</li>
</ul>
<pre><code class="language-rust ignore">use aprender::format::{save, load, ModelType, SaveOptions};
use serde::{Serialize, Deserialize};
use std::collections::HashMap;

#[derive(Serialize, Deserialize)]
struct ShellModel {
    n: usize,
    ngrams: HashMap&lt;String, HashMap&lt;String, u32&gt;&gt;,
    total_commands: usize,
}

impl ShellModel {
    fn new(n: usize) -&gt; Self {
        Self {
            n,
            ngrams: HashMap::new(),
            total_commands: 0,
        }
    }

    fn train(&amp;mut self, commands: &amp;[String]) {
        self.total_commands = commands.len();
        for cmd in commands {
            let tokens: Vec&lt;&amp;str&gt; = cmd.split_whitespace().collect();
            if tokens.is_empty() {
                continue;
            }

            // Empty context → first token
            self.ngrams
                .entry(String::new())
                .or_default()
                .entry(tokens[0].to_string())
                .and_modify(|c| *c += 1)
                .or_insert(1);

            // Build context n-grams
            for i in 0..tokens.len() {
                let start = i.saturating_sub(self.n - 1);
                let context = tokens[start..=i].join(&quot; &quot;);
                if i + 1 &lt; tokens.len() {
                    self.ngrams
                        .entry(context)
                        .or_default()
                        .entry(tokens[i + 1].to_string())
                        .and_modify(|c| *c += 1)
                        .or_insert(1);
                }
            }
        }
    }
}

// Create and train model
let mut model = ShellModel::new(3);
model.train(&amp;[
    &quot;git status&quot;.to_string(),
    &quot;git commit -m test&quot;.to_string(),
    &quot;cargo build&quot;.to_string(),
]);

// Save to .apr format
let options = SaveOptions::default()
    .with_name(&quot;my-shell-model&quot;)
    .with_description(&quot;3-gram shell completion model&quot;);

save(&amp;model, ModelType::Custom, &quot;shell.apr&quot;, options)?;

// Load and verify
let loaded: ShellModel = load(&quot;shell.apr&quot;, ModelType::Custom)?;
assert_eq!(loaded.n, 3);
assert_eq!(loaded.total_commands, 3);</code></pre>
<h3 id="inspecting-apr-files"><a class="header" href="#inspecting-apr-files">Inspecting .apr Files</a></h3>
<pre><code class="language-bash"># View model metadata
apr inspect shell.apr

# Output:
# Model: my-shell-model
# Type: Custom
# Description: 3-gram shell completion model
# Created: 2025-11-26T15:30:00Z
# Size: 2.1 KB
# Checksum: CRC32 valid
</code></pre>
<h2 id="part-3-encryption-for-privacy"><a class="header" href="#part-3-encryption-for-privacy">Part 3: Encryption for Privacy</a></h2>
<p>Shell history contains sensitive patterns. Encrypt your models:</p>
<pre><code class="language-rust ignore">use aprender::format::{save_encrypted, load_encrypted, ModelType, SaveOptions};

// Save with password encryption (AES-256-GCM + Argon2id)
let options = SaveOptions::default()
    .with_name(&quot;private-shell-model&quot;)
    .with_description(&quot;Encrypted personal shell history model&quot;);

save_encrypted(&amp;model, ModelType::Custom, &quot;shell.apr&quot;, options, &quot;my-password&quot;)?;

// Load requires password
let loaded: ShellModel = load_encrypted(&quot;shell.apr&quot;, ModelType::Custom, &quot;my-password&quot;)?;

// Wrong password fails with DecryptionFailed error
let result: Result&lt;ShellModel, _&gt; = load_encrypted(&quot;shell.apr&quot;, ModelType::Custom, &quot;wrong&quot;);
assert!(result.is_err());</code></pre>
<h3 id="recipient-encryption-x25519"><a class="header" href="#recipient-encryption-x25519">Recipient Encryption (X25519)</a></h3>
<p>For sharing models with specific people:</p>
<pre><code class="language-rust ignore">use aprender::format::{save_for_recipient, load_as_recipient, ModelType, SaveOptions};
use aprender::format::x25519::{generate_keypair, PublicKey, SecretKey};

// Generate recipient keypair (they share public key with you)
let (recipient_secret, recipient_public) = generate_keypair();

// Save encrypted for specific recipient
let options = SaveOptions::default()
    .with_name(&quot;team-shell-model&quot;);

save_for_recipient(&amp;model, ModelType::Custom, &quot;team.apr&quot;, options, &amp;recipient_public)?;

// Only recipient can decrypt
let loaded: ShellModel = load_as_recipient(&quot;team.apr&quot;, ModelType::Custom, &amp;recipient_secret)?;</code></pre>
<h2 id="part-4-single-binary-deployment"><a class="header" href="#part-4-single-binary-deployment">Part 4: Single Binary Deployment</a></h2>
<p>Embed your trained model directly in a Rust binary:</p>
<pre><code class="language-rust ignore">// In build.rs or your binary
const MODEL_BYTES: &amp;[u8] = include_bytes!(&quot;../shell.apr&quot;);

fn main() {
    use aprender::format::load_from_bytes;

    // Load at runtime - zero filesystem access
    let model: ShellModel = load_from_bytes(MODEL_BYTES, ModelType::Custom)
        .expect(&quot;embedded model should be valid&quot;);

    // Use model
    let suggestions = model.suggest(&quot;git &quot;);
    println!(&quot;Suggestions: {:?}&quot;, suggestions);
}</code></pre>
<p><strong>Benefits:</strong></p>
<ul>
<li>Zero runtime dependencies</li>
<li>Works in sandboxed environments</li>
<li>Tamper-proof (model is part of binary hash)</li>
<li>~500KB overhead for typical shell model</li>
</ul>
<h3 id="complete-bundling-pipeline"><a class="header" href="#complete-bundling-pipeline">Complete Bundling Pipeline</a></h3>
<pre><code class="language-bash"># 1. Train on your history
aprender-shell train --output shell.apr

# 2. Optionally encrypt
apr encrypt shell.apr --password &quot;$SECRET&quot; --output shell-enc.apr

# 3. Embed in binary (Cargo.toml)
# [package]
# include = [&quot;shell.apr&quot;]

# 4. Build release
cargo build --release

# Result: Single binary with embedded, optionally encrypted model
</code></pre>
<h2 id="part-5-extending-the-model"><a class="header" href="#part-5-extending-the-model">Part 5: Extending the Model</a></h2>
<h3 id="add-command-categories"><a class="header" href="#add-command-categories">Add Command Categories</a></h3>
<pre><code class="language-rust">use std::collections::HashMap;

#[derive(Default)]
struct CategorizedModel {
    /// Category → NgramTable
    categories: HashMap&lt;String, HashMap&lt;String, HashMap&lt;String, u32&gt;&gt;&gt;,
}

impl CategorizedModel {
    fn categorize(command: &amp;str) -&gt; &amp;'static str {
        let first = command.split_whitespace().next().unwrap_or(&quot;&quot;);
        match first {
            &quot;git&quot; | &quot;gh&quot; =&gt; &quot;vcs&quot;,
            &quot;cargo&quot; | &quot;rustc&quot; | &quot;rustup&quot; =&gt; &quot;rust&quot;,
            &quot;docker&quot; | &quot;kubectl&quot; | &quot;helm&quot; =&gt; &quot;containers&quot;,
            &quot;npm&quot; | &quot;yarn&quot; | &quot;pnpm&quot; =&gt; &quot;node&quot;,
            &quot;cd&quot; | &quot;ls&quot; | &quot;cat&quot; | &quot;grep&quot; | &quot;find&quot; =&gt; &quot;filesystem&quot;,
            _ =&gt; &quot;other&quot;,
        }
    }

    fn train(&amp;mut self, command: &amp;str) {
        let category = Self::categorize(command);
        let tokens: Vec&lt;&amp;str&gt; = command.split_whitespace().collect();

        if tokens.is_empty() {
            return;
        }

        let table = self.categories.entry(category.to_string()).or_default();

        // Train within category
        table
            .entry(String::new())
            .or_default()
            .entry(tokens[0].to_string())
            .and_modify(|c| *c += 1)
            .or_insert(1);

        for i in 0..tokens.len().saturating_sub(1) {
            table
                .entry(tokens[i].to_string())
                .or_default()
                .entry(tokens[i + 1].to_string())
                .and_modify(|c| *c += 1)
                .or_insert(1);
        }
    }
}

let mut model = CategorizedModel::default();
model.train(&quot;git status&quot;);
model.train(&quot;git commit&quot;);
model.train(&quot;cargo build&quot;);
model.train(&quot;cargo test&quot;);
model.train(&quot;ls -la&quot;);

// Verify categorization
assert!(model.categories.contains_key(&quot;vcs&quot;));
assert!(model.categories.contains_key(&quot;rust&quot;));
assert!(model.categories.contains_key(&quot;filesystem&quot;));</code></pre>
<h3 id="add-time-weighted-decay"><a class="header" href="#add-time-weighted-decay">Add Time-Weighted Decay</a></h3>
<p>Recent commands matter more than old ones:</p>
<pre><code class="language-rust">use std::collections::HashMap;

struct DecayingModel {
    /// context → (token → weighted_count)
    ngrams: HashMap&lt;String, HashMap&lt;String, f32&gt;&gt;,
    /// Decay factor per observation (0.99 = 1% decay)
    decay: f32,
}

impl DecayingModel {
    fn new(decay: f32) -&gt; Self {
        Self {
            ngrams: HashMap::new(),
            decay: decay.clamp(0.9, 0.999),
        }
    }

    fn observe(&amp;mut self, context: &amp;str, token: &amp;str) {
        // Decay all existing counts first
        for counts in self.ngrams.values_mut() {
            for count in counts.values_mut() {
                *count *= self.decay;
            }
        }

        // Add new observation with weight 1.0
        self.ngrams
            .entry(context.to_string())
            .or_default()
            .entry(token.to_string())
            .and_modify(|c| *c += 1.0)
            .or_insert(1.0);
    }

    fn predict(&amp;self, context: &amp;str) -&gt; Vec&lt;(String, f32)&gt; {
        let Some(counts) = self.ngrams.get(context) else {
            return vec![];
        };
        let total: f32 = counts.values().sum();
        if total &lt; 0.001 {
            return vec![];
        }
        let mut probs: Vec&lt;_&gt; = counts
            .iter()
            .map(|(t, c)| (t.clone(), *c / total))
            .collect();
        probs.sort_by(|a, b| b.1.partial_cmp(&amp;a.1).unwrap());
        probs
    }
}

// Test decay behavior
let mut model = DecayingModel::new(0.9); // 10% decay per observation

// Old observation
model.observe(&quot;git&quot;, &quot;status&quot;);

// Newer observation (git status decays, commit is fresh)
model.observe(&quot;git&quot;, &quot;commit&quot;);

let preds = model.predict(&quot;git&quot;);
// &quot;commit&quot; should be weighted higher (fresher)
assert_eq!(preds[0].0, &quot;commit&quot;);</code></pre>
<h3 id="privacy-filter"><a class="header" href="#privacy-filter">Privacy Filter</a></h3>
<p>Filter sensitive commands before training:</p>
<pre><code class="language-rust">struct PrivacyFilter {
    sensitive_patterns: Vec&lt;String&gt;,
}

impl PrivacyFilter {
    fn new() -&gt; Self {
        Self {
            sensitive_patterns: vec![
                &quot;password&quot;.to_string(),
                &quot;passwd&quot;.to_string(),
                &quot;secret&quot;.to_string(),
                &quot;token&quot;.to_string(),
                &quot;api_key&quot;.to_string(),
                &quot;AWS_SECRET&quot;.to_string(),
                &quot;GITHUB_TOKEN&quot;.to_string(),
                &quot;Authorization:&quot;.to_string(),
            ],
        }
    }

    fn is_safe(&amp;self, command: &amp;str) -&gt; bool {
        let lower = command.to_lowercase();

        // Check sensitive patterns
        for pattern in &amp;self.sensitive_patterns {
            if lower.contains(&amp;pattern.to_lowercase()) {
                return false;
            }
        }

        // Skip history manipulation
        if command.starts_with(&quot;history&quot;) || command.starts_with(&quot;fc &quot;) {
            return false;
        }

        // Skip very short commands
        if command.len() &lt; 2 {
            return false;
        }

        true
    }

    fn filter(&amp;self, commands: Vec&lt;String&gt;) -&gt; Vec&lt;String&gt; {
        commands.into_iter().filter(|c| self.is_safe(c)).collect()
    }
}

let filter = PrivacyFilter::new();

// Safe commands pass through
assert!(filter.is_safe(&quot;git push origin main&quot;));
assert!(filter.is_safe(&quot;cargo build --release&quot;));

// Sensitive commands are blocked
assert!(!filter.is_safe(&quot;export API_KEY=secret123&quot;));
assert!(!filter.is_safe(&quot;curl -H 'Authorization: Bearer token'&quot;));
assert!(!filter.is_safe(&quot;echo $PASSWORD&quot;));

// History manipulation blocked
assert!(!filter.is_safe(&quot;history -c&quot;));
assert!(!filter.is_safe(&quot;fc -l&quot;));

// Filter a batch
let commands = vec![
    &quot;git status&quot;.to_string(),
    &quot;export SECRET=abc&quot;.to_string(),
    &quot;cargo test&quot;.to_string(),
];
let safe = filter.filter(commands);
assert_eq!(safe.len(), 2);
assert_eq!(safe[0], &quot;git status&quot;);
assert_eq!(safe[1], &quot;cargo test&quot;);</code></pre>
<h2 id="part-6-complete-working-example"><a class="header" href="#part-6-complete-working-example">Part 6: Complete Working Example</a></h2>
<pre><code class="language-rust ignore">//! Complete shell history model with .apr persistence
//!
//! cargo run --example shell_history_model

use aprender::format::{save, load, ModelType, SaveOptions};
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use std::path::Path;

#[derive(Serialize, Deserialize, Default)]
pub struct ShellHistoryModel {
    n: usize,
    ngrams: HashMap&lt;String, HashMap&lt;String, u32&gt;&gt;,
    command_freq: HashMap&lt;String, u32&gt;,
    total_commands: usize,
}

impl ShellHistoryModel {
    pub fn new(n: usize) -&gt; Self {
        Self {
            n: n.clamp(2, 5),
            ..Default::default()
        }
    }

    pub fn train(&amp;mut self, commands: &amp;[String]) {
        for cmd in commands {
            self.train_command(cmd);
        }
    }

    fn train_command(&amp;mut self, cmd: &amp;str) {
        self.total_commands += 1;
        *self.command_freq.entry(cmd.to_string()).or_insert(0) += 1;

        let tokens: Vec&lt;&amp;str&gt; = cmd.split_whitespace().collect();
        if tokens.is_empty() {
            return;
        }

        // Empty context → first token
        self.observe(&quot;&quot;, tokens[0]);

        // Build n-grams
        for i in 0..tokens.len() {
            let start = i.saturating_sub(self.n - 1);
            let context = tokens[start..=i].join(&quot; &quot;);
            if i + 1 &lt; tokens.len() {
                self.observe(&amp;context, tokens[i + 1]);
            }
        }
    }

    fn observe(&amp;mut self, context: &amp;str, token: &amp;str) {
        self.ngrams
            .entry(context.to_string())
            .or_default()
            .entry(token.to_string())
            .and_modify(|c| *c += 1)
            .or_insert(1);
    }

    pub fn suggest(&amp;self, prefix: &amp;str, count: usize) -&gt; Vec&lt;(String, f32)&gt; {
        let tokens: Vec&lt;&amp;str&gt; = prefix.trim().split_whitespace().collect();
        if tokens.is_empty() {
            return self.top_first_tokens(count);
        }

        let start = tokens.len().saturating_sub(self.n - 1);
        let context = tokens[start..].join(&quot; &quot;);

        let Some(next_tokens) = self.ngrams.get(&amp;context) else {
            return vec![];
        };

        let total: u32 = next_tokens.values().sum();
        let mut suggestions: Vec&lt;_&gt; = next_tokens
            .iter()
            .map(|(token, count)| {
                let completion = format!(&quot;{} {}&quot;, prefix, token);
                let prob = *count as f32 / total as f32;
                (completion, prob)
            })
            .collect();

        suggestions.sort_by(|a, b| b.1.partial_cmp(&amp;a.1).unwrap());
        suggestions.truncate(count);
        suggestions
    }

    fn top_first_tokens(&amp;self, count: usize) -&gt; Vec&lt;(String, f32)&gt; {
        let Some(firsts) = self.ngrams.get(&quot;&quot;) else {
            return vec![];
        };
        let total: u32 = firsts.values().sum();
        let mut results: Vec&lt;_&gt; = firsts
            .iter()
            .map(|(t, c)| (t.clone(), *c as f32 / total as f32))
            .collect();
        results.sort_by(|a, b| b.1.partial_cmp(&amp;a.1).unwrap());
        results.truncate(count);
        results
    }

    pub fn save_to_apr(&amp;self, path: &amp;Path) -&gt; Result&lt;(), aprender::error::AprenderError&gt; {
        let options = SaveOptions::default()
            .with_name(&quot;shell-history-model&quot;)
            .with_description(&amp;format!(
                &quot;{}-gram model trained on {} commands&quot;,
                self.n, self.total_commands
            ));
        save(self, ModelType::Custom, path, options)
    }

    pub fn load_from_apr(path: &amp;Path) -&gt; Result&lt;Self, aprender::error::AprenderError&gt; {
        load(path, ModelType::Custom)
    }

    pub fn stats(&amp;self) -&gt; ModelStats {
        ModelStats {
            n: self.n,
            total_commands: self.total_commands,
            unique_commands: self.command_freq.len(),
            ngram_count: self.ngrams.values().map(|m| m.len()).sum(),
        }
    }
}

#[derive(Debug)]
pub struct ModelStats {
    pub n: usize,
    pub total_commands: usize,
    pub unique_commands: usize,
    pub ngram_count: usize,
}

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Simulate shell history
    let history = vec![
        &quot;git status&quot;,
        &quot;git add .&quot;,
        &quot;git commit -m fix&quot;,
        &quot;git push&quot;,
        &quot;git status&quot;,
        &quot;git log --oneline&quot;,
        &quot;cargo build&quot;,
        &quot;cargo test&quot;,
        &quot;cargo build --release&quot;,
        &quot;cargo clippy&quot;,
    ]
    .into_iter()
    .map(String::from)
    .collect::&lt;Vec&lt;_&gt;&gt;();

    // Train model
    let mut model = ShellHistoryModel::new(3);
    model.train(&amp;history);

    // Show stats
    let stats = model.stats();
    println!(&quot;Model Statistics:&quot;);
    println!(&quot;  N-gram size: {}&quot;, stats.n);
    println!(&quot;  Total commands: {}&quot;, stats.total_commands);
    println!(&quot;  Unique commands: {}&quot;, stats.unique_commands);
    println!(&quot;  N-gram count: {}&quot;, stats.ngram_count);

    // Test suggestions
    println!(&quot;\nSuggestions for 'git ':&quot;);
    for (suggestion, prob) in model.suggest(&quot;git &quot;, 5) {
        println!(&quot;  {:.1}%  {}&quot;, prob * 100.0, suggestion);
    }

    println!(&quot;\nSuggestions for 'cargo ':&quot;);
    for (suggestion, prob) in model.suggest(&quot;cargo &quot;, 5) {
        println!(&quot;  {:.1}%  {}&quot;, prob * 100.0, suggestion);
    }

    // Save to .apr
    let path = std::path::Path::new(&quot;shell_history.apr&quot;);
    model.save_to_apr(path)?;
    println!(&quot;\nModel saved to: {}&quot;, path.display());

    // Reload and verify
    let loaded = ShellHistoryModel::load_from_apr(path)?;
    assert_eq!(loaded.total_commands, model.total_commands);
    println!(&quot;Model reloaded successfully!&quot;);

    // Cleanup
    std::fs::remove_file(path)?;

    Ok(())
}</code></pre>
<h2 id="part-7-model-validation-with-aprender-metrics"><a class="header" href="#part-7-model-validation-with-aprender-metrics">Part 7: Model Validation with aprender Metrics</a></h2>
<p>The <code>aprender-shell</code> CLI uses aprender's ranking metrics for proper evaluation:</p>
<pre><code class="language-bash"># Train on your history
aprender-shell train

# Validate with holdout evaluation
aprender-shell validate
</code></pre>
<h3 id="ranking-metrics-aprendermetricsranking"><a class="header" href="#ranking-metrics-aprendermetricsranking">Ranking Metrics (aprender::metrics::ranking)</a></h3>
<pre><code class="language-rust ignore">use aprender::metrics::ranking::{hit_at_k, mrr, RankingMetrics};

// Hit@K: Is correct answer in top K predictions?
let predictions = vec![&quot;git commit&quot;, &quot;git push&quot;, &quot;git pull&quot;];
let target = &quot;git push&quot;;
assert_eq!(hit_at_k(&amp;predictions, target, 1), 0.0);  // Not #1
assert_eq!(hit_at_k(&amp;predictions, target, 2), 1.0);  // In top 2

// Mean Reciprocal Rank: 1/rank of correct answer
let all_predictions = vec![
    vec![&quot;git commit&quot;, &quot;git push&quot;],  // target at rank 2 → RR = 0.5
    vec![&quot;cargo test&quot;, &quot;cargo build&quot;],  // target at rank 1 → RR = 1.0
];
let targets = vec![&quot;git push&quot;, &quot;cargo test&quot;];
let score = mrr(&amp;all_predictions, &amp;targets);  // (0.5 + 1.0) / 2 = 0.75

// Comprehensive metrics
let metrics = RankingMetrics::compute(&amp;all_predictions, &amp;targets);
println!(&quot;Hit@1: {:.1}%&quot;, metrics.hit_at_1 * 100.0);
println!(&quot;Hit@5: {:.1}%&quot;, metrics.hit_at_5 * 100.0);
println!(&quot;MRR: {:.3}&quot;, metrics.mrr);</code></pre>
<h3 id="validation-output"><a class="header" href="#validation-output">Validation Output</a></h3>
<pre><code class="language-text">🔬 aprender-shell: Model Validation

📂 History file: ~/.zsh_history
📊 Total commands: 21,763
⚙️  N-gram size: 3
📈 Train/test split: 80% / 20%

═══════════════════════════════════════════
           VALIDATION RESULTS
═══════════════════════════════════════════
  Training set:      17,410 commands
  Test set:           4,353 commands
  Evaluated:          3,857 commands
───────────────────────────────────────────
  Hit@1  (top 1):     13.3%
  Hit@5  (top 5):     26.2%
  Hit@10 (top 10):    30.7%
  MRR (Mean Recip):  0.181
═══════════════════════════════════════════
</code></pre>
<p><strong>Interpretation:</strong></p>
<ul>
<li><strong>Hit@5 ~27%</strong>: Model suggests correct command in top 5 for ~1 in 4 predictions</li>
<li><strong>MRR ~0.18</strong>: Average rank of correct answer is ~5th position</li>
<li>This is realistic for shell completion given command diversity</li>
</ul>
<h2 id="part-8-synthetic-data-augmentation"><a class="header" href="#part-8-synthetic-data-augmentation">Part 8: Synthetic Data Augmentation</a></h2>
<p>Improve model coverage with three strategies:</p>
<pre><code class="language-bash"># Generate 5000 synthetic commands and retrain
aprender-shell augment --count 5000
</code></pre>
<h3 id="cli-command-templates"><a class="header" href="#cli-command-templates">CLI Command Templates</a></h3>
<pre><code class="language-rust ignore">use aprender_shell::synthetic::CommandGenerator;

let gen = CommandGenerator::new();
let commands = gen.generate(1000);

// Generates realistic dev commands:
// - git status, git commit -m, git push --force
// - cargo build --release, cargo test --lib
// - docker run -it, kubectl get pods
// - npm install --save-dev, pip install -r</code></pre>
<h3 id="mutation-engine"><a class="header" href="#mutation-engine">Mutation Engine</a></h3>
<pre><code class="language-rust ignore">use aprender_shell::synthetic::CommandMutator;

let mutator = CommandMutator::new();

// Original: &quot;git commit -m test&quot;
// Mutations:
//   - &quot;git add -m test&quot;      (command substitution)
//   - &quot;git commit -am test&quot;  (flag substitution)
//   - &quot;git commit test&quot;      (flag removal)
let mutations = mutator.mutate(&quot;git commit -m test&quot;);</code></pre>
<h3 id="coverage-guided-generation"><a class="header" href="#coverage-guided-generation">Coverage-Guided Generation</a></h3>
<pre><code class="language-rust ignore">use aprender_shell::synthetic::{SyntheticPipeline, CoverageGuidedGenerator};
use std::collections::HashSet;

// Extract known n-grams from current model
let known_ngrams: HashSet&lt;String&gt; = model.ngram_keys().collect();

// Generate commands that maximize new n-gram coverage
let pipeline = SyntheticPipeline::new();
let result = pipeline.generate(&amp;real_history, known_ngrams, 5000);

println!(&quot;New n-grams added: {}&quot;, result.report.new_ngrams);
println!(&quot;Coverage gain: {:.1}%&quot;, result.report.coverage_gain * 100.0);</code></pre>
<h3 id="augmentation-output"><a class="header" href="#augmentation-output">Augmentation Output</a></h3>
<pre><code class="language-text">🧬 aprender-shell: Data Augmentation

📂 History file: ~/.zsh_history
📊 Real commands: 21,761
🔢 Known n-grams: 39,176

🧪 Generating synthetic commands... done!

📈 Coverage Report:
   Synthetic commands: 5,000
   New n-grams added:  5,473
   Coverage gain:      99.0%

✅ Augmented model saved

📊 Model Statistics:
   Total training commands: 26,761
   Unique n-grams: 46,340 (+18%)
   Vocabulary size: 21,101 (+31%)
</code></pre>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Purpose</th><th>Complexity</th></tr></thead><tbody>
<tr><td>N-gram table</td><td>Token prediction</td><td>O(1) lookup</td></tr>
<tr><td>Trie index</td><td>Prefix completion</td><td>O(k) where k=prefix length</td></tr>
<tr><td>.apr format</td><td>Persistence + metadata</td><td>~2KB overhead</td></tr>
<tr><td>Encryption</td><td>Privacy protection</td><td>+50ms save/load</td></tr>
<tr><td>Single binary</td><td>Zero-dependency deployment</td><td>+500KB binary size</td></tr>
<tr><td><strong>Ranking metrics</strong></td><td>Model validation</td><td><code>aprender::metrics::ranking</code></td></tr>
<tr><td><strong>Synthetic data</strong></td><td>Coverage improvement</td><td>+13% n-grams</td></tr>
</tbody></table>
</div>
<p><strong>Key insights:</strong></p>
<ol>
<li>Shell commands are highly predictable (Markov property)</li>
<li>N-grams outperform neural nets for this domain (speed, size, accuracy)</li>
<li><code>.apr</code> format provides type-safe, versioned persistence</li>
<li>Encryption enables sharing sensitive models securely</li>
<li><code>include_bytes!()</code> enables self-contained deployment</li>
<li><strong>Ranking metrics</strong> (Hit@K, MRR) are standard for language model evaluation</li>
<li><strong>Synthetic data</strong> fills coverage gaps for commands you rarely use</li>
</ol>
<h2 id="cli-reference"><a class="header" href="#cli-reference">CLI Reference</a></h2>
<pre><code class="language-bash"># Training
aprender-shell train              # Full retrain from history
aprender-shell update             # Incremental update (fast)

# Evaluation
aprender-shell validate           # Holdout evaluation with metrics
aprender-shell validate -n 4      # Test different n-gram sizes
aprender-shell stats              # Model statistics

# Data Augmentation
aprender-shell augment            # Generate synthetic data + retrain
aprender-shell augment -c 10000   # Custom synthetic count

# Inference
aprender-shell suggest &quot;git &quot;     # Get completions
aprender-shell suggest &quot;cargo t&quot;  # Prefix matching

# Export
aprender-shell export model.apr   # Export to .apr format
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><a href="https://github.com/paiml/aprender/tree/main/crates/aprender-shell"><code>aprender-shell</code> source code</a></li>
<li><a href="../examples/model-format.html">Model Format Specification</a></li>
<li>Ranking Metrics API (see <code>aprender::metrics</code>)</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../examples/mixture-of-experts.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../examples/custom-error-classifier.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../examples/mixture-of-experts.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../examples/custom-error-classifier.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../editor.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
