Model: test.apr (encoder-decoder (Whisper/T5))

═══════════════════════════════════════════════════════════════
                     FULL MODEL DATA FLOW
═══════════════════════════════════════════════════════════════

INPUT  audio [N, samples]
   │
   ▼
┌─────────────────┐  mel_spectrogram()
│  [N, 80, T]      │
└────────┬────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────────┐
│  ENCODER                                               │
├─────────────────────────────────────────────────────────────┤
│            │                                                │
│            ▼                                                │
│  ┌─────────────────────────────────────────────────┐        │
│  │  Encoder Layers × 2                                   │        │
│  │  ┌─────────────────────────────────────────┐    │        │
│  │  │ ln1 → self_attn → + residual            │    │        │
│  │  │ ln2 → ffn → + residual                  │    │        │
│  │  └─────────────────────────────────────────┘    │        │
│  └─────────────────────────────────────────────────┘        │
│            │                                                │
│            ▼                                                │
│  encoder_output [N, T', d_model]                          │
└─────────────────────────────────────────────────────────────┘
             │
             │ (used as K,V for cross-attention)
             ▼
┌─────────────────────────────────────────────────────────────┐
│  DECODER                                               │
├─────────────────────────────────────────────────────────────┤
│  tokens [N, seq_len]                                        │
│       │                                                     │
│       ▼                                                     │
│  ┌──────────────────┐                                       │
│  │ Token Embed │ + positional_embedding              │
│  └────────┬─────────┘                                       │
│            │                                                │
│            ▼                                                │
│  ┌─────────────────────────────────────────────────┐        │
│  │  Decoder Layers × 2                                   │        │
│  │  ┌─────────────────────────────────────────┐    │        │
│  │  │ ln1 → self_attn (causal) → + residual      │    │        │
│  │  │ ln2 → cross_attn → + residual          │    │        │
│  │  │       └── Q from decoder                │    │        │
│  │  │       └── K,V from encoder_output │    │        │
│  │  │ ln3 → ffn → + residual                  │    │        │
│  │  └─────────────────────────────────────────┘    │        │
│  └─────────────────────────────────────────────────┘        │
│            │                                                │
│            ▼                                                │
│  ┌──────────────────┐                                       │
│  │ LM Head │ → logits [N, seq_len, vocab]           │
│  └────────┬─────────┘                                       │
└─────────────────────────────────────────────────────────────┘
         │
         ▼
OUTPUT  tokens [N, seq_len]
