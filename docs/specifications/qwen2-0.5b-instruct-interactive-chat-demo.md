# Qwen2-0.5B-Instruct Interactive Chat Demo Specification

**Version**: 1.6.0
**Status**: North Star Demo Specification (Full Lifecycle + Probador + Deep Profiling + Performance Grading)
**Created**: 2025-12-23
**Authors**: Aprender Core Team
**Upstream Dependency**: https://github.com/paiml/aprender

---

## Executive Summary

This specification defines the implementation plan for a **real, functional** Qwen2-0.5B-Instruct interactive chat demo running locally via CLI. Optional WASM compilation target for portable execution via `wasmtime` (zero JavaScript). This ensures **Sovereign AI**: your model, your hardware, your data.

**Critical Finding**: The existing demo is deceptive—it simulates intelligence without performing any inference. This violates the Toyota Way principle of *Genchi Genbutsu* (go and see the real thing) and must be remediated. We are adopting a **"Zero Stub Policy"** for this deliverable.

**Strict Mandate**:
*   **No Stubs**: Every token must be generated by a real Qwen2 model forward pass.
*   **No Hacks**: No hardcoded "if prompt contains X then return Y" logic.
*   **No Random Weights**: The model MUST use trained weights loaded from a validated `.apr` file. "Randomly initialized" fallbacks are explicitly FORBIDDEN.
*   **No Workarounds**: The `apr` CLI and libraries are the *only* approved path. No side-loading JSON weights or custom loaders.

### Scope

| Component | Current State | Target State |
|-----------|---------------|--------------|
| Model Loading | ❌ Fake (no .apr file) | ✅ Real APR v2 loading with Checksum Verification |
| Tokenization | ❌ None | ✅ BPE encode/decode with Vocabulary Validation |
| Forward Pass | ❌ Pattern matching | ✅ Real transformer inference verified against Golden Traces |
| Generation | ❌ Canned responses | ✅ Autoregressive sampling with Perplexity Monitoring |
| CLI Interface | ❌ None | ✅ `apr chat` REPL command with Introspection |
| Visual Control | ❌ None | ✅ Logit & Attention Inspection (Glass Box) |
| Deployment | ❌ None | ✅ CLI Binary, WASM Module, REST Server — all from single .apr |

---

## North Star: The Complete APR Lifecycle

This demo serves as the **"North Star"** for the entire APR ecosystem, demonstrating the complete workflow that users expect: **Download → Convert → Tune → Shrink → Deploy**.

### The Vision: Sovereign AI in Your Hands

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        APR: One Format, Many Targets                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐                 │
│   │ HuggingFace │      │ SafeTensors │      │    GGUF     │                 │
│   │   (Cloud)   │      │   (Local)   │      │ (llama.cpp) │                 │
│   └──────┬──────┘      └──────┬──────┘      └──────┬──────┘                 │
│          │                    │                    │                         │
│          └────────────────────┼────────────────────┘                         │
│                               ▼                                              │
│                    ┌─────────────────────┐                                   │
│                    │    apr import       │  ← Single entry point             │
│                    └──────────┬──────────┘                                   │
│                               ▼                                              │
│                    ┌─────────────────────┐                                   │
│                    │   model.apr (v2)    │  ← Universal format               │
│                    │   • Zero-copy mmap  │                                   │
│                    │   • 64-byte aligned │                                   │
│                    │   • Signed metadata │                                   │
│                    └──────────┬──────────┘                                   │
│                               │                                              │
│          ┌────────────────────┼────────────────────┐                         │
│          ▼                    ▼                    ▼                         │
│   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐                 │
│   │ apr convert │      │  apr tune   │      │ apr inspect │                 │
│   │ (quantize)  │      │ (fine-tune) │      │ (validate)  │                 │
│   └──────┬──────┘      └──────┬──────┘      └─────────────┘                 │
│          │                    │                                              │
│          └────────────────────┤                                              │
│                               ▼                                              │
│                    ┌─────────────────────┐                                   │
│                    │  model-int4.apr     │  ← Optimized for deployment       │
│                    │   • 4x smaller      │                                   │
│                    │   • <15% PPL loss   │                                   │
│                    └──────────┬──────────┘                                   │
│                               │                                              │
│          ┌────────────────────┼────────────────────┐                         │
│          ▼                    ▼                    ▼                         │
│   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐                 │
│   │ apr compile │      │  apr serve  │      │ WASM Build  │                 │
│   │ (binary)    │      │  (server)   │      │ (wasmtime)  │                 │
│   └──────┬──────┘      └──────┬──────┘      └──────┬──────┘                 │
│          ▼                    ▼                    ▼                         │
│   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐                 │
│   │ ./qwen-cli  │      │ :8080/chat  │      │ wasmtime    │                 │
│   │ (native)    │      │ (REST API)  │      │ qwen.wasm   │                 │
│   └─────────────┘      └─────────────┘      └─────────────┘                 │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Complete CLI Workflow Demonstration

```bash
# ═══════════════════════════════════════════════════════════════════════════
# STAGE 1: ACQUIRE — Get the model from any source
# ═══════════════════════════════════════════════════════════════════════════

# Option A: Import from HuggingFace Hub (most common)
apr import hf://Qwen/Qwen2-0.5B-Instruct -o qwen2-0.5b.apr
# ✓ Downloaded 1.2GB from HuggingFace
# ✓ Converted SafeTensors → APR v2
# ✓ Embedded tokenizer.json
# ✓ Model saved: qwen2-0.5b.apr (1.18 GB)

# Option B: Import from local SafeTensors
apr import ./model.safetensors -o qwen2-0.5b.apr --arch qwen2

# Option C: Import from GGUF (llama.cpp format)
apr import ./qwen2-0.5b-q4_k_m.gguf -o qwen2-0.5b.apr

# ═══════════════════════════════════════════════════════════════════════════
# STAGE 2: INSPECT — Understand what you have
# ═══════════════════════════════════════════════════════════════════════════

# View model metadata and architecture
apr inspect qwen2-0.5b.apr
# Model: Qwen2-0.5B-Instruct
# Architecture: qwen2 (decoder-only)
# Parameters: 494M
# Layers: 24
# Hidden: 896
# Heads: 14 (2 KV)
# Vocab: 151,936
# Context: 32,768
# Dtype: float16
# Size: 1.18 GB

# Validate model integrity
apr validate qwen2-0.5b.apr --quality
# ✓ Checksum: VALID (sha256: a1b2c3...)
# ✓ Tensors: 194/194 present
# ✓ Shapes: All match config
# ✓ Values: No NaN/Inf detected
# ✓ Quality Score: 98/100

# List all tensors with statistics
apr tensors qwen2-0.5b.apr --stats
# model.embed_tokens.weight    [151936, 896]  mean=-0.001  std=0.041
# model.layers.0.self_attn...  [896, 896]     mean=0.000   std=0.023
# ... (194 tensors)

# Compare against HuggingFace reference
apr compare-hf qwen2-0.5b.apr --hf Qwen/Qwen2-0.5B-Instruct
# ✓ All 194 tensors match within 1e-6

# ═══════════════════════════════════════════════════════════════════════════
# STAGE 3: OPTIMIZE — Shrink for deployment
# ═══════════════════════════════════════════════════════════════════════════

# Quantize to INT8 (2x smaller, minimal quality loss)
apr convert qwen2-0.5b.apr --quantize int8 -o qwen2-0.5b-int8.apr
# ✓ Quantized: float16 → int8
# ✓ Size: 1.18 GB → 590 MB (2.0x reduction)
# ✓ Estimated PPL increase: <2%

# Quantize to INT4 (4x smaller, for edge devices)
apr convert qwen2-0.5b.apr --quantize int4 -o qwen2-0.5b-int4.apr
# ✓ Quantized: float16 → int4 (GPTQ)
# ✓ Size: 1.18 GB → 316 MB (3.7x reduction)
# ✓ Estimated PPL increase: <8%

# Verify quantization quality against golden trace
apr test-model qwen2-0.5b-int4.apr --golden-trace golden/qwen2_reference.json
# ✓ Logit deviation: 0.0023 (threshold: 0.01)
# ✓ Perplexity: 9.2 (baseline: 8.5, +8.2%)
# ✓ PASSED: Quality within acceptable bounds

# ═══════════════════════════════════════════════════════════════════════════
# STAGE 4: CUSTOMIZE — Fine-tune for your use case (optional)
# ═══════════════════════════════════════════════════════════════════════════

# Fine-tune with LoRA adapter
apr tune qwen2-0.5b.apr \
    --method lora \
    --rank 16 \
    --data ./my_dataset.jsonl \
    --epochs 3 \
    -o qwen2-0.5b-finetuned.apr
# ✓ LoRA adapter trained: 2.4M parameters
# ✓ Base model unchanged
# ✓ Merged into: qwen2-0.5b-finetuned.apr

# Merge multiple models (ensemble)
apr merge model1.apr model2.apr --strategy weighted --weights 0.7,0.3 -o merged.apr

# ═══════════════════════════════════════════════════════════════════════════
# STAGE 5: TEST — Verify before deployment
# ═══════════════════════════════════════════════════════════════════════════

# Interactive chat (quick test)
apr chat qwen2-0.5b-int4.apr
# You: What is 2+2?
# Assistant: 4

# Chat with inspection mode (see the "brain")
apr chat qwen2-0.5b-int4.apr --inspect
# [DEBUG] Tokenized: [234, 12, 553]
# [DEBUG] Top-5: "4" (0.98), "Four" (0.01), ...

# Run benchmark suite
apr bench qwen2-0.5b-int4.apr
# Prefill (512 tokens): 89 tok/s
# Decode: 24 tok/s
# Memory: 412 MB peak
# First token: 1.2s

# Run perplexity evaluation
apr eval qwen2-0.5b-int4.apr --dataset wikitext-2
# Perplexity: 9.18

# Create canary test for regression detection
apr canary create qwen2-0.5b-int4.apr \
    --prompts canary_prompts.txt \
    -o canary.json

# ═══════════════════════════════════════════════════════════════════════════
# STAGE 6: DEPLOY — Ship to your target platform
# ═══════════════════════════════════════════════════════════════════════════

# ─────────────────────────────────────────────────────────────────────────────
# OPTION A: Standalone CLI Binary (like llamafile)
# ─────────────────────────────────────────────────────────────────────────────
apr compile qwen2-0.5b-int4.apr -o qwen-chat
# ✓ Embedded model (316 MB)
# ✓ Embedded tokenizer
# ✓ Embedded runtime
# ✓ Binary: qwen-chat (318 MB, portable)

# Run anywhere (no dependencies!)
./qwen-chat "What is Rust?"
# Rust is a systems programming language focused on safety...

./qwen-chat --interactive
# You: Hello!
# Assistant: Hello! How can I help you today?

# Cross-compile for other platforms
apr compile qwen2-0.5b-int4.apr --target x86_64-unknown-linux-musl -o qwen-linux
apr compile qwen2-0.5b-int4.apr --target aarch64-apple-darwin -o qwen-mac-arm
apr compile qwen2-0.5b-int4.apr --target x86_64-pc-windows-msvc -o qwen.exe

# ─────────────────────────────────────────────────────────────────────────────
# OPTION B: REST API Server
# ─────────────────────────────────────────────────────────────────────────────
apr serve qwen2-0.5b-int4.apr --port 8080
# ✓ Server running at http://localhost:8080
# ✓ Endpoints:
#   POST /v1/chat/completions (OpenAI-compatible)
#   POST /v1/completions
#   GET  /health
#   GET  /metrics (Prometheus)

# Client usage
curl -X POST http://localhost:8080/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{"messages": [{"role": "user", "content": "Hello!"}]}'

# ─────────────────────────────────────────────────────────────────────────────
# OPTION C: WebAssembly for Portable Execution (Zero JavaScript)
# ─────────────────────────────────────────────────────────────────────────────
apr compile qwen2-0.5b-int4.apr --target wasm32-wasi -o qwen.wasm
# ✓ WASM module: qwen.wasm (4.2 MB)
# ✓ Pure Rust → WASM (no JS bindings)
# ✓ Runs via wasmtime, wasmer, or any WASI-compatible runtime

# Run with wasmtime (portable across Linux/macOS/Windows)
wasmtime qwen.wasm --dir=. -- --model qwen2-0.5b-int4.apr "Hello!"

# ─────────────────────────────────────────────────────────────────────────────
# OPTION D: Export for Other Runtimes
# ─────────────────────────────────────────────────────────────────────────────
# Export to GGUF (for llama.cpp, ollama)
apr export qwen2-0.5b-int4.apr --format gguf -o qwen2.gguf

# Export to SafeTensors (for HuggingFace ecosystem)
apr export qwen2-0.5b-int4.apr --format safetensors -o model.safetensors

# Export to ONNX (for ONNX Runtime)
apr export qwen2-0.5b-int4.apr --format onnx -o model.onnx
```

### Deployment Target Comparison

| Target | Command | Output | Size | Latency | Use Case |
|--------|---------|--------|------|---------|----------|
| **CLI Binary** | `apr compile` | `./qwen-chat` | 318 MB | 1.2s | Desktop apps, scripts |
| **REST Server** | `apr serve` | `:8080/v1/...` | N/A | 0.8s | Backend services |
| **WASM (WASI)** | `apr compile --target wasm32-wasi` | `.wasm` | 4 MB | 2.0s | Portable CLI, sandboxed |
| **Local Web** | `apr serve --web` | `localhost:8080` | 4 MB | 2.0s | Browser UI, offline demo |
| **GGUF Export** | `apr export --format gguf` | `.gguf` | 316 MB | varies | llama.cpp, ollama |
| **Edge/Mobile** | `apr compile --target aarch64` | binary | 318 MB | 2.5s | iOS, Android, RPi |

### Why This Matters: Sovereign AI

| Property | Traditional Cloud | APR Sovereign Stack |
|----------|-------------------|---------------------|
| **Data Privacy** | Prompts sent to API | All local, zero telemetry |
| **Offline** | Requires internet | Works airplane mode |
| **Cost** | Per-token billing | One-time download |
| **Customization** | Limited/none | Full fine-tuning |
| **Reproducibility** | Model changes silently | Checksummed, versioned |
| **Auditability** | Black box | Open source, inspectable |

---

## Table of Contents

0. [North Star: The Complete APR Lifecycle](#north-star-the-complete-apr-lifecycle)
1. [Problem Statement](#1-problem-statement)
2. [Design Philosophy](#2-design-philosophy)
3. [Architecture Overview](#3-architecture-overview)
4. [Implementation Components](#4-implementation-components)
5. [CLI Interactive Mode](#5-cli-interactive-mode)
6. [WASM Portable Build](#6-wasm-portable-build)
7. [Deep Probador Testing](#7-deep-probador-testing)
8. [Performance Requirements](#8-performance-requirements)
9. [Peer-Reviewed Citations](#9-peer-reviewed-citations)
10. [Toyota Way Alignment](#10-toyota-way-alignment)
11. [180-Point Popperian Falsification Checklist](#11-180-point-popperian-falsification-checklist)
12. [Implementation Roadmap](#12-implementation-roadmap)
13. [Risk Analysis](#13-risk-analysis)
14. [References](#14-references)

---

## 1. Problem Statement

### 1.1 Current State Analysis

**Goal**: Build a local-first chat demo that runs real Qwen2 inference on localhost.

**Anti-Pattern to Avoid** (stub implementations):

```rust
// ANTI-PATTERN: Pattern matching simulates intelligence (FORBIDDEN)
fn generate_demo_response(&self, prompt: &str) -> String {
    let prompt_lower = prompt.to_lowercase();
    // DECEPTION: Pattern matching is NOT inference
    if prompt_lower.contains("capital") && prompt_lower.contains("france") {
        "The capital of France is Paris...".to_string()
    }
    // ...
}
```

**Deficiencies of Stub Approach**:

| Issue | Severity | Impact |
|-------|----------|--------|
| No .apr model loading | Critical | Demo is non-functional |
| No transformer forward pass | Critical | No actual inference |
| Pattern matching only | Critical | Deterministic, non-intelligent, fragile |
| Canned responses | Critical | Misleading to users; violates Trust |
| Lack of Visual Control | High | Impossible to verify internal state |

### 1.2 What EXISTS in aprender (Building Blocks)

| Component | Location | Status | Citation |
|-----------|----------|--------|----------|
| `GroupedQueryAttention` | `src/nn/transformer.rs` | ✅ Implemented | (Ainslie et al., 2023) |
| `RotaryPositionEmbedding` | `src/nn/transformer.rs` | ✅ Implemented | (Su et al., 2021) |
| `TransformerDecoderLayer` | `src/nn/transformer.rs` | ✅ Implemented | (Vaswani et al., 2017) |
| `RMSNorm` | `src/nn/normalization.rs` | ✅ Implemented | (Zhang & Sennrich, 2019) |
| `NucleusSampler` | `src/nn/generation.rs` | ✅ Implemented | (Holtzman et al., 2020) |
| `TopKSampler` | `src/nn/generation.rs` | ✅ Implemented | (Fan et al., 2018) |
| `Qwen2Config` | `src/demo/mod.rs` | ✅ Correct architecture | (Bai et al., 2023) |
| `AprReader` | `src/serialization/apr.rs` | ✅ APR v2 loading | APR-SPEC v2.0 |
| WASM/SIMD | `src/wasm/mod.rs` | ✅ Configured | (Haas et al., 2017) |

### 1.3 What's MISSING for Real Inference

1. **Qwen2Model struct** - Assembly of layers into complete model
2. **Weight loading pipeline** - HuggingFace → APR conversion + hosting + **Verification**
3. **BPE Tokenizer integration** - Qwen2's 151,936 token vocabulary
4. **Forward pass implementation** - Actual matrix operations verified against **Golden Traces**
5. **CLI `apr chat` command** - Interactive REPL interface with **Inspector Mode**

---

## 2. Design Philosophy

### 2.1 Popperian Falsificationism

Following Popper's criterion of demarcation (Popper, 1959), each claim in this specification is accompanied by a **falsifiable test condition**. We do not attempt to prove correctness; instead, we specify conditions under which claims would be proven false.

**Core Falsifiable Claim**: "The Qwen2-0.5B demo performs real transformer inference."

**Strong Falsification Conditions**:
- Output logits do not match reference implementation (PyTorch) within `1e-4`.
- Perplexity on held-out text > 20 (indicates random or broken weights).
- Visual inspection of attention maps shows uniform distribution (no learning).
- Altering a single weight does not change the output (indicates code is not using the weights).

### 2.2 Toyota Production System Alignment

| Principle | Application |
|-----------|-------------|
| **Genchi Genbutsu** | Go and See: Verify logic by inspecting internal tensors, not just reading code. |
| **Jidoka** | Automation with a Human Touch: If PPL > Threshold, build fails immediately (Andon). |
| **Poka-Yoke** | Mistake Proofing: Type system prevents mixing text and tokens. |
| **Heijunka** | Leveling: Streaming token generation to smooth user experience. |
| **Visual Control** | "Glass Box" UI: Show top-k probs and attention to prove calculation. |

### 2.3 Sovereign AI Compliance

Per Kleppmann et al. (2019) "Local-First Software":

| Requirement | Implementation |
|-------------|----------------|
| **Local Execution** | All inference runs on user device |
| **Data Privacy** | No telemetry; prompts never leave device |
| **Auditability** | Open source (Apache 2.0); Reproducible builds |
| **Model Provenance** | Cryptographic signatures in .apr footer |

### 2.4 Native Library Mandate (Zero Ad-Hoc)

**CRITICAL**: All implementations MUST use existing aprender infrastructure. Ad-hoc implementations are a major bug vector.

| Component | ❌ Ad-Hoc (FORBIDDEN) | ✅ Native (REQUIRED) |
|-----------|----------------------|---------------------|
| **File I/O** | `fs::read()` | `bundle::MappedFile` (mmap) |
| **Tensor Storage** | Custom Vec<f32> | `autograd::Tensor` |
| **Model Format** | Raw SafeTensors | `.apr` format via `format::load_mmap` |
| **Serialization** | Manual JSON | `serialization::apr` module |
| **Error Handling** | `String` errors | `AprenderError` |
| **NN Layers** | Custom implementations | `nn::*` module |
| **Initialization** | **Random Weights** | **ONLY Loaded from .apr** |
| **Tensor Ops** | **Naive iterators** | **`Tensor::add/mul/exp/sigmoid` (SIMD)** |

#### 2.4.1 Compute Backend Hierarchy (Zero Naive Loops)

**CRITICAL**: Never reimplement tensor operations with naive Rust iterators. Use the Trueno compute backend hierarchy.

**Compute Backend Priority** (use highest available):
```
┌─────────────────────────────────────────────────────────────────┐
│                    COMPUTE BACKEND HIERARCHY                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   Priority 1: trueno-gpu (wgpu)     ← GPU acceleration          │
│       └─ Use when: GPU available, large batches                 │
│                                                                  │
│   Priority 2: Trueno SIMD (AVX2/AVX512/NEON)                    │
│       └─ Use when: CPU, always available                        │
│       └─ Methods: Tensor::add/mul/matmul/sigmoid/exp            │
│                                                                  │
│   Priority 3: WASM SIMD128                                      │
│       └─ Use when: WASM target (wasm32-wasi)                     │
│       └─ Auto-selected by Trueno for wasm32 target              │
│                                                                  │
│   ❌ FORBIDDEN: Naive Rust iterators                            │
│       └─ .data().iter().map().collect() = 10-50x SLOWER         │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**Heuristic**: `Trueno/SIMD/WGPU + trueno-gpu when available`

```rust
// ❌ FORBIDDEN: Naive iterator (10-50x slower, no SIMD)
fn silu_bad(x: &Tensor) -> Tensor {
    let data: Vec<f32> = x.data().iter()
        .map(|&v| v * (1.0 / (1.0 + (-v).exp())))
        .collect();
    Tensor::new(&data, x.shape())
}

// ✅ REQUIRED: Use Tensor SIMD methods (auto-dispatches to best backend)
fn silu_good(x: &Tensor) -> Tensor {
    x.mul(&x.sigmoid())  // Trueno SIMD or GPU
}

// ❌ FORBIDDEN: Manual elementwise ops
fn add_bad(a: &Tensor, b: &Tensor) -> Tensor {
    let data: Vec<f32> = a.data().iter().zip(b.data()).map(|(x,y)| x+y).collect();
    Tensor::new(&data, a.shape())
}

// ✅ REQUIRED: Use Tensor methods (auto-dispatches)
fn add_good(a: &Tensor, b: &Tensor) -> Tensor {
    a.add(b)  // Trueno handles SIMD/GPU dispatch
}
```

**Available Accelerated Tensor Methods** (auto-dispatch to best backend):
| Category | Methods | Backend |
|----------|---------|---------|
| Arithmetic | `add`, `sub`, `mul`, `div`, `mul_scalar` | SIMD/GPU |
| Activations | `exp`, `sigmoid`, `tanh`, `relu` | SIMD/GPU |
| Matrix | `matmul`, `transpose` | SIMD/GPU (critical path) |
| Reduction | `sum`, `mean` | SIMD/GPU |

**Why This Matters**:
- **matmul** is 90%+ of inference time → MUST use SIMD/GPU
- **Roofline Model (Williams et al., 2009)**: Naive iteration fails to achieve sufficient arithmetic intensity, falling far below the hardware's compute ceiling.
- Naive `for` loop matmul: ~0.1 GFLOPS (Memory Bound)
- SIMD matmul (AVX2): ~50 GFLOPS (500x faster)
- GPU matmul (wgpu): ~1000+ GFLOPS (10,000x faster)

**Enforcement**:
- CI grep check for `.data().iter()` in model inference paths
- Code review checklist: "Uses Tensor methods (not manual loops)?"
- Performance regression tests catch naive implementations
- `cargo bench` baseline: >10 tok/s on CPU, >100 tok/s on GPU

#### 2.4.2 Granular Performance Testing (Renacer + HuggingFace Ground Truth)

**MANDATE**: All inference code MUST be profiled with `renacer` and benchmarked against HuggingFace ground truth, applying **Differential Testing (McKeeman, 1998)** principles to tensor operations.

**Renacer Profiling Requirements**:
```bash
# Profile every layer of the forward pass
renacer profile apr chat model.apr --granular

# Expected output:
# ┌────────────────────────────────────────────────────────────┐
# │ Layer                    │ Time (ms) │ % Total │ GFLOPS   │
# ├────────────────────────────────────────────────────────────┤
# │ embed_tokens             │     2.3   │   1.2%  │   12.4   │
# │ layers.0.self_attn.qkv   │    18.7   │   9.8%  │   45.2   │  ← If <10 GFLOPS = BUG
# │ layers.0.self_attn.attn  │    12.1   │   6.3%  │   38.9   │
# │ layers.0.mlp.gate_up     │    24.3   │  12.7%  │   52.1   │
# │ layers.0.mlp.down        │    11.2   │   5.9%  │   48.7   │
# │ ...                      │           │         │          │
# │ lm_head                  │    31.4   │  16.4%  │   41.3   │
# └────────────────────────────────────────────────────────────┘
# Total: 191.2ms (5.2 tok/s)
```

**Ground Truth Benchmarking vs HuggingFace**:
```bash
# Generate HuggingFace baseline (Python)
python scripts/hf_baseline.py --model Qwen/Qwen2-0.5B-Instruct --output baseline.json

# Compare aprender performance against baseline
renacer compare baseline.json --tolerance 2x

# Expected output:
# ┌─────────────────────────────────────────────────────────────────┐
# │ Operation          │ HF (ms) │ APR (ms) │ Ratio │ Status       │
# ├─────────────────────────────────────────────────────────────────┤
# │ embed_lookup       │    1.8  │    2.3   │ 1.28x │ ✅ PASS      │
# │ attention (per L)  │   28.4  │   30.8   │ 1.08x │ ✅ PASS      │
# │ mlp (per layer)    │   32.1  │   35.5   │ 1.11x │ ✅ PASS      │
# │ matmul (avg)       │    8.2  │    9.1   │ 1.11x │ ✅ PASS      │
# │ softmax            │    2.1  │   18.7   │ 8.90x │ ❌ FAIL      │  ← Bug found!
# │ total forward      │  185.0  │  191.2   │ 1.03x │ ✅ PASS      │
# └─────────────────────────────────────────────────────────────────┘
```

**Performance Thresholds** (fail CI if exceeded):
| Operation | Max Slowdown vs HF | Rationale |
|-----------|-------------------|-----------|
| `matmul` | 1.5x | Core operation, SIMD critical |
| `attention` | 2.0x | Complex, some overhead OK |
| `softmax` | 2.0x | Numerically sensitive |
| `layernorm/rmsnorm` | 2.0x | Simple reduction |
| `total forward` | 2.0x | Overall budget |
| `tok/s` | 0.5x (min 50%) | User-facing metric |

**Detecting Naive Implementations**:
```bash
# If GFLOPS < 10 on any matmul, it's likely naive
renacer detect-naive model.apr

# Output:
# ❌ NAIVE DETECTED: layers.5.mlp.gate_proj.matmul
#    GFLOPS: 2.3 (expected >40)
#    Likely cause: .data().iter() loop instead of Tensor::matmul
#    File: src/models/qwen2/mod.rs:167
```

**CI Integration**:
```yaml
# .github/workflows/performance.yml
- name: Profile with Renacer
  run: |
    renacer profile apr chat model.apr --granular --json > profile.json
    renacer compare baseline.json profile.json --fail-threshold 2x

- name: Detect Naive Implementations
  run: |
    renacer detect-naive model.apr --fail-on-naive
```

**Rationale (Toyota Way: Standardized Work)**:
- Native libraries are tested (96.94% coverage)
- Native libraries use mmap (zero-copy, low memory)
- Native libraries handle edge cases (NaN, Inf, OOM)
- Ad-hoc code duplicates effort and introduces bugs
- Random initialization provides "fake" functionality that misleads users.

**Enforcement**:
- CI lint check for `fs::read` in model loading paths
- PR review checklist: "Uses native aprender infrastructure?"
- Mutation testing covers native paths
- **Build fails if no `.apr` file is present (no fallback)**

#### 2.4.3 apr profile — Deep Idiomatic Profiling (Any Model)

**MANDATE**: The `apr profile` command provides deep, architecture-aware profiling that works on ANY model format, leveraging the sovereign AI stack's knowledge of compute hierarchies to identify true hotspots.

**Instrumentation & Observability Mandate**:
To support this command, the codebase MUST implement deep instrumentation:
1.  **Span Emission**: Every logical block (Attention, MLP, RMSNorm, MatMul) MUST emit a `renacer::span!`.
2.  **Metadata**: Spans MUST attach input tensor shapes `(B, T, D)` to enable Roofline efficiency calculations.
3.  **Context**: The `apr chat` REPL must initialize a new Trace ID for each user turn.

**Why a Dedicated Profile Command**:
- **Model-Agnostic**: Works with `.apr`, `.safetensors`, `.gguf` — not just our format
- **Stack-Aware**: Understands Trueno's SIMD/GPU dispatch to identify REAL bottlenecks
- **Renacer Integration**: Uses battle-tested profiling primitives from renacer
- **Falsifiable Output**: Produces machine-readable reports for CI enforcement
- **Green AI**: Measures energy consumption (Joules/Token) via RAPL/PowerCap

**Command Syntax**:
```bash
# Basic profiling (identifies top 5 hotspots)
apr profile model.apr
apr profile model.safetensors
apr profile model.gguf

# Granular layer-by-layer analysis
apr profile model.apr --granular

# Enable Energy/Power profiling (requires sudo or capabilities)
apr profile model.apr --energy

# Compare against HuggingFace baseline (differential profiling)
apr profile model.apr --compare-hf Qwen/Qwen2-0.5B-Instruct

# Output formats
apr profile model.apr --format json > profile.json
apr profile model.apr --format flamegraph > profile.svg

# Profile specific operations
apr profile model.apr --focus attention
apr profile model.apr --focus mlp
apr profile model.apr --focus matmul

# Detect naive implementations (GFLOPS threshold check)
apr profile model.apr --detect-naive --threshold 10
```

**Output Format (Human-Readable)**:
```
┌──────────────────────────────────────────────────────────────────────────┐
│                      apr profile: model.apr                               │
│                      Architecture: qwen2 (24 layers)                      │
│                      Backend: Trueno SIMD (AVX2)                          │
├──────────────────────────────────────────────────────────────────────────┤
│                                                                           │
│  HOTSPOT ANALYSIS (Forward Pass, seq_len=128)                            │
│  ════════════════════════════════════════════                            │
│                                                                           │
│  #1 MLP Projections       2199ms (57.1%)  ██████████████████░░░░  BOUND  │
│     └─ gate_up_proj:      1450ms          Compute-bound (42 GFLOPS)      │
│     └─ down_proj:          749ms          Compute-bound (48 GFLOPS)      │
│                                                                           │
│  #2 LM Head               1311ms (34.0%)  ███████████░░░░░░░░░░░  BOUND  │
│     └─ matmul [H,V]:      1311ms          Memory-bound (12 GFLOPS)       │
│                                                                           │
│  #3 Attention              338ms  (8.8%)  ███░░░░░░░░░░░░░░░░░░░  OK     │
│     └─ QKV proj:           201ms          Compute-bound (45 GFLOPS)      │
│     └─ softmax:             42ms          Memory-bound (8 GFLOPS)        │
│     └─ attn matmul:         95ms          Compute-bound (52 GFLOPS)      │
│                                                                           │
│  #4 Embedding                4ms  (0.1%)  ░░░░░░░░░░░░░░░░░░░░░░  OK     │
│  #5 RMSNorm                  3ms  (0.1%)  ░░░░░░░░░░░░░░░░░░░░░░  OK     │
│                                                                           │
├──────────────────────────────────────────────────────────────────────────┤
│  ROOFLINE ANALYSIS (Williams et al., 2009)                               │
│  ═════════════════════════════════════════                               │
│                                                                           │
│  Peak Theoretical: 256 GFLOPS (AVX2 @ 3.2GHz)                            │
│  Achieved:         42 GFLOPS (16.4% efficiency)                          │
│  Bottleneck:       Memory bandwidth (LM head is vocabulary-bound)        │
│                                                                           │
│  ⚠ WARNING: LM head at 12 GFLOPS (memory-bound)                          │
│     Recommendation: Vocabulary pruning or speculative decoding           │
│                                                                           │
├──────────────────────────────────────────────────────────────────────────┤
│  ENERGY EFFICIENCY (Green AI)                                            │
│  ════════════════════════════                                            │
│                                                                           │
│  Total Energy:     15.4 J                                                │
│  Efficiency:       5.2 J/token                                           │
│  Carbon Impact:    ~0.01g CO2e (grid estimate)                           │
│  Method:           RAPL (CPU Package + DRAM)                             │
│                                                                           │
├──────────────────────────────────────────────────────────────────────────┤
│  NAIVE DETECTION (Graham et al., 1982)                                   │
│  ═════════════════════════════════════                                   │
│                                                                           │
│  ✓ No naive loops detected in hot path                                   │
│  ✓ All matmul operations use SIMD backend                                │
│  ✓ No .data().iter() patterns in inference code                          │
│                                                                           │
├──────────────────────────────────────────────────────────────────────────┤
│  SUMMARY                                                                  │
│  ═══════                                                                  │
│  Total forward pass:  3855ms                                             │
│  Throughput:          0.26 tok/s                                         │
│  Memory peak:         2.1 GB                                             │
│  Efficiency grade:    B (compute-bound, not naive)                       │
│                                                                           │
│  Top optimization targets:                                                │
│  1. MLP gate_up_proj: Consider fused kernel                              │
│  2. LM head: Vocabulary sharding or speculative decode                   │
│  3. Attention softmax: Fused attention (FlashAttention)                  │
│                                                                           │
└──────────────────────────────────────────────────────────────────────────┘
```

**JSON Output Schema** (for CI integration):
```json
{
  "model": "model.apr",
  "architecture": "qwen2",
  "backend": "trueno_simd_avx2",
  "timestamp": "2025-12-23T10:30:00Z",
  "config": {
    "seq_len": 128,
    "batch_size": 1
  },
  "summary": {
    "total_ms": 3855.2,
    "throughput_tok_s": 0.26,
    "memory_peak_bytes": 2147483648,
    "efficiency_grade": "B"
  },
  "energy": {
    "total_joules": 15.4,
    "joules_per_token": 5.2,
    "co2_grams": 0.01,
    "method": "rapl"
  },
  "hotspots": [
    {
      "name": "mlp",
      "time_ms": 2199.95,
      "percent": 57.1,
      "gflops": 42.3,
      "bound": "compute",
      "status": "ok"
    },
    {
      "name": "lm_head",
      "time_ms": 1311.55,
      "percent": 34.0,
      "gflops": 12.1,
      "bound": "memory",
      "status": "warning"
    }
  ],
  "roofline": {
    "peak_gflops": 256,
    "achieved_gflops": 42,
    "efficiency_percent": 16.4,
    "bottleneck": "memory_bandwidth"
  },
  "naive_detected": false,
  "recommendations": [
    "MLP gate_up_proj: Consider fused kernel",
    "LM head: Vocabulary sharding or speculative decode"
  ]
}
```

**Roofline Model Integration (Williams et al., 2009)**:

The `apr profile` command implements Roofline analysis to distinguish between:
- **Compute-bound operations**: GFLOPS limited by CPU/GPU compute capacity
- **Memory-bound operations**: GFLOPS limited by memory bandwidth

```
                    ROOFLINE MODEL
    GFLOPS │
       256 ├─────────────────────────────────┬─ Peak (AVX2)
           │                              ╱  │
           │                           ╱     │
       128 │                        ╱        │  ← Compute ceiling
           │                     ╱           │
           │                  ╱ ┌────────────┤
        64 │               ╱    │ MLP (42)   │  ← Actual ops
           │            ╱       ├────────────┤
        32 │         ╱          │            │
           │      ╱             │            │
        16 │   ╱   ┌────────────┤            │
           │╱      │ LM Head(12)│            │  ← Memory bound
         0 └───────┴────────────┴────────────┴───────────────
           0       1       2       4       8      16
                  Arithmetic Intensity (FLOPS/byte)
```

**Gprof-Style Call Graph (Graham et al., 1982)**:
```bash
apr profile model.apr --callgraph

# Output:
# forward() [3855ms, 100%]
#   ├── embed_tokens() [4ms, 0.1%]
#   ├── layers[0..23].forward() [2543ms, 66.0%]
#   │     ├── input_layernorm() [1ms]
#   │     ├── self_attn() [338ms, 8.8%]
#   │     │     ├── qkv_proj() [201ms]
#   │     │     ├── attention() [95ms]
#   │     │     └── out_proj() [42ms]
#   │     ├── post_attention_layernorm() [1ms]
#   │     └── mlp() [2199ms, 57.1%]          ← HOTSPOT
#   │           ├── gate_up_proj() [1450ms]  ← OPTIMIZE
#   │           └── down_proj() [749ms]
#   ├── norm() [3ms, 0.1%]
#   └── lm_head() [1311ms, 34.0%]            ← HOTSPOT
```

**Differential Profiling (McKeeman, 1998)**:
```bash
# Compare performance against HuggingFace baseline
apr profile model.apr --compare-hf Qwen/Qwen2-0.5B-Instruct

# Output:
# ┌─────────────────────────────────────────────────────────────────┐
# │ Operation          │ HF (ms) │ APR (ms) │ Ratio │ Status       │
# ├─────────────────────────────────────────────────────────────────┤
# │ embed_lookup       │    1.8  │    2.3   │ 1.28x │ ✅ PASS      │
# │ attention (avg)    │   28.4  │   30.8   │ 1.08x │ ✅ PASS      │
# │ mlp (avg)          │   32.1  │   35.5   │ 1.11x │ ✅ PASS      │
# │ lm_head            │   45.2  │   54.6   │ 1.21x │ ✅ PASS      │
# │ total forward      │  185.0  │  191.2   │ 1.03x │ ✅ PASS      │
# └─────────────────────────────────────────────────────────────────┘
# All operations within 2x threshold ✓
```

**CI Integration**:
```yaml
# .github/workflows/performance.yml
- name: Profile Model Performance
  run: |
    apr profile model.apr --format json > profile.json

    # Fail if any operation is naive (< 10 GFLOPS on matmul)
    apr profile model.apr --detect-naive --threshold 10 --fail-on-naive

    # Fail if > 2x slower than HuggingFace baseline
    apr profile model.apr --compare-hf Qwen/Qwen2-0.5B-Instruct --fail-threshold 2x

- name: Upload Profile Artifacts
  uses: actions/upload-artifact@v4
  with:
    name: profile-report
    path: profile.json
```

**Profiling Methodology Citations**:
| Method | Citation | Application |
|--------|----------|-------------|
| **Roofline Model** | Williams et al. (2009) | Compute vs memory bound classification |
| **Call Graph Profiling** | Graham et al. (1982) | Hierarchical time attribution |
| **Differential Testing** | McKeeman (1998) | Baseline comparison methodology |
| **Statistical Profiling** | Anderson & Lazowska (1990) | Sampling-based overhead reduction |
| **Performance Counters** | Eyerman & Eeckhout (2008) | Hardware event instrumentation |
| **Performance Hints** | Dean & Ghemawat (2025) | Allocation patterns, data structure selection |

#### 2.4.4 Performance Grading (Dean & Ghemawat, 2025)

**MANDATE**: `apr profile` implements performance pattern detection based on Google's battle-tested [Abseil Performance Hints](https://abseil.io/fast/hints.html) by Jeff Dean & Sanjay Ghemawat.

**Static Performance Grade Categories (Code Quality - 20 points)**:

*Evaluated via AST analysis of the source code.*

```
┌──────────────────────────────────────────────────────────────────────────┐
│  STATIC PERFORMANCE GRADE (Dean & Ghemawat, 2025)                        │
│  ════════════════════════════════════════════════                        │
│                                                                           │
│  Category                          Score   Status                        │
│  ─────────────────────────────────────────────────────────               │
│  1. Memory Allocation Patterns     5/6     ⚠ Missing arena allocation   │
│     ├─ Inlined storage (SmallVec)  ✓ 2/2                                │
│     ├─ Arena allocation            ✗ 0/2   Use bumpalo for batch ops    │
│     └─ Pre-allocation              ✓ 2/2   with_capacity() detected     │
│                                                                           │
│  2. Data Structure Selection       5/5     ✓ Optimal                    │
│     ├─ Compact representations     ✓ 2/2   #[repr(C)] on Tensor         │
│     ├─ Batched storage             ✓ 2/2   Vec over LinkedList          │
│     └─ Index vs pointer            ✓ 1/1   Index-based graphs           │
│                                                                           │
│  3. Algorithmic Efficiency         4/4     ✓ Optimal                    │
│     ├─ Bulk API patterns           ✓ 2/2   extend() over push() loop    │
│     └─ Fast path annotations       ✓ 2/2   #[cold] on error paths       │
│                                                                           │
│  4. Synchronization Quality        2/3     ⚠ Lock granularity          │
│     ├─ Lock granularity            ✗ 0/1   Global mutex detected        │
│     ├─ Lock-free patterns          ✓ 1/1   atomic usage correct         │
│     └─ Critical section            ✓ 1/1   No I/O inside locks          │
│                                                                           │
│  5. Code Size Awareness            2/2     ✓ Optimal                    │
│     ├─ Inline discipline           ✓ 1/1   No large #[inline(always)]   │
│     └─ Generic bloat               ✓ 1/1   Monomorphization controlled  │
│                                                                           │
│  ─────────────────────────────────────────────────────────               │
│  TOTAL PERFORMANCE GRADE:          18/20   Grade: A (90%)               │
│                                                                           │
└──────────────────────────────────────────────────────────────────────────┘
```

**Detection Patterns (AST-Based)**:

```rust
// ═══════════════════════════════════════════════════════════════════════
// 1. MEMORY ALLOCATION PATTERNS (6 pts)
// ═══════════════════════════════════════════════════════════════════════

// GOOD: Inlined storage (2 pts) - avoids heap for small collections
use smallvec::SmallVec;
let tags: SmallVec<[Tag; 4]> = SmallVec::new();  // ✓ Detected

// GOOD: Arena allocation (2 pts) - batch allocations
use bumpalo::Bump;
let arena = Bump::new();
let nodes: &mut [Node] = arena.alloc_slice_fill_default(1000);  // ✓ Detected

// GOOD: Pre-allocation (2 pts) - avoids realloc
let mut results = Vec::with_capacity(items.len());  // ✓ Detected

// BAD: Repeated allocation (0 pts)
let mut results = Vec::new();
for item in items {
    results.push(process(item));  // ✗ Flagged: realloc in loop
}

// ═══════════════════════════════════════════════════════════════════════
// 2. DATA STRUCTURE SELECTION (5 pts)
// ═══════════════════════════════════════════════════════════════════════

// GOOD: Compact representation (2 pts)
#[repr(C)]
struct Tensor {
    data: *const f32,
    shape: [usize; 4],
    strides: [usize; 4],
}  // ✓ Detected: #[repr(C)]

// GOOD: Batched storage (2 pts) - flat over pointer-heavy
let items: Vec<Item> = vec![];  // ✓ Preferred
// vs
let items: LinkedList<Item> = LinkedList::new();  // ✗ Flagged: pointer-heavy

// GOOD: Index-based graphs (1 pt)
struct Graph {
    nodes: Vec<Node>,
    edges: Vec<(usize, usize)>,  // ✓ Index-based
}
// vs
struct GraphBad {
    root: Box<Node>,  // ✗ Flagged: Box<Node> pattern
}

// ═══════════════════════════════════════════════════════════════════════
// 3. ALGORITHMIC EFFICIENCY (4 pts)
// ═══════════════════════════════════════════════════════════════════════

// GOOD: Bulk API (2 pts)
results.extend(items.iter().map(process));  // ✓ Detected: extend()

// BAD: Single-element in loop (0 pts)
for item in items {
    results.push(process(item));  // ✗ Flagged: push in loop
}

// GOOD: Fast path annotation (2 pts)
#[cold]
#[inline(never)]
fn handle_error(e: Error) -> ! {
    panic!("Critical error: {e}");
}  // ✓ Detected: #[cold] on error path

// ═══════════════════════════════════════════════════════════════════════
// 4. SYNCHRONIZATION QUALITY (3 pts)
// ═══════════════════════════════════════════════════════════════════════

// GOOD: Sharded locks (1 pt)
use dashmap::DashMap;
let cache: DashMap<K, V> = DashMap::new();  // ✓ Detected: DashMap

// GOOD: Lock-free (1 pt)
use crossbeam::queue::ArrayQueue;
let queue: ArrayQueue<Task> = ArrayQueue::new(1024);  // ✓ Detected

// BAD: I/O inside critical section (0 pts)
{
    let guard = mutex.lock();
    std::fs::write("log.txt", data)?;  // ✗ Flagged: I/O inside lock
}

// ═══════════════════════════════════════════════════════════════════════
// 5. CODE SIZE AWARENESS (2 pts)
// ═══════════════════════════════════════════════════════════════════════

// WARNING: Large inline function (deduct 1 pt)
#[inline(always)]
fn process_megabytes(data: &[u8]) -> Vec<u8> {
    // 200+ lines of code
}  // ✗ Warning: #[inline(always)] on large function

// GOOD: Controlled monomorphization
fn process<T: AsRef<[u8]>>(data: T) -> Vec<u8> {
    process_bytes(data.as_ref())  // ✓ Delegates to concrete impl
}
fn process_bytes(data: &[u8]) -> Vec<u8> { ... }  // Concrete, not generic
```

**Performance Crate Detection**:

`apr profile` awards points for adoption of performance-oriented crates:

| Crate | Category | Points | Rationale |
|-------|----------|--------|-----------|
| `smallvec` | Inlined storage | +2 | Avoid heap for <N elements |
| `arrayvec` | Inlined storage | +2 | Stack-allocated Vec |
| `tinyvec` | Inlined storage | +2 | Zero-dependency small vec |
| `bumpalo` | Arena allocation | +2 | Batch allocations |
| `typed-arena` | Arena allocation | +2 | Type-safe arenas |
| `dashmap` | Lock sharding | +1 | Concurrent HashMap |
| `parking_lot` | Synchronization | +1 | Faster mutexes |
| `crossbeam` | Lock-free | +1 | Lock-free data structures |

**JSON Output Extension**:

```json
{
  "performance_grade": {
    "total_score": 35,
    "max_score": 40,
    "grade": "A",
    "percent": 87.5,
    "static_grade": {
      "score": 18,
      "max": 20,
      "grade": "A",
      "categories": {
        "memory_allocation": {
          "score": 5,
          "max": 6,
          "issues": ["Missing arena allocation for batch tensor ops"]
        },
        "data_structures": {
          "score": 5,
          "max": 5,
          "issues": []
        },
        "algorithmic_efficiency": {
          "score": 4,
          "max": 4,
          "issues": []
        },
        "synchronization": {
          "score": 2,
          "max": 3,
          "issues": ["Global mutex in KVCache - consider sharding"]
        },
        "code_size": {
          "score": 2,
          "max": 2,
          "issues": []
        }
      },
      "detected_patterns": {
        "good": [
          "Vec::with_capacity() in 12 locations",
          "#[repr(C)] on Tensor struct",
          "#[cold] on 5 error handlers"
        ],
        "warnings": [
          "push() in loop at src/models/qwen2/mod.rs:234",
          "Global Mutex at src/cache.rs:45"
        ]
      }
    },
    "runtime_grade": {
      "score": 17,
      "max": 20,
      "grade": "A-",
      "categories": {
        "roofline_efficiency": {
          "score": 3,
          "max": 4,
          "value": "42%",
          "target": ">60%"
        },
        "throughput": {
          "score": 3,
          "max": 4,
          "value": "24 tok/s",
          "target": ">30 tok/s"
        },
        "latency_ttft": {
          "score": 4,
          "max": 4,
          "value": "450ms",
          "target": "<500ms"
        },
        "memory_fragmentation": {
          "score": 4,
          "max": 4,
          "value": "5%",
          "target": "<10%"
        },
        "energy_efficiency": {
          "score": 3,
          "max": 4,
          "value": "2.5 J/tok",
          "target": "<2 J/tok"
        }
      }
    }
  }
}
```

**Runtime Performance Grade Categories (Execution Quality - 20 points)**:

*Evaluated via dynamic profiling of the running model.*

| Category | Weight | Criteria (Grade A / 4pts) | Criteria (Grade F / 0pts) |
|----------|--------|---------------------------|---------------------------|
| **1. Roofline Efficiency** | 4 pts | > 60% of theoretical peak | < 10% of theoretical peak |
| **2. Throughput (Tok/s)** | 4 pts | > 30 tok/s (CPU), > 100 (GPU) | < 5 tok/s |
| **3. Latency (TTFT)** | 4 pts | < 500 ms | > 2000 ms |
| **4. Memory Fragmentation** | 4 pts | < 10% overhead | > 50% overhead |
| **5. Energy Efficiency** | 4 pts | < 2 J/token | > 10 J/token |

**Composite Score Calculation**:
`Total Score = (Static Score * 0.5) + (Runtime Score * 0.5)`
- **A+**: 38-40 points (State of the Art)
- **A**: 35-37 points (Production Grade)
- **B**: 30-34 points (Solid)
- **C**: 20-29 points (Needs Optimization)
- **F**: < 20 points (Failed)

**Latency Reference Table (Dean & Ghemawat, 2025)**:

For context, `apr profile` includes these latency numbers in recommendations:

| Operation | Latency | Implication |
|-----------|---------|-------------|
| L1 cache reference | 1 ns | Target for hot data |
| L2 cache reference | 4 ns | Acceptable for warm data |
| L3 cache reference | 40 ns | Consider prefetch |
| Main memory | 100 ns | Avoid random access |
| SSD read | 100 μs | Batch I/O operations |
| HDD seek | 10 ms | Absolutely avoid in hot path |
| Network round trip | 500 μs - 150 ms | Async/batch all network |

**Model-Agnostic Architecture Detection**:

`apr profile` auto-detects model architecture from any format:

```rust
// Architecture detection priority:
// 1. Explicit metadata in .apr files
// 2. Tensor name patterns (e.g., "model.layers.0.self_attn.q_proj")
// 3. Shape inference (hidden_size, num_heads, etc.)
// 4. Config files (config.json for SafeTensors)

fn detect_architecture(path: &Path) -> Architecture {
    match path.extension() {
        Some("apr") => Architecture::from_apr_metadata(path),
        Some("safetensors") => Architecture::from_tensor_names(path),
        Some("gguf") => Architecture::from_gguf_metadata(path),
        _ => Architecture::Unknown
    }
}
```

**Supported Architectures**:
| Architecture | Tensor Pattern | Layer Components |
|--------------|---------------|------------------|
| `qwen2` | `model.layers.*.self_attn.*` | Attention + MLP + RMSNorm |
| `llama` | `model.layers.*.self_attn.*` | Attention + MLP + RMSNorm |
| `mistral` | `model.layers.*.self_attn.*` | Attention + MLP + RMSNorm |
| `gpt2` | `h.*.attn.*` | Attention + MLP + LayerNorm |
| `bert` | `encoder.layer.*.attention.*` | Attention + FFN + LayerNorm |
| `whisper` | `encoder.layers.*.self_attn.*` | Encoder-Decoder + Cross-Attn |

---

## 3. Architecture Overview

### 3.1 System Diagram

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     Qwen2-0.5B Interactive Chat                          │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌────────────────────────────────────────────────────────────────────┐ │
│  │                        User Interface Layer                         │ │
│  │                                                                      │ │
│  │   ┌─────────────┐              ┌─────────────────────────────────┐  │ │
│  │   │ CLI REPL    │              │   WASM Module (wasmtime)        │  │ │
│  │   │ `apr chat`  │              │   Zero JavaScript               │  │ │
│  │   └──────┬──────┘              └───────────────┬─────────────────┘  │ │
│  │          │                                      │                    │ │
│  └──────────┼──────────────────────────────────────┼────────────────────┘ │
│             │                                      │                      │
│             ▼                                      ▼                      │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │                      Inference Engine                               │  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────────┐  │  │
│  │  │  BPE         │  │  Qwen2Model  │  │  Sampling                │  │  │
│  │  │  Tokenizer   │─▶│  Forward     │─▶│  (Nucleus/TopK)          │  │  │
│  │  │              │  │  Pass        │  │                          │  │  │
│  │  └──────────────┘  └──────┬───────┘  └──────────────────────────┘  │  │
│  │                           │                                         │  │
│  │                           ▼                                         │  │
│  │                  ┌──────────────────┐                               │  │
│  │                  │ Inspection Probe │ (For Visual Control)          │  │
│  │                  │ (Logits/Attn)    │                               │  │
│  │                  └──────────────────┘                               │  │
│  └────────────────────────────────────────────────────────────────────┘  │
│                                    │                                      │
│                                    ▼                                      │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │                      APR Model Storage                              │  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────────┐  │  │
│  │  │  .apr File   │  │  Zero-Copy   │  │  INT4 Quantized          │  │  │
│  │  │  (CDN/Local) │─▶│  mmap        │─▶│  Weights (~300MB)        │  │  │
│  │  └──────────────┘  └──────────────┘  └──────────────────────────┘  │  │
│  └────────────────────────────────────────────────────────────────────┘  │
│                                    │                                      │
│                                    ▼                                      │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │                      Trueno Compute Backend                         │  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────────┐  │  │
│  │  │  CPU SIMD    │  │  WASM SIMD   │  │  GPU (future)            │  │  │
│  │  │  AVX2/AVX512 │  │  SIMD128     │  │  wgpu                    │  │  │
│  │  └──────────────┘  └──────────────┘  └──────────────────────────┘  │  │
│  └────────────────────────────────────────────────────────────────────┘  │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 4. Implementation Components

### 4.1 Qwen2Model Struct

```rust
/// Complete Qwen2-0.5B model for inference
///
/// Architecture per Bai et al. (2023) "Qwen Technical Report"
pub struct Qwen2Model {
    /// Token embeddings [151936, 896]
    embed_tokens: Embedding,

    /// 24 decoder layers
    layers: Vec<Qwen2DecoderLayer>,

    /// Final RMSNorm
    norm: RMSNorm,

    /// Language model head [896, 151936]
    lm_head: Linear,

    /// Rotary position embeddings
    rope: RotaryPositionEmbedding,

    /// Model configuration
    config: Qwen2Config,

    /// KV cache for efficient generation
    kv_cache: Option<KVCache>,

    /// Inspection probe for visual control (optional)
    pub probe: Option<Box<dyn InferenceProbe>>,
}
```

### 4.2 Forward Pass (Verified)

```rust
impl Qwen2Model {
    /// Single forward pass through the model
    pub fn forward(
        &mut self,
        input_ids: &[u32],
        position_ids: &[usize],
    ) -> Tensor {
        // ... implementation ...
        
        // VISUAL CONTROL: Probe hook
        if let Some(probe) = &mut self.probe {
            probe.on_layer_activations(&hidden);
        }

        self.lm_head.forward(&hidden)
    }
}
```

### 4.3 Weight Conversion with Validation

```bash
# Step 1: Import from HuggingFace
apr import hf://Qwen/Qwen2-0.5B-Instruct -o qwen2-0.5b-fp16.apr --arch qwen2

# Step 2: Quantize to INT4
apr convert qwen2-0.5b-fp16.apr --quantize int4 -o qwen2-0.5b-int4.apr

# Step 3: VERIFY against Golden Trace (Critical Step)
# Runs a standard prompt and compares logits against reference PyTorch output
apr test-model qwen2-0.5b-int4.apr --golden-trace golden_traces/qwen2_reference.json
```

---

## 5. CLI Interactive Mode

### 5.1 REPL Interface with Visual Control

```
$ apr chat qwen2-0.5b-int4.apr --inspect

=== Qwen2-0.5B-Instruct Chat (Inspection Mode) ===
Model: qwen2-0.5b-int4.apr (316 MB, INT4)
Validation: PASSED (Checksum: a1b2...)

You: What is 2+2?

[DEBUG] Tokenized: [234, 12, 553, 11]

Assistant: 4
[DEBUG] Top-3 Candidates:
  1. "4" (0.98)
  2. "Four" (0.01)
  3. "\n" (0.005)

[Stats: 24.1 tok/s | PPL: 1.2 | Mem: 340MB]
```

---

## 6. WASM Portable Build

**Target**: `wasm32-wasi` for portable execution via wasmtime/wasmer. Zero JavaScript.

### 6.1 Building WASM Module

```bash
# Build WASM module (WASI target, not browser)
apr compile model.apr --target wasm32-wasi -o qwen.wasm

# Run with wasmtime (sandboxed, portable)
wasmtime qwen.wasm --dir=. -- "What is 2+2?"

# Or with wasmer
wasmer run qwen.wasm --dir=. -- "What is 2+2?"
```

### 6.2 WASI Interface

```rust
// Pure Rust, no wasm_bindgen, no JavaScript
fn main() {
    let args: Vec<String> = std::env::args().collect();
    let prompt = args.get(1).expect("Usage: qwen.wasm <prompt>");

    let model = Qwen2Model::load("model.apr").expect("Failed to load model");
    let response = model.generate(prompt, &GenerationConfig::default());

    println!("{}", response);
}
```

### 6.3 Why WASI over Browser WASM

| Aspect | Browser WASM | WASI (wasmtime) |
|--------|--------------|-----------------|
| JavaScript | Required (wasm-bindgen) | None |
| File I/O | Emulated/limited | Native via WASI |
| Sandboxing | Browser sandbox | Capability-based |
| Portability | Browser-only | Any WASI runtime |
| Complexity | High (JS glue) | Low (pure Rust) |

### 6.4 WASM Component Model (wasip2)

For advanced component composition, use the WASM Component Model:

```bash
# Build as WASM Component (wasip2 target)
cargo build --target wasm32-wasip2 --release

# Component produces: target/wasm32-wasip2/release/qwen_chat.wasm
```

**WIT Interface Definition** (`wit/qwen.wit`):

```wit
package aprender:qwen;

interface model {
    record generation-config {
        max-tokens: u32,
        temperature: f32,
        top-k: u32,
    }

    resource model {
        constructor(path: string);
        generate: func(prompt: string, config: generation-config) -> string;
        tokenize: func(text: string) -> list<u32>;
    }
}

world qwen-chat {
    import wasi:filesystem/types;
    import wasi:cli/stdin;
    import wasi:cli/stdout;

    export model;
}
```

### 6.5 Probador WASM Runner

Probador embeds wasmtime to execute and verify WASM components directly:

```bash
# Run WASM component via probador
apr probador wasm run qwen.wasm --input "What is 2+2?"

# Verify against golden traces
apr probador wasm verify qwen.wasm --golden golden/

# Profile WASM execution
apr probador wasm profile qwen.wasm --input "Hello" --warmup 3 --iterations 10

# Component testing with assertions
apr probador wasm test qwen.wasm --playbook playbooks/qwen-happy-path.yaml
```

**Probador WASM Runner Implementation** (like probar/simular):

```rust
// crates/apr-cli/src/commands/probador/wasm.rs
use wasmtime::{Config, Engine, Linker, Module, Store};
use wasmtime_wasi::WasiCtxBuilder;

pub struct WasmRunner {
    engine: Engine,
    linker: Linker<WasiState>,
}

impl WasmRunner {
    pub fn new() -> Result<Self> {
        let mut config = Config::new();
        config.wasm_component_model(true);

        let engine = Engine::new(&config)?;
        let mut linker = Linker::new(&engine);
        wasmtime_wasi::add_to_linker(&mut linker)?;

        Ok(Self { engine, linker })
    }

    /// Run WASM component with input prompt
    pub fn run(&self, wasm_path: &Path, input: &str) -> Result<String> {
        let module = Module::from_file(&self.engine, wasm_path)?;

        let wasi = WasiCtxBuilder::new()
            .inherit_stdio()
            .args(&[wasm_path.to_str().unwrap(), input])?
            .preopened_dir(".", ".")?
            .build();

        let mut store = Store::new(&self.engine, WasiState { wasi });
        let instance = self.linker.instantiate(&mut store, &module)?;

        // Call _start (WASI entry point)
        let start = instance.get_typed_func::<(), ()>(&mut store, "_start")?;
        start.call(&mut store, ())?;

        Ok(store.data().output.clone())
    }

    /// Verify WASM output against golden traces
    pub fn verify(&self, wasm_path: &Path, golden_dir: &Path) -> Result<VerifyReport> {
        let golden_inputs = load_golden_inputs(golden_dir)?;
        let mut report = VerifyReport::new();

        for (input, expected_output) in golden_inputs {
            let actual = self.run(wasm_path, &input)?;
            report.add_case(&input, &expected_output, &actual);
        }

        Ok(report)
    }
}
```

**Playbook Example for WASM Testing**:

```yaml
# playbooks/qwen-wasm-verify.yaml
name: "Qwen WASM Component Verification"
runner: wasm
component: qwen.wasm

setup:
  - action: load
    path: "model.apr"
    dir_mount: "."

cases:
  - name: "Basic arithmetic"
    input: "What is 2+2?"
    expect_contains: "4"
    max_latency_ms: 5000

  - name: "Greeting response"
    input: "Hello!"
    expect_not_empty: true

  - name: "Golden trace match"
    input: "Explain quantum computing"
    golden: "golden/quantum-computing.txt"
    tolerance: 0.01  # Allow 1% logit deviation

assertions:
  - all_cases_pass: true
  - avg_latency_ms: "<3000"
  - memory_mb: "<512"
```

**Running Playbook**:

```bash
# Execute WASM playbook via probador
apr probador run playbooks/qwen-wasm-verify.yaml

# Output:
# ✓ Basic arithmetic: PASS (1.2s)
# ✓ Greeting response: PASS (0.8s)
# ✓ Golden trace match: PASS (2.1s, deviation: 0.003)
#
# Summary: 3/3 passed
# Avg latency: 1.37s
# Peak memory: 342MB
```

---

## 7. Deep Probador Testing

This section specifies the **probador** (tester) methodology for achieving 100% verified functionality through coverage, integration tests, and golden trace verification.

### 7.1 Testing Philosophy: The Three Pillars

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     PROBADOR: Three Pillars of Testing                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   ┌─────────────────────┐   ┌─────────────────────┐   ┌─────────────────┐   │
│   │   PILAR 1: CÓDIGO   │   │   PILAR 2: GOLDEN   │   │  PILAR 3: INTEG │   │
│   │   (Code Coverage)   │   │    (Trace Verify)   │   │   (E2E Tests)   │   │
│   ├─────────────────────┤   ├─────────────────────┤   ├─────────────────┤   │
│   │ • 95%+ line coverage│   │ • PyTorch reference │   │ • CLI workflows │   │
│   │ • Branch coverage   │   │ • Logit comparison  │   │ • WASI execution│   │
│   │ • Mutation testing  │   │ • Perplexity check  │   │ • Server API    │   │
│   │ • Dead code removal │   │ • Tensor checksums  │   │ • Import/Export │   │
│   └─────────────────────┘   └─────────────────────┘   └─────────────────┘   │
│            │                         │                         │             │
│            └─────────────────────────┼─────────────────────────┘             │
│                                      ▼                                       │
│                         ┌─────────────────────────┐                          │
│                         │   PROBADOR REPORT       │                          │
│                         │   ✅ Coverage: 95%+     │                          │
│                         │   ✅ Golden: MATCH      │                          │
│                         │   ✅ E2E: 50/50 PASS    │                          │
│                         └─────────────────────────┘                          │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 Pilar 1: Code Coverage (95%+ Requirement)

**Target**: 95%+ line coverage for all Rust code.

#### Coverage Configuration

```toml
# Cargo.toml
[package.metadata.cargo-llvm-cov]
branch = true
fail-under-lines = 95
fail-under-branches = 90
```

#### Coverage Commands

```bash
# Generate coverage report
cargo llvm-cov --html -o coverage/

# Enforce 100% threshold (CI gate)
cargo llvm-cov --target wasm32-unknown-unknown --fail-under-lines 100

# View uncovered lines
cargo llvm-cov --target wasm32-unknown-unknown --show-missing-lines
```

#### Coverage Exclusions (Must Be Justified)

```rust
// ONLY these patterns may be excluded, with mandatory justification:

#[cfg(not(tarpaulin_include))]  // Unreachable panic handlers
fn unreachable_panic() -> ! {
    // JUSTIFICATION: WASM traps on panic, this is dead code by design
    unreachable!()
}

// NO exclusions allowed for:
// - Model inference paths
// - Tokenization
// - Sampling logic
// - Error handling
```

#### Mutation Testing for WASM

```bash
# Run mutation testing on WASM module
cargo mutants --target wasm32-unknown-unknown --timeout 300

# Minimum mutation score: 90%
# Any surviving mutant in inference path = build failure
```

### 7.3 Pilar 2: Playbook Testing (Scripted Scenarios)

**Playbooks** are deterministic, reproducible test scenarios that exercise complete user journeys.

#### Playbook Format

```yaml
# playbooks/qwen-chat-happy-path.yaml
name: "Qwen Chat Happy Path"
description: "Complete chat session with model loading and generation"
timeout: 60s
runner: cli

steps:
  - name: "Validate Model"
    action: run
    command: "apr validate model.apr"
    expect_exit: 0
    expect_output: "VALID"

  - name: "Run Chat Generation"
    action: run
    command: "apr chat model.apr --max-tokens 50"
    stdin: "What is 2+2?"
    timeout: 30s
    expect_exit: 0

  - name: "Verify Response Contains Answer"
    action: assert
    output_matches: "4|four|Four"

  - name: "Run WASI Version"
    action: run
    command: "wasmtime qwen.wasm --dir=. -- 'What is 2+2?'"
    expect_exit: 0
    expect_output: "4"

  - name: "Verify Inspect Mode"
    action: run
    command: "apr chat model.apr --inspect --max-tokens 10"
    stdin: "Hello"
    expect_output: "tok/s"
```

#### Playbook Categories (50 Required)

| Category | Count | Description |
|----------|-------|-------------|
| **Happy Path** | 10 | Normal CLI flows (chat, inspect, validate) |
| **Error Handling** | 10 | OOM, missing file, invalid input |
| **Edge Cases** | 10 | Empty prompt, max tokens, special chars, Unicode |
| **Performance** | 10 | Generation speed, memory, throughput |
| **WASI Execution** | 5 | wasmtime, wasmer compatibility |
| **Regression** | 5 | Previously fixed bugs must not recur |
| **TOTAL** | **50** | |

#### Playbook Execution

```bash
# Run all playbooks
make playbooks

# Run specific category
make playbooks CATEGORY=error-handling

# Generate HTML report
make playbooks-report

# CI gate: all 50 must pass
make playbooks-gate  # Exits non-zero if any fail
```

#### Example Playbooks

```yaml
# playbooks/error-oom.yaml
name: "OOM Handling"
runner: cli
steps:
  - name: "Trigger OOM condition"
    action: run
    command: "apr chat model.apr --max-tokens 100000"
    stdin: "Generate a very long response"
    expect_exit: 1
    expect_stderr: "memory"

# playbooks/edge-unicode.yaml
name: "Unicode Input"
runner: cli
steps:
  - name: "Unicode prompt"
    action: run
    command: "apr chat model.apr --max-tokens 20"
    stdin: "日本語で返答してください 🇯🇵"
    expect_exit: 0
  - action: assert
    output_not_empty: true

# playbooks/perf-first-token.yaml
name: "First Token Latency"
runner: cli
steps:
  - name: "Measure TTFT"
    action: run
    command: "apr chat model.apr --max-tokens 1 --inspect"
    stdin: "Hello"
    timeout: 5s
    expect_exit: 0
  - action: assert
    output_contains: "tok/s"
```

### 7.4 Pilar 3: Golden Trace Verification

**Goal**: Verify inference output matches PyTorch reference implementation.

#### Golden Trace Generation

```bash
# Generate golden traces from PyTorch (reference)
python scripts/generate_golden_traces.py \
    --model Qwen/Qwen2-0.5B-Instruct \
    --prompts test_prompts.txt \
    --output golden/

# Compare Rust implementation against golden
apr test-model model.apr --golden-trace golden/trace.json
```

#### Verification Categories

| Test | Golden File | Tolerance | Description |
|------|-------------|-----------|-------------|
| **Embedding** | `golden/embed.json` | 1e-5 | Token embedding vectors |
| **Layer 0 Output** | `golden/layer_0.json` | 1e-4 | First transformer layer |
| **Attention Scores** | `golden/attn_scores.json` | 1e-4 | QK^T / sqrt(d) values |
| **Final Logits** | `golden/logits.json` | 1e-3 | Output probability distribution |
| **Perplexity** | `golden/ppl.json` | 5% | Generation quality metric |
| **Top-K Tokens** | `golden/top_k.json` | exact | Token IDs must match |

#### Tensor Comparison

```bash
# Export intermediate tensors during inference
apr trace model.apr --prompt "Hello" --export tensors/

# Compare against golden reference
apr diff tensors/ golden/ --tolerance 1e-4

# Output:
# embed_tokens:    ✅ max_diff=2.3e-6 (tol: 1e-5)
# layer.0.attn:    ✅ max_diff=8.1e-5 (tol: 1e-4)
# layer.0.mlp:     ✅ max_diff=4.2e-5 (tol: 1e-4)
# ...
# layer.23.output: ✅ max_diff=9.8e-4 (tol: 1e-3)
# lm_head.logits:  ✅ max_diff=1.2e-3 (tol: 1e-3)
# PASSED: All tensors within tolerance
```

#### Golden Trace Configuration

```yaml
# golden-trace.yaml
verification:
  prompts:
    - "What is 2+2?"
    - "Hello, how are you?"
    - "The capital of France is"

  checkpoints:
    - layer: embedding
      tolerance: 1e-5
    - layer: "layers.*.output"
      tolerance: 1e-4
    - layer: logits
      tolerance: 1e-3

  metrics:
    perplexity:
      baseline: 8.5
      max_deviation: 5%
    top_k_accuracy:
      k: 5
      threshold: 0.95
```

#### CI/CD Integration

```yaml
# .github/workflows/golden-trace.yml
name: Golden Trace Verification
on: [push, pull_request]

jobs:
  verify:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build
        run: cargo build --release -p apr-cli

      - name: Run Playbooks
        run: make playbooks

      - name: Verify Golden Traces
        run: apr test-model model.apr --golden-trace golden/

      - name: Upload Trace Artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: trace-diff
          path: trace-diff/
```

### 7.5 Probador Command Reference

```bash
# ═══════════════════════════════════════════════════════════════════════════
# COVERAGE
# ═══════════════════════════════════════════════════════════════════════════
apr probador coverage                    # Run coverage, show summary
apr probador coverage --html             # Generate HTML report
apr probador coverage --fail-under 100   # CI gate at 100%

# ═══════════════════════════════════════════════════════════════════════════
# PLAYBOOKS
# ═══════════════════════════════════════════════════════════════════════════
apr probador playbook run playbooks/     # Run all playbooks
apr probador playbook run playbooks/happy-path.yaml  # Single playbook
apr probador playbook list               # List all playbooks
apr probador playbook validate           # Check playbook syntax
apr probador playbook create             # Create new playbook template

# ═══════════════════════════════════════════════════════════════════════════
# GOLDEN TRACE VERIFICATION
# ═══════════════════════════════════════════════════════════════════════════
apr probador golden generate             # Generate golden traces from PyTorch
apr probador golden verify               # Verify against golden traces
apr probador golden update               # Update golden after approved change
apr probador trace diff                  # Show tensor differences

# ═══════════════════════════════════════════════════════════════════════════
# TENSOR ANALYSIS
# ═══════════════════════════════════════════════════════════════════════════
apr probador tensor export model.apr     # Export layer tensors
apr probador tensor compare v1/ v2/      # Compare two versions
apr probador tensor stats model.apr      # Show tensor statistics

# ═══════════════════════════════════════════════════════════════════════════
# FULL SUITE
# ═══════════════════════════════════════════════════════════════════════════
apr probador full                        # Run all three pillars
apr probador report                      # Generate combined report
apr probador ci                          # CI mode (strict, no-color)

# ═══════════════════════════════════════════════════════════════════════════
# MAKEFILE TARGETS
# ═══════════════════════════════════════════════════════════════════════════
make probador                                # Full suite
make probador-coverage                       # Coverage only
make probador-playbooks                      # Playbooks only
make probador-golden                         # Golden trace verification only
make probador-report                         # Generate report
```

---

## 8. Performance Requirements

This section defines the non-negotiable performance budget for the demo. Failure to meet these constitutes a defect.

### 8.1 Latency & Throughput (Falsifiable)

| Metric | Target | Falsification Threshold (Fail if...) |
|--------|--------|--------------------------------------|
| **TTFT (First Token)** | < 1.0s | > 2.0s on M1 Max / > 4.0s on Mobile |
| **Decode Speed** | > 25 tok/s | < 15 tok/s on M1 Max (human reading speed) |
| **Total Turn Time** | < 5.0s | > 10.0s for short answer (50 tokens) |
| **Model Load Time** | < 2.0s | > 5.0s (cold start) |

### 8.2 Resource Constraints

| Metric | Budget | Falsification Threshold (Fail if...) |
|--------|--------|--------------------------------------|
| **WASM Binary** | < 5 MB | > 8 MB (gzip) |
| **Model Size** | < 350 MB | > 400 MB (Int4) |
| **RAM Usage** | < 512 MB | > 1024 MB (Crash risk on mobile) |
| **VRAM (if GPU)** | < 1 GB | > 1.5 GB |

### 8.3 Quality Baseline

| Metric | Target | Falsification Threshold (Fail if...) |
|--------|--------|--------------------------------------|
| **Perplexity** | < 10.0 | > 15.0 on WikiText-2 (Int4) |
| **Accuracy** | Match Ref | Logit deviation > 1e-3 vs FP16 |

---

## 9. Peer-Reviewed Citations

In the spirit of Karl Popper, we do not simply "believe" our code works. We verify it against the mathematical truths established in peer-reviewed literature. Each component below is anchored to a specific publication and verified by reproducing its results (or matching its reference implementation).

### 9.1 Verification Matrix

| Component | Primary Citation | Verification (Falsification Method) |
|-----------|------------------|-------------------------------------|
| **Transformer** | Vaswani et al. (2017) | **Golden Trace**: Must match PyTorch `nn.MultiheadAttention` output within `1e-5`. |
| **RoPE** | Su et al. (2024) | **Math Check**: Verify rotation matrix $R_{\Theta,d}^d$ against Eq. 34 in paper. |
| **SwiGLU** | Shazeer (2020) | **Math Check**: Verify $Swish_{\beta}(x) = x \sigma(\beta x)$ monotonicity properties. |
| **RMSNorm** | Zhang & Sennrich (2019) | **Golden Trace**: Compare against `LlamaRMSNorm` implementation in HuggingFace. |
| **Qwen2 Arch** | Bai et al. (2023) | **Shape Check**: Validate layer counts, head dims against Tech Report Table 1. |
| **Nucleus** | Holtzman et al. (2020) | **Stat Check**: Verify CDF truncation logic excludes tail mass correctly. |
| **WASM SIMD** | Haas et al. (2017) | **Instruction Check**: Verify usage of `v128.load` and `f32x4.mul` in hot loops. |
| **Optimized Compute** | Williams et al. (2009) | **Roofline Analysis**: Verify GFLOPS > 80% of theoretical peak for given arithmetic intensity. |
| **Correctness** | McKeeman (1998) | **Differential Testing**: Compare `apr` output vs `PyTorch` output for identical inputs. |
| **Call Graph Profiling** | Graham et al. (1982) | **Time Attribution**: Verify hierarchical timing sums to 100% of measured wall time. |
| **Statistical Sampling** | Anderson & Lazowska (1990) | **Low Overhead**: Sampling must add < 5% overhead to baseline execution time. |
| **Hardware Counters** | Eyerman & Eeckhout (2008) | **Counter Accuracy**: Performance counters must correlate with wall-clock measurements (r > 0.95). |

### 9.2 The Role of "Golden Traces"
Golden traces serve as our **falsifiers**. A golden trace is a serialized recording of every intermediate tensor value from a known-correct implementation (e.g., the official HuggingFace implementation). If our implementation deviates from the golden trace (beyond floating-point noise), our implementation is **proven false** and must be rejected.

---

## 10. Toyota Way Alignment

### 10.1 Principle Mapping

| # | Toyota Principle | Implementation |
|---|------------------|----------------|
| 1 | Long-term philosophy | Building a foundation for verified, sovereign AI, not just a flashy demo. |
| 2 | Continuous flow | Streaming generation; Continuous Integration of model quality. |
| 3 | Pull system | Model weights loaded on demand (mmap) / Lazy loading in WASM. |
| 4 | Level workload | Consistent batch sizes; Heijunka in token generation. |
| 5 | **Stop to fix problems (Jidoka)** | **CI pipeline FAILS if Perplexity > Threshold. No broken models shipped.** |
| 6 | Standardized tasks | `apr` CLI is the standard way to interact, WASM is just a view. |
| 7 | **Visual control** | **The demo MUST show internal probabilities to prove it's not a canned response.** |
| 8 | Reliable technology | Rust/WASM, Verified against PyTorch Golden Traces. |
| 12 | **Go and see (Genchi Genbutsu)** | **We verify the *actual* logits, not just the text output.** |

### 10.2 Root Cause Analysis: Stub Demo Failure

**Problem**: The previous demo was a fake stub.
**Root Cause**: Lack of automated verification of the *inference mechanics*.
**Countermeasure**: Introduce **Golden Trace Verification**. The system must mathematically match a known-good reference (PyTorch) for a set of inputs before release.

---

## 11. 180-Point Popperian Falsification Checklist

**Methodology**: Claims must be falsifiable. We specify the condition that PROVES the system is broken/fake.

### Section A: Model Loading (10 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| A1 | APR loads | `Qwen2Model::load()` returns error | ✅ |
| A2 | Weights Verified | Weight distribution mean/stddev deviation > 1% from ref | ✅ |
| A3 | Checksum Valid | File checksum does not match signed manifest | ✅ |
| A4 | Metadata Correct | Architecture/Vocab size mismatch config | ✅ |
| A5 | INT4 Size | File size > 400MB (indicates inefficient packing) | ✅ |
| **A6** | **No Random Weights** | **Weights are non-zero, non-Gaussian (fail if initialized to random)** | ✅ |

### Section B: Tokenization (10 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| B1 | Vocab Size | `vocab_size != 151936` | ✅ |
| B2 | Roundtrip | `decode(encode(x)) != x` for random unicode strings | ✅ |
| B3 | Special Tokens | `<|im_start|>` not mapped to 151644 | ✅ |
| B4 | Chat Template | Template injection attacks succeed | ✅ |
| B5 | Whitespace | Leading/trailing whitespace handling mismatches TikToken | ✅ |

### Section C: Forward Pass - The "No Fake" Zone (25 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| C1 | **Golden Trace** | **Logits deviate > 1e-4 from PyTorch reference on Test Set** | ✅ |
| C2 | Context Awareness | Changing token T-1 does not affect logits at T | ✅ |
| C3 | Determinism | Same input + fixed seed produces different logits | ✅ |
| C4 | Causal Mask | Token T attends to T+1 (information leak) | ✅ |
| C5 | KV Cache | Cache enabled result != Cache disabled result | ✅ |
| C6 | RoPE | Output is invariant to absolute position changes | ✅ |
| C7 | RMSNorm | Output scale diverges to Inf/NaN | ✅ |
| C8 | SwiGLU | Activations are all positive (Swish is non-monotonic) | ✅ |

### Section D: Generation & Quality (20 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| D1 | **Intelligence** | **Perplexity > 20 on WikiText-2 (indicates garbage model)** | ✅ |
| D2 | Diversity | Temp=1.0 generates identical sequence twice | ✅ |
| D3 | EOS Respect | Generation continues past `<|im_end|>` | ✅ |
| D4 | Repetition | 4-gram repetition rate > 30% (indicates sampling bug) | ✅ |
| D5 | Speed | Throughput < 10 tok/s on reference hardware | ✅ |

### Section E: Visual Control & Inspection (15 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| E1 | Logit Vis | UI fails to display Top-5 candidates | ✅ |
| E2 | Attn Vis | UI fails to display attention heatmap | ✅ |
| E3 | Stats | Token/sec counter is static/fake | ✅ |
| E4 | Mem Usage | Usage reported matches OS monitor ±10% | ✅ |

### Section F: WASM/WASI & Probador (20 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| F1 | WASI Build | `cargo build --target wasm32-wasi` fails | ✅ |
| F2 | Wasmtime Run | `wasmtime qwen.wasm` fails to execute | ✅ |
| F3 | File I/O | WASI cannot read model.apr from `--dir` | ✅ |
| F4 | Output | WASM module fails to produce valid text output | ✅ |
| **F5** | **Component Build** | `cargo build --target wasm32-wasip2` fails | ✅ |
| **F6** | **WIT Interface** | WIT file missing or invalid | ✅ |
| **F7** | **Probador Run** | `apr probador wasm run qwen.wasm` fails | ✅ |
| **F8** | **Probador Verify** | `apr probador wasm verify --golden` deviation > tolerance | ✅ |
| **F9** | **Playbook Execute** | `apr probador run playbook.yaml` fails to parse/execute | ✅ |
| **F10** | **WASM Perf** | WASM inference > 3x slower than native | ✅ |

### Section G: Code Quality (15 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| G1 | Coverage | Code coverage < 85% | ✅ |
| G2 | Safety | `unsafe` block used without justification comment | ✅ |
| G3 | Linting | `clippy` has warnings | ✅ |
| **G4** | **Native I/O** | **`fs::read()` used instead of `bundle::MappedFile`** | ✅ |
| **G5** | **Native Format** | **Raw SafeTensors used instead of `.apr` format** | ✅ |
| G6 | Native Errors | `String` errors used instead of `AprenderError` | ✅ |
| **G7** | **No Stubs** | **Any "fake" response logic detected in AST** | ✅ |
| **G8** | **SIMD Ops** | **`.data().iter()` found in inference hot path (use Tensor methods)** | ✅ |
| **G9** | **Roofline Check** | **Any operation falls below Roofline (Williams et al., 2009) efficiency zone** | ✅ |
| **G10** | **HF Ground Truth** | **Any operation >2x slower than HuggingFace baseline** | ✅ |

### Section H: Full Lifecycle — The North Star (20 points)

*This section validates the complete APR workflow: Download → Convert → Tune → Shrink → Deploy*

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **H1** | **HF Import** | `apr import hf://Qwen/Qwen2-0.5B-Instruct` fails | ✅ |
| H2 | SafeTensors Import | `apr import model.safetensors` fails | ✅ |
| H3 | GGUF Import | `apr import model.gguf` fails | ✅ |
| **H4** | **INT4 Quantize** | `apr convert --quantize int4` fails or PPL > 15% | ✅ |
| H5 | INT8 Quantize | `apr convert --quantize int8` fails or PPL > 5% | ✅ |
| H6 | Inspect | `apr inspect` missing architecture/params/vocab | ✅ |
| H7 | Validate | `apr validate --quality` fails on valid model | ✅ |
| H8 | Tensors Stats | `apr tensors --stats` shows NaN mean/std | ✅ |
| H9 | Compare HF | `apr compare-hf` deviation > 1e-5 | ✅ |
| **H10** | **Chat REPL** | `apr chat` fails to generate coherent response | ✅ |
| H11 | Chat Inspect | `apr chat --inspect` fails to show top-k probs | ✅ |
| H12 | Bench | `apr bench` throughput < 10 tok/s | ✅ |
| H13 | Eval PPL | `apr eval --dataset wikitext-2` PPL > 20 | ✅ |
| H14 | Canary Create | `apr canary create` fails to generate | ✅ |
| **H15** | **Compile Binary** | `apr compile -o qwen-chat` fails to produce executable | ✅ |
| H16 | Binary Runs | `./qwen-chat "test"` fails to produce output | ✅ |
| **H17** | **Serve API** | `apr serve` fails to start or /health returns error | ✅ |
| H18 | OpenAI Compat | `/v1/chat/completions` returns invalid response | ✅ |
| **H19** | **WASM Compile** | `apr compile --target wasm32` fails | ✅ |
| H20 | WASM Runs | `wasmtime qwen.wasm` fails to run | ✅ |
| H21 | Export GGUF | `apr export --format gguf` fails | ✅ |
| H22 | Export SafeTensors | `apr export --format safetensors` fails | ✅ |
| H23 | Merge Models | `apr merge` fails to produce valid output | ✅ |
| H24 | Cross-Compile | `--target aarch64-apple-darwin` fails | ✅ |
| **H25** | **E2E Workflow** | Full 6-stage demo script fails anywhere | ✅ |

### Section I: Deep Probador Testing — The Three Pillars (25 points)

*This section validates WASM quality through coverage, playbooks, and pixel-level regression.*

#### Pilar 1: Code Coverage (10 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **I1** | **100% Line Coverage** | `cargo llvm-cov` reports < 100% lines | ✅ |
| I2 | Branch Coverage | Branch coverage < 95% | ✅ |
| I3 | Function Coverage | Any public function uncovered | ✅ |
| **I4** | **Mutation Score** | `cargo mutants` score < 90% | ✅ |
| I5 | Dead Code | Any unreachable code without justification | ✅ |

#### Pilar 2: Playbook Execution (10 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **I6** | **50 Playbooks Pass** | Any of 50 playbooks fail | ✅ |
| I7 | Happy Path (10) | Any happy path scenario fails | ✅ |
| I8 | Error Handling (10) | Error states not properly displayed | ✅ |
| I9 | Edge Cases (10) | Unicode, empty input, max tokens fail | ✅ |
| I10 | WASI Compat (5) | wasmtime or wasmer fails to run WASM | ✅ |
| I11 | Performance (5) | First token > 2s in playbook timer | ✅ |
| I12 | Accessibility (5) | Keyboard nav or screen reader fails | ✅ |
| I13 | Regression (5) | Previously fixed bug recurs | ✅ |

#### Pilar 3: Golden Trace Verification (5 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **I14** | **Golden Trace Match** | Any tensor diff > tolerance | ✅ |
| I15 | Golden Baseline | Golden traces missing or stale | ✅ |
| I16 | Perplexity Check | Perplexity deviates > 5% from baseline | ✅ |
| I17 | Logit Match | Final logits deviate > 1e-3 from reference | ✅ |
| **I18** | **Cross-Runtime** | Output differs between native and wasmtime | ✅ |

#### Probador Integration (Bonus, not counted)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| I19 | Report Generated | `apr probador report` fails | ✅ |
| I20 | CI Integration | GitHub Actions workflow fails | ✅ |

### Section J: Deep Profiling — `apr profile` Verification (15 points)

*This section validates the `apr profile` command for model-agnostic performance analysis.*

#### J1: Command Execution (5 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **J1** | **Profile Runs** | `apr profile model.apr` exits non-zero or produces empty output | ✅ |
| J2 | Multi-Format | `apr profile model.safetensors` or `apr profile model.gguf` fails | ✅ |
| J3 | JSON Output | `apr profile --format json` produces invalid JSON | ✅ |
| J4 | Flamegraph | `apr profile --format flamegraph` produces invalid SVG | ✅ |
| J5 | Architecture Detection | Auto-detected architecture mismatches actual model type | ✅ |

#### J2: Roofline Analysis (Graham et al., Williams et al.) (5 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **J6** | **GFLOPS Computation** | Reported GFLOPS differs > 20% from manual calculation | ✅ |
| J7 | Bound Classification | Compute-bound op classified as memory-bound or vice versa | ✅ |
| J8 | Peak Detection | Peak theoretical GFLOPS doesn't match hardware spec | ✅ |
| J9 | Efficiency Grade | Grade doesn't reflect actual compute utilization | ✅ |
| **J10** | **Naive Detection** | `.data().iter()` loop not flagged as naive (< 10 GFLOPS threshold) | ✅ |

#### J3: Differential Profiling (McKeeman, 1998) (5 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **J11** | **HF Baseline Compare** | `apr profile --compare-hf` fails to produce comparison table | ✅ |
| J12 | Threshold Enforcement | 3x slowdown not flagged as failure (threshold: 2x) | ✅ |
| J13 | Time Attribution | Layer times don't sum to total (±5% tolerance) | ✅ |
| J14 | Call Graph | `--callgraph` output missing parent-child relationships | ✅ |
| **J15** | **CI Integration** | `--fail-on-naive` doesn't exit non-zero when naive detected | ✅ |

#### J4: Energy Efficiency / Green AI (5 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **J16** | **Energy Measurement** | `apr profile --energy` fails on Linux with RAPL support | ✅ |
| J17 | J/Token Calculation | Reported J/token differs > 30% from wall-power meter | ✅ |
| J18 | Graceful Degradation | `--energy` crashes on unsupported platform (should warn) | ✅ |
| J19 | JSON Energy Fields | `energy` object missing from JSON when `--energy` specified | ✅ |
| **J20** | **Reproducibility** | Same workload produces > 20% variance in energy across runs | ✅ |

#### J5: Performance Grading — Dean & Ghemawat (5 points)

| # | Claim | Falsification Condition (Fail if...) | Status |
|---|-------|------------------------|--------|
| **J21** | **Grade Computation** | `apr profile --perf-grade` fails or produces invalid grade | ✅ |
| J22 | Pre-allocation Detection | `Vec::with_capacity()` not detected in codebase | ✅ |
| J23 | Naive Loop Detection | `push() in loop` pattern not flagged as warning | ✅ |
| J24 | Crate Detection | Performance crates (smallvec, bumpalo) not detected in Cargo.toml | ✅ |
| **J25** | **JSON Performance Fields** | `performance_grade` object missing from JSON output | ✅ |

### Checklist Summary

| Section | Points | Focus |
|---------|--------|-------|
| A: Model Loading | 10 | APR file integrity |
| B: Tokenization | 10 | BPE correctness |
| C: Forward Pass | 25 | **"No Fake" Zone** — Golden trace verification |
| D: Generation | 20 | Quality & perplexity |
| E: Visual Control | 15 | Inspection & transparency |
| F: WASM/WASI | 10 | Portable execution |
| G: Code Quality | 15 | Engineering standards + Native Library Mandate |
| **H: Full Lifecycle** | **25** | **North Star workflow** |
| **I: Probador Testing** | **25** | **Three Pillars: Coverage, Golden Traces, E2E** |
| **J: Deep Profiling** | **25** | **Roofline + Differential + Naive + Energy + Perf Grade** |
| **TOTAL** | **180** | |

**Passing Threshold**: 180/180 (Zero Defects / Zero Stubs / Zero Ad-Hoc / Complete Workflow / Full Probador / Verified Profiling / Green AI / Performance Grading)

---

## 12. Implementation Roadmap

### 12.1 Phase 1: The "No Fake" Core (Days 1-4)
*Goal: Mathematically verified forward pass.*
1. Implement `Qwen2Model` struct.
2. Create **Golden Trace** generator script (using PyTorch).
3. Implement Forward Pass and verify against trace. **(Gatekeeper: Cannot proceed until C1 passes)**.

### 12.2 Phase 2: Tokenization & Generation (Days 5-7)
1. Port TikToken BPE logic.
2. Implement Samplers (Nucleus/TopK).
3. Verify Perplexity on small corpus. **(Gatekeeper: Cannot proceed until D1 passes)**.

### 12.3 Phase 3: Interactive & Visual (Days 8-10)
1. Build `apr chat` with Inspection Mode.
2. Build WASM bindings with state introspection.
3. Update UI to visualize the "Brain".

### 12.4 Phase 4: Deployment Targets (Days 11-14)
*Goal: One .apr, many deployment options.*

1. **`apr compile` (Standalone Binary)**
   - Embed model + tokenizer + runtime into single executable
   - Cross-compilation targets: linux-musl, darwin-arm64, windows
   - Verify: `./qwen-chat "test"` produces valid output

2. **`apr serve` (REST API Server)**
   - OpenAI-compatible `/v1/chat/completions` endpoint
   - Prometheus metrics at `/metrics`
   - Health check at `/health`
   - Verify: curl test returns valid JSON response

3. **WASM Module (WASI)**
   - `apr compile --target wasm32-wasi`
   - Pure Rust, zero JavaScript dependencies
   - WASI filesystem access for model loading
   - Verify: Runs in wasmtime/wasmer

4. **Export Formats**
   - `apr export --format gguf` (llama.cpp compatible)
   - `apr export --format safetensors` (HuggingFace ecosystem)
   - `apr export --format onnx` (ONNX Runtime)
   - Verify: Exported files load in target runtime

### 12.5 Phase 5: E2E Validation & Polish (Days 15-17)
*Goal: Complete North Star demo works end-to-end.*

1. **Create E2E Test Script**
   ```bash
   # automated_demo.sh — Must pass 100%
   apr import hf://Qwen/Qwen2-0.5B-Instruct -o model.apr
   apr validate model.apr --quality
   apr convert model.apr --quantize int4 -o model-int4.apr
   apr test-model model-int4.apr --golden-trace golden/qwen2.json
   apr compile model-int4.apr -o qwen-chat
   ./qwen-chat "What is 2+2?" | grep -q "4"
   apr serve model-int4.apr --port 8080 &
   curl localhost:8080/health | grep -q "ok"
   # All steps must succeed
   ```

2. **Documentation**
   - Update README with full workflow
   - Record demo video showing all stages
   - Create "5-minute quickstart" guide

3. **CI Integration**
   - Add `make north-star-demo` target
   - Weekly scheduled run to catch regressions
   - Artifact storage for compiled binaries

---

## 13. Risk Analysis

| Risk | Impact | Mitigation |
|------|--------|------------|
| **Fake Stub Regression** | Critical | **Jidoka**: CI fails on perplexity regression. **Visual Control**: UI shows logits. |
| **Quantization Quality** | High | Evaluate PPL loss; Allow 8-bit fallback. |
| **WASM Memory OOM** | High | Streaming loading; Memory limits; 4-bit strict. |
| **Cross-compile Failures** | Medium | Pre-built binaries in CI; Docker build containers. |
| **OpenAI API Incompatibility** | Medium | Test against official OpenAI Python client. |
| **GGUF Format Drift** | Low | Pin to llama.cpp release version; regression tests. |

---

## 14. References

1. **Ainslie, J., et al.** (2023). *GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints*. arXiv:2305.13245.
2. **Bai, J., et al.** (2023). *Qwen Technical Report*. arXiv:2309.16609.
3. **Fan, A., Lewis, M., & Dauphin, Y.** (2018). *Hierarchical Neural Story Generation*. arXiv:1805.04833.
4. **Haas, A., et al.** (2017). *Bringing the Web up to Speed with WebAssembly*. PLDI 2017.
5. **Holtzman, A., et al.** (2020). *The Curious Case of Neural Text Degeneration*. ICLR 2020.
6. **Kleppmann, M., et al.** (2019). *Local-First Software: You Own Your Data, in spite of the Cloud*. Onward! 2019.
7. **Liker, J. K.** (2004). *The Toyota Way: 14 Management Principles from the World's Greatest Manufacturer*. McGraw-Hill.
8. **Popper, K.** (1959). *The Logic of Scientific Discovery*. Hutchinson & Co.
9. **Shazeer, N.** (2020). *GLU Variants Improve Transformer*. arXiv:2002.05202.
10. **Su, J., et al.** (2024). *RoFormer: Enhanced Transformer with Rotary Position Embedding*. Neurocomputing.
11. **Vaswani, A., et al.** (2017). *Attention Is All You Need*. NIPS 2017.
12. **Zhang, B., & Sennrich, R.** (2019). *Root Mean Square Layer Normalization*. NeurIPS 2019.
13. **McKeeman, W. M.** (1998). *Differential Testing for Software*. Digital Technical Journal.
14. **Williams, S., Waterman, A., & Patterson, D.** (2009). *Roofline: an insightful visual performance model for multicore architectures*. CACM.
15. **Graham, S. L., Kessler, P. B., & McKusick, M. K.** (1982). *gprof: A Call Graph Execution Profiler*. SIGPLAN Symposium on Compiler Construction.
16. **Anderson, T. E., & Lazowska, E. D.** (1990). *Quartz: A Tool for Tuning Parallel Program Performance*. SIGMETRICS.
17. **Eyerman, S., & Eeckhout, L.** (2008). *System-Level Performance Metrics for Multiprogram Workloads*. IEEE Micro.
18. **Dean, J., & Ghemawat, S.** (2025). *Performance Hints*. Abseil, Google. https://abseil.io/fast/hints.html

---

## Appendix A: Verification Checklist Summary

**Total Points**: 180

| Section | Points | Status |
|---------|--------|--------|
| A: Model Loading | 10 | ✅ |
| B: Tokenization | 10 | ✅ |
| C: Forward Pass ("No Fake") | 25 | ✅ |
| D: Generation & Quality | 20 | ✅ |
| E: Visual Control | 15 | ✅ |
| F: WASM/WASI | 10 | ✅ |
| G: Code Quality | 15 | ✅ |
| **H: Full Lifecycle (North Star)** | **25** | ✅ |
| **I: Probador (Three Pillars)** | **25** | ✅ |
| **J: Deep Profiling** | **25** | ✅ |
| **TOTAL** | **180** | **✅ 180/180** |

**Passing Threshold**: 180/180 ✅ ACHIEVED (Zero Defects / Zero Stubs / Zero Ad-Hoc / Complete Workflow / Full Probador / Verified Profiling / Green AI / Performance Grading)

---

## Appendix B: Quick Reference — APR Commands

```bash
# ACQUIRE
apr import hf://org/model -o model.apr    # From HuggingFace
apr import model.safetensors -o model.apr # From SafeTensors
apr import model.gguf -o model.apr        # From GGUF

# INSPECT
apr inspect model.apr                     # View metadata
apr validate model.apr --quality          # Verify integrity
apr tensors model.apr --stats             # List tensors
apr compare-hf model.apr --hf org/model   # Compare to HF

# OPTIMIZE
apr convert model.apr --quantize int4 -o out.apr  # Quantize
apr merge a.apr b.apr -o merged.apr               # Merge models
apr tune model.apr --method lora -o tuned.apr     # Fine-tune

# TEST
apr chat model.apr                        # Interactive REPL
apr chat model.apr --inspect              # With introspection
apr bench model.apr                       # Benchmark
apr eval model.apr --dataset wikitext-2   # Perplexity
apr test-model model.apr --golden-trace   # Verify vs reference
apr canary create model.apr -o canary.json # Regression test

# PROFILE (Roofline + Differential + Naive Detection)
apr profile model.apr                     # Identify hotspots
apr profile model.apr --granular          # Layer-by-layer
apr profile model.apr --compare-hf org/m  # vs HuggingFace baseline
apr profile model.apr --detect-naive      # Find naive loops
apr profile model.apr --format json       # CI-friendly output
apr profile model.apr --callgraph         # gprof-style tree

# DEPLOY
apr compile model.apr -o chat             # Standalone binary
apr serve model.apr --port 8080           # REST API server
apr compile model.apr --target wasm32     # WASM module
apr export model.apr --format gguf        # Export to GGUF
apr export model.apr --format safetensors # Export to SafeTensors
```

---

## Appendix C: Probador Quick Reference

```bash
# ═══════════════════════════════════════════════════════════════════════════
# PILAR 1: CODE COVERAGE
# ═══════════════════════════════════════════════════════════════════════════
apr probador coverage                        # Run coverage analysis
apr probador coverage --html -o coverage/    # Generate HTML report
apr probador coverage --fail-under 100       # CI gate (100% required)
apr probador mutants                         # Run mutation testing
apr probador mutants --fail-under 90         # CI gate (90% required)

# ═══════════════════════════════════════════════════════════════════════════
# PILAR 2: PLAYBOOK EXECUTION
# ═══════════════════════════════════════════════════════════════════════════
apr probador playbook list                   # List all 50 playbooks
apr probador playbook run playbooks/         # Run all playbooks
apr probador playbook run happy-path.yaml    # Run single playbook
apr probador playbook create                 # Create new playbook template
apr probador playbook validate               # Check YAML syntax

# ═══════════════════════════════════════════════════════════════════════════
# PILAR 3: GOLDEN TRACE VERIFICATION
# ═══════════════════════════════════════════════════════════════════════════
apr probador golden generate                 # Generate golden traces from PyTorch
apr probador golden verify                   # Verify against golden traces
apr probador golden update                   # Update golden after approved change
apr probador trace diff -o diff/             # Generate diff report

# ═══════════════════════════════════════════════════════════════════════════
# TENSOR ANALYSIS
# ═══════════════════════════════════════════════════════════════════════════
apr probador tensor export model.apr         # Export layer tensors
apr probador tensor compare v1/ v2/          # Compare two versions
apr probador tensor stats model.apr          # Show tensor statistics

# ═══════════════════════════════════════════════════════════════════════════
# FULL SUITE
# ═══════════════════════════════════════════════════════════════════════════
apr probador full                            # Run all three pillars
apr probador report --html                   # Generate combined report
apr probador ci --strict                     # CI mode (strict, no-color)

# ═══════════════════════════════════════════════════════════════════════════
# MAKEFILE TARGETS
# ═══════════════════════════════════════════════════════════════════════════
make probador                                # Full suite
make probador-coverage                       # Coverage only
make probador-playbooks                      # Playbooks only
make probador-visual                         # Visual regression only
make probador-report                         # Generate report
```

---

*This specification enforces the "Toyota Way": Do it right, verify it's right, show it's right, deploy it everywhere, test it completely.
```