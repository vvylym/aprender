# Showcase Benchmark Workflow
#
# Per spec: docs/specifications/qwen2.5-coder-showcase-demo.md Section 6
#
# Runs the ComputeBrick showcase benchmarks and falsification tests.
# This workflow validates the brick-level performance claims.

name: Showcase Benchmark

on:
  # Manual trigger for on-demand benchmarking
  workflow_dispatch:
    inputs:
      throughput_threshold:
        description: 'Minimum throughput (tok/s)'
        required: "false"
        default: '100'
      brick_score_threshold:
        description: 'Minimum brick score (0-100)'
        required: "false"
        default: '80'

  # Run on PR for showcase-related changes
  pull_request:
    paths:
      - 'crates/apr-cli/src/commands/cbtop.rs'
      - 'tests/falsification_*.rs'
      - 'docs/specifications/qwen2.5-coder-showcase-demo.md'
      - '.github/workflows/showcase-benchmark.yml'

  # Weekly scheduled run for trend tracking
  schedule:
    - cron: '0 3 * * 1'  # Every Monday at 3 AM UTC

env:
  CARGO_TERM_COLOR: always

jobs:
  falsification-tests:
    name: Run Falsification Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2

      - name: Run Falsification Tests (137 tests: F001-F105, M001-M020, O001-O009, R001)
        run: |
          echo "Running Popperian falsification test suite (137 tests)..."
          cargo test --release \
            --test falsification_brick_tests \
            --test falsification_budget_tests \
            --test falsification_correctness_tests \
            --test falsification_cuda_tests \
            --test falsification_measurement_tests \
            --test falsification_performance_tests \
            --test falsification_2x_ollama_tests \
            --test falsification_real_profiling \
            -- --test-threads=2 2>&1 | tee falsification-results.txt

      - name: Generate test summary
        if: always()
        run: |
          echo "# Falsification Test Results" > falsification-summary.md
          echo "" >> falsification-summary.md
          echo "**Date:** $(date -u)" >> falsification-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> falsification-summary.md
          echo "**Commit:** ${{ github.sha }}" >> falsification-summary.md
          echo "" >> falsification-summary.md
          echo "## Test Categories (137 total)" >> falsification-summary.md
          echo "" >> falsification-summary.md
          echo "| Category | Count | Description |" >> falsification-summary.md
          echo "|----------|-------|-------------|" >> falsification-summary.md
          echo "| F001-F020 | 20 | Brick Core Invariants |" >> falsification-summary.md
          echo "| F021-F040 | 20 | Token Budget Compliance |" >> falsification-summary.md
          echo "| F041-F060 | 21 | Backend Correctness |" >> falsification-summary.md
          echo "| F061-F080 | 21 | CUDA Kernel Validation |" >> falsification-summary.md
          echo "| F081-F105 | 25 | Performance Regression |" >> falsification-summary.md
          echo "| M001-M020 | 20 | Measurement & Scoring |" >> falsification-summary.md
          echo "| O001-O009 | 9 | 2x Ollama Parity |" >> falsification-summary.md
          echo "| R001 | 1 | Real Profiling |" >> falsification-summary.md
          echo "" >> falsification-summary.md

          # Count passed/failed
          passed=$(grep -c "ok$" falsification-results.txt || echo "0")
          failed=$(grep -c "FAILED$" falsification-results.txt || echo "0")
          echo "## Results" >> falsification-summary.md
          echo "" >> falsification-summary.md
          echo "- **Passed:** $passed" >> falsification-summary.md
          echo "- **Failed:** $failed" >> falsification-summary.md
          echo "" >> falsification-summary.md

          cat falsification-summary.md

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: falsification-results-${{ github.sha }}
          path: |
            falsification-results.txt
            falsification-summary.md
          retention-days: 30

  headless-benchmark:
    name: Run Headless Benchmark
    runs-on: ubuntu-latest
    needs: falsification-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2

      - name: Build in release mode
        run: cargo build --release -p apr-cli

      - name: Run headless benchmark (simulated for CI)
        run: |
          echo "Running cbtop headless benchmark (simulated data for CI)..."
          cargo run --release -p apr-cli -- cbtop \
            --headless \
            --simulated \
            --json \
            --output showcase-results.json \
            --iterations 100

          echo "Benchmark results:"
          cat showcase-results.json

      - name: Validate CI thresholds (simulated)
        if: github.event_name == 'workflow_dispatch'
        run: |
          echo "Validating CI thresholds (simulated data)..."
          cargo run --release -p apr-cli -- cbtop \
            --headless \
            --simulated \
            --ci \
            --throughput ${{ github.event.inputs.throughput_threshold || '100' }} \
            --iterations 100

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: showcase-results-${{ github.sha }}
          path: showcase-results.json
          retention-days: 90

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let results = {};
            try {
              results = JSON.parse(fs.readFileSync('showcase-results.json', 'utf8'));
            } catch (e) {
              results = { error: 'Failed to parse results' };
            }

            const throughput = results.throughput?.tokens_per_sec?.toFixed(1) || 'N/A';
            const status = results.status || 'UNKNOWN';
            const passed = results.falsification?.passed || 0;
            const total = results.falsification?.total_points || 137;

            const body = `## ComputeBrick Showcase Results

            | Metric | Value |
            |--------|-------|
            | Throughput | ${throughput} tok/s |
            | Status | ${status} |
            | Falsification | ${passed}/${total} points |

            **Model:** ${results.model || 'N/A'}

            ---
            *Benchmark completed on commit ${context.sha.substring(0, 7)}*`;

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.name,
              body: body
            });
